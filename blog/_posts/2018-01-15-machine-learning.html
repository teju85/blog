<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="/blog/assets/main.css">

  <link rel="stylesheet" href="/blog/assets/katex.min.css">
  <script rel="src" src="/blog/assets/jquery-1.11.1.min.js"></script>
  <script rel="src" src="/blog/assets/katex.min.js"></script>
  <script rel="src" src="/blog/assets/auto-render.min.js"></script>
  <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
              {left: '$$', right: '$$', display: false},
              {left: '$', right: '$', display: false}
          ],
          throwOnError : false
        });
    });
  </script>


</head>
  <body>
    <header class="site-header" role="banner">
  <div class="wrapper">
    
    
    <a class="site-title" rel="author" href="/blog/">Quagmire</a>

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
            <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
            <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
          </svg>
        </span>
      </label>

      <div class="trigger">
        <a class="page-link" href="/blog/about.html">About</a>
        <a class="page-link" href="/blog/allposts.html">All Posts</a>
        <a class="page-link" href="/blog/tags.html">Tags</a>
      </div>
    </nav>
  </div>
</header>
    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Machine Learning Coursera notes</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-01-15" itemprop="datePublished">
        Published: 2018-01-15
      </time>
      
        <br/>
        <time class="dt-published" datetime="2021-07-15" itemprop="datePublished">
          Last Modifed: 2021-07-15
        </time>
      
    </p>
  </header>

  <ul class="tags">
  
    
    <li><a href="/blog/tags.html#course-notes" class="tag">course-notes</a></li>
  
    
    <li><a href="/blog/tags.html#machine-learning" class="tag">machine-learning</a></li>
  
  </ul>

  <div class="post-content e-content" itemprop="articleBody">
    <p>My notes while taking the ML course from Dr. Andrew Ng on coursera.</p>
<h3>Week1</h3>
<ul>
<li>ML grew out of work in AI</li>
<li>ML is also used where applications can&#x27;t be programmed by hand
<ul>
<li>NLP, Comp.Vision, etc</li>
<li>self-customizing programs</li>
<li>understanding human learning</li>
</ul>
</li>
<li>most common ML algos: supervised and unsupervised</li>
<li>other algos: reinforcement learning, recommender systems, etc</li>
<li>supervised learning:
<ul>
<li>regression = predict continuous output variable</li>
<li>classification = predict/classify discreet valued output</li>
</ul>
</li>
<li>unsupervised learning:
<ul>
<li>clustering of unlabeled data</li>
</ul>
</li>
<li>supervised learning:
<ul>
<li>training set = data-set (labelled)</li>
<li>m = num of training examples</li>
<li>x = &#x27;input&#x27; variable/features</li>
<li>y = &#x27;output&#x27; variable/ &#x27;target&#x27; variable</li>
<li>$$x_i$$, $$y_i$$ - ith training sample</li>
<li>its flow:
<ul>
<li>training-set --&gt; learning algo --&gt; h (hypothesis)</li>
<li>test/real-world-input --&gt; h --&gt; prediction/classification</li>
</ul>
</li>
</ul>
</li>
<li>univariate linear regression:
<ul>
<li>$$h(x) = t_0 + t_1 x$$</li>
<li>cost function: $$J(t_0,t_1) = \frac{\sum(h(x_i) - y_i)^2}{2 * m}$$
<ul>
<li>$$min_{(t_0,t_1)} J(t_0,t_1)$$</li>
<li>also called squared-error function</li>
<li>most commonly used cost function</li>
<li>gives a nice quadratic surface to minimize</li>
</ul>
</li>
<li>gradient descent
<ul>
<li>start with some initial value</li>
<li>keep following down the gradient and hopefully will reach minimum</li>
<li>local minima can trip us here!</li>
<li>repeat until convergence:
<ul>
<li>$$t_i -= \alpha \frac{\partial J(t0,..)}{\partial t_i}$$</li>
<li>for every parameter $$t_i$$</li>
<li>these updates are concurrent for all params!</li>
<li>$$\alpha$$ = learning rate (controls the step size)</li>
</ul>
</li>
<li>convex functions always ensure that gradient descent will converge to global optimum</li>
<li>the above algo is &#x27;batch&#x27; gradient descent
<ul>
<li>meaning at each step, we are using all  - of the training samples</li>
</ul>
</li>
</ul>
</li>
<li>linear algebra: notation and set of ops using matrices and vectors</li>
</ul>
</li>
</ul>
<h3>Week2</h3>
<ul>
<li>multi-variate linear regression
<ul>
<li>n = number of features</li>
<li>x(i) = input features of ith training sample</li>
<li>x(i)(j) = feature j value in ith training sample</li>
<li>h(x) = sum(ti *xi) i=0:n</li>
<li>vectorized version:  h(X) = T&#x27;   - X   x0 is always 1!</li>
</ul>
</li>
<li>gradient descent for multivariate linear regression
<ul>
<li>J(T) = sum(((T&#x27;   - X) - Y).^2) / (2*m)</li>
<li>T = n+1 x 1</li>
<li>X = m x n+1</li>
<li>Y = m x 1</li>
<li>updation:  T = T - alpha   - d(J(T))/dT</li>
<li>T = T - alpha   - (((X   - T) - Y)&#x27;   - X)&#x27; / m</li>
<li>such an X is called design matrix</li>
</ul>
</li>
<li>gradient descent - feature scaling
<ul>
<li>make sure features are on a similar scale</li>
<li>convergence is quicker this way!</li>
<li>because the contour plots of cost function will have incredibly skewed ellipses. Thus, the convergence will take quite a long time</li>
<li>generally, get the feature into [-1, 1] range</li>
<li>Can this be the reason we have sigmoid functions in neural nets!??</li>
<li>use mean normalization brings features to [-0.5, 0.5] range with mean=0
<ul>
<li>(xi - meani) / range</li>
<li>mean can be the mean of that feature in the training set</li>
<li>range can be (max - min) or standard-deviation</li>
</ul>
</li>
</ul>
</li>
<li>gradient descent - learning rate
<ul>
<li>plot J(T) over iterations, should help debug the learning algo</li>
<li>J(T) should decrease after every iteration</li>
<li>this will also tell us when to stop running more iterations</li>
<li>one other approach is to monitor the changes in J(T) over the iterations and stop when the decrease is &#x27;insignificant&#x27;</li>
<li>but better to not automate this and use plots to confirm</li>
<li>if J(T) is increasing over iterations, choose a smaller alpha</li>
<li>but if alpha is too small, convergence might be slower!</li>
</ul>
</li>
<li>depending on the insight into the problem, by defining new features based on the training set, we might get better model</li>
<li>looking at the data, we could also decide to probably use polynomial model or cubic model, so on...
<ul>
<li>for such models, the feature scaling becomes increasingly important!</li>
</ul>
</li>
<li>normal equation:
<ul>
<li>solve for T analytically, instead of iterative gradient descent</li>
<li>T = pinv(X&#x27; - X) - X&#x27; - Y</li>
<li>for this method, feature scaling is not required</li>
<li>thus doesn&#x27;t need to iterate and no need to choose alpha</li>
<li>becomes very slow for large values of &#x27;n&#x27;</li>
</ul>
</li>
<li>normal equation non-invertibility
<ul>
<li>what if (X&#x27; - X) is non-invertible (singular/degenerate)?</li>
<li>pretty rare case</li>
<li>however, as long as we use &quot;pinv&quot; for inverse of X&#x27;*X, we are OK</li>
<li>causes for it to be singular:
<ul>
<li>redundant features (linearly dependent)</li>
<li>too many features (m &lt;= n)
<ul>
<li>Better to delete some features or use regularization</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Week3</h3>
<ul>
<li>Binary classification: y in {0,1}  0=negative-class, 1=positive-class</li>
<li>There&#x27;s multi-class classification problem as well.</li>
<li>threshold classifier:
<ul>
<li>fit linear regression and then apply a threshold on its output</li>
<li>but this is very sensitive to the position of inputs passed!
<ul>
<li>example: think what happens if there&#x27;s an outlier far away from the current set of poinets?</li>
</ul>
</li>
<li>output needs to be either 0 or 1, but linear regression outputs continuous values</li>
</ul>
</li>
<li>that&#x27;s where logistic regression is applied for classification problem</li>
<li>hypothesis representation for logistic regression
<ul>
<li>want h(x) in [0,1]</li>
<li>h(x) = g(theta&#x27;   - x)</li>
<li>g(i) = 1 / (1 + e^-i)</li>
<li>g = logistic function or sigmoid function</li>
</ul>
</li>
<li>one interpretation of the above h(x) is probability that y=1 on input x
<ul>
<li>ie. h(x) = P(y=1|x;theta)</li>
</ul>
</li>
<li>this basically means y=1 whenever theta&#x27;   - x &gt;= 0, and y=0 otherwise
<ul>
<li>this is the decision boundary for logistic regression hypothesis</li>
<li>in this particular case this boundary is linear</li>
<li>if we need a non-linear decision boundary, then use non-linear terms in the logistic regression equation (similar to what was discussed in linear regression lecture)</li>
</ul>
</li>
<li>if we use quadratic cost function as was used in linear regression model, now it will be a non-convex function</li>
<li>cost function for logistic regression:
<ul>
<li>cost(h(x),y) = -log(h(x)) if y=1, -log(1-h(x)) if y=0</li>
<li>intuition is that for correct classification there is no penalty and for incorrect, there&#x27;s a very large cost</li>
<li>this is gives us a convex function which only one minima</li>
</ul>
</li>
<li>simplified cost function for the above:
<ul>
<li>cost(h(x),y) = -y*log(h(x)) - (1-y)*log(1-h(x))</li>
</ul>
</li>
<li>gradient descent on this will now be:
<ul>
<li>T = T - alpha   - ((h(X)-Y)&#x27;   - X)&#x27;</li>
<li>looks similar to logistic regression!</li>
<li>feature scaling also works here.</li>
</ul>
</li>
<li>optimization algos:
<ul>
<li>gradient descent</li>
<li>conjugate descent</li>
<li>BFGS</li>
<li>LBFGS</li>
<li>these only require J(theta) and d(J(theta))/d(theta)</li>
</ul>
</li>
<li>advantages of the other 3 algos
<ul>
<li>no need to manually pick alpha</li>
<li>faster than gradient descent in terms of convergence</li>
</ul>
</li>
<li>disadvantages of these:
<ul>
<li>more complex</li>
</ul>
</li>
<li>use &#x27;fminunc&#x27; (function minimization unconstrained) for optimization using these different optimization techniques</li>
<li>logistic regression on multi-class classification:
<ul>
<li>one-vs-all classification (one-vs-rest)
<ul>
<li>make all others under one class, except the current class</li>
<li>apply logistic regression for binary classification</li>
<li>repeat this for all classes</li>
<li>pick the class that has highest probability (max value of h(x))</li>
</ul>
</li>
</ul>
</li>
<li>Regularization (problem of overfitting)
<ul>
<li>under fitting (high bias)</li>
<li>over fitting (high variance)</li>
<li>over fitting - if we have too many features in the learned hypothesis, it may fit the training set very well, but fail to generalize on new examples</li>
<li>lot of features and very less training data can also lead to this</li>
<li>to address overfitting:
<ul>
<li>reduce number of features
<ul>
<li>manually select which features to keep</li>
<li>model selection algo</li>
</ul>
</li>
<li>regularization
<ul>
<li>keep all features, but reduce the magnitude/values of params</li>
<li>works well when there are lot of features</li>
</ul>
</li>
</ul>
</li>
<li>having small values for params
<ul>
<li>&#x27;simpler&#x27; hypothesis</li>
<li>less prone to overfitting</li>
</ul>
</li>
<li>J(theta) = (sum((h(x)-y)^2) + lambda*T(1:)&#x27;<em>T(1:))/(2</em>m)
<ul>
<li>theta(0) is not part of the above sum!</li>
<li>lambda - regularization param
<ul>
<li>controls trade off between fitting to training data well at the same time keeping params small</li>
<li>if it is large, then we will see underfitting</li>
</ul>
</li>
</ul>
</li>
<li>the gradient for the descent also changes according to this regularizer</li>
<li>for normal equation with regularization
<ul>
<li>m = eye(n+1,n+1)</li>
<li>m[0,0] = 0</li>
<li>T = pinv((X&#x27;   - X) + (lambda   - m))   - X&#x27;   - Y</li>
<li>as long as lambda &gt; 0, the above matrix is invertible!</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Week4</h3>
<ul>
<li>non-linear hypotheses (neural networks representation)
<ul>
<li>using quadratic features leads to huge number of features</li>
<li>can lead to overfitting of the data as well</li>
<li>this is especially difficult with image applications!</li>
</ul>
</li>
<li>neural networks are algos designed to mimic brain</li>
<li>neuron model and logistic unit
<ul>
<li>bias unit</li>
<li>inputs</li>
<li>input wires/params/weights</li>
<li>sigmoid (logistic) activation function</li>
</ul>
</li>
<li>neural network is now a collection of these neurons stacked into layers
<ul>
<li>first layer is input layer</li>
<li>last layer is output layer</li>
<li>in between layers are hidden layers</li>
<li>a[i][j] = &#x27;activation&#x27; of unit i in layer j</li>
<li>theta[j] = matrix of weights from layer j to j+1</li>
<li>if net has s[j] units in layer j and s[j+1] in j+1, then theta[j] is of dimension s[j+1]x(s[j]+1).  +1 for bias unit</li>
<li>vectorization of this computation is basically matrix-vector multiplication</li>
<li>a[i+1] = g(theta[i]   - a[i])    (add bias unit at each layer!)</li>
<li>a[1] = input layer</li>
<li>this process is called forward propagation</li>
<li>forward propagation of input activation to output activations</li>
</ul>
</li>
<li>neural net learning its own features
<ul>
<li>hidden and output layer look like a logistic regression</li>
<li>each unit in hidden layer is set of new features learned from the input!</li>
<li>ANN can use this hidden layer to learn more complex features to feed to the output layer</li>
</ul>
</li>
<li>neural nets for multi-class classification
<ul>
<li>by using multiple units in the output layer</li>
</ul>
</li>
</ul>
<h3>Week5</h3>
<ul>
<li>nomenclature
<ul>
<li>L = total no. of layers in network</li>
<li>s(l) = no. of units (w/o bias unit) in layer l</li>
</ul>
</li>
<li>neural net cost function will be (using NLL with L2-norm)
<ul>
<li>NLL will be the same except that h(x) will now be the entire MLP!</li>
<li>regularization will be summed across all weights on all layers</li>
</ul>
</li>
<li>backpropagation algo
<ul>
<li>del[l][j] = &#x27;error&#x27; of node j in layer l</li>
<li>then propagate back these &#x27;del&#x27; till the input layer is reached</li>
<li>del[l] = (theta[l]&#x27;   - del[l+1]) .  -  g&#x27;(z[l])
<ul>
<li>g&#x27; is derivative of g</li>
<li>theta&#x27; is matrix transpose</li>
</ul>
</li>
<li>dJ/d(theta[l][i][j]) = (a[l][j]   - del[l+1][i]) + (lambda   - theta[l][i][j])</li>
</ul>
</li>
<li>gradient checking
<ul>
<li>can catch bugs in the forward/backward prop implementation</li>
<li>estimate slope using theta-eps and theta+eps</li>
<li>such a two-sided difference gives better estimation than theta-eps, theta (one-sided).</li>
<li>call your implementation for evaluating gradients</li>
<li>compare them!</li>
<li>for vectors, partial derivatives can be obtained using the same principle
<ul>
<li>just work on each dimension, one at a time!</li>
</ul>
</li>
</ul>
</li>
<li>initial value of theta
<ul>
<li>cannot initialize all theta in a net to zero
<ul>
<li>after each gradient update, params corresponding to inputs to each hidden units will be identical</li>
<li>this is the problem of symmetric weights</li>
</ul>
</li>
<li>thus for symmetry-breaking, we&#x27;ll have to perform random init.
<ul>
<li>init each theta between [-eps, eps]</li>
</ul>
</li>
</ul>
</li>
<li>putting it all together
<ul>
<li>number of inputs = dimension of input features</li>
<li>number of outputs = number of classes (For a classification problem)</li>
<li>reasonable default: have same of number of hidden units in each layer</li>
<li>can usually start with 1 hidden layer</li>
<li>usually the more the hidden layers, the better the network</li>
</ul>
</li>
</ul>
<h3>Week6</h3>
<ul>
<li>debugging a learning algo
<ul>
<li>if the system shows huge prediction errors on new data
<ul>
<li>get more training data</li>
<li>try smaller set of features</li>
<li>try to get additional features</li>
<li>try adding polynomial features</li>
<li>play with lambda value</li>
</ul>
</li>
</ul>
</li>
<li>machine learning diagnostic:
<ul>
<li>a test to gain insight on what is/isnt working with a learning algo and how to best improve its performance.</li>
</ul>
</li>
<li>evaluating a hypothesis
<ul>
<li>split dataset into training/test set (70:30 split)
<ul>
<li>train using training set and measure its performance using test set</li>
<li>another way can be to just measure the misclassification rate</li>
</ul>
</li>
</ul>
</li>
<li>training error is usually lower than the generalization error</li>
<li>model selection
<ul>
<li>select those hyper-params for which we get the lowest test error</li>
<li>but we cannot estimate generalization error for this, since we had selected the model based on the test error itself!</li>
<li>hence, split dataset into training/cross-validation/test sets. (split ratio: 60:20:20)</li>
<li>now measure the model&#x27;s performance on the CV set.</li>
<li>pick the hypothesis with the lowest CV error</li>
</ul>
</li>
<li>diagnosis bias vs variance (under vs over fitting)
<ul>
<li>both high training and high CV error = bias problem (simple model)</li>
<li>low training and high CV error = variance problem (complex model)</li>
</ul>
</li>
<li>choosing lambda
<ul>
<li>in this case, the training/CV errors do not contain regularization param</li>
<li>only the cost function during training the model itself, contains so!</li>
<li>to choose an optimal lambda, then use similar approach as before in model selection</li>
<li>both high training and high CV error = bias problem (large lambda)</li>
<li>low training and high CV error = variance problem (small lambda)</li>
</ul>
</li>
<li>learning curves
<ul>
<li>plot training/CV errors as a function of dataset size</li>
<li>here average training error grows with dataset size</li>
<li>average CV errors decays with dataset size</li>
<li>for large data if training error ~= CV error =&gt; bias problem (with high error value)</li>
<li>high bias problem cannot be solved using more data!</li>
<li>for large data if training error != CV error and there&#x27;s a large difference between them =&gt; variance problem (training error smaller than CV error)</li>
<li>high variance problem cannot be somewhat reduced with more data</li>
</ul>
</li>
<li>What to do next?
<ul>
<li>getting more training examples (helps for high variance case)</li>
<li>try smaller set of features (high variance)</li>
<li>try getting additional features (helps for high bias problem)</li>
<li>try adding polynomial features (high bias)</li>
<li>try decreasing lambda (high bias)</li>
<li>try increasing lambda (high variance)</li>
</ul>
</li>
<li>neural nets
<ul>
<li>smaller neural net (less params) = more prone to underfitting</li>
<li>larger neural net = more prone to overfitting</li>
<li>use regularization to address overfitting</li>
</ul>
</li>
<li>ML system design
<ul>
<li>prioritizing what to work on: collect more data or planning what features to use</li>
<li>have a single evaluation metric (eg: error percentage) to evaluate different ideas/approaches</li>
<li>for skewed classes (rare classes in the dataset)
<ul>
<li>usual classification accuracy is bad!</li>
<li>in such cases, use confusion matrix to measure error rates in classification</li>
<li>can also use precision/recall technique</li>
</ul>
</li>
<li>precision/recall
<ul>
<li>precision = #true positives / #positives predicted</li>
<li>recall = #true positives / #actual positives</li>
</ul>
</li>
</ul>
</li>
<li>trading off between precision and recall
<ul>
<li>lower precision; higher recall (avoid false negatives)</li>
<li>higher precision; lower recall (avoid false positives)</li>
</ul>
</li>
<li>comparing precision/recall (F score): F = 2   - P   - R / (P + R)</li>
<li>how much data to train on?
<ul>
<li>in ML, it is not who has the best system that wins, but the one who has the most data!</li>
</ul>
</li>
</ul>
<h3>Week7</h3>
<ul>
<li>logistic regression optimization objective
<ul>
<li>y=1, we need theta&#x27;   - x &gt;&gt; 0 and for y=0, &lt;&lt; 0</li>
<li>instead of putting lambda hyper-parameter on regularization, in SVMs people putting the inverse of it onto the cost itself.</li>
<li>and they don&#x27;t use &#x27;1/m&#x27; multiplier as convention</li>
</ul>
</li>
<li>Support Vector Machines (SVMs)
<ul>
<li>instead of giving out probabilities like in logistic regression, SVM hypothesis directly gives out y=0/1.</li>
<li>meaning, h(x) = 1 if theta&#x27;   - x &gt;= 0, and 0 otherwise</li>
<li>they are also called as large margin classifiers</li>
<li>they create a more robust decision boundary</li>
<li>but these classifiers can be sensitive to outliers! (in which case, the regularization parameter &#x27;C&#x27; plays vital role, similar to lambda)</li>
</ul>
</li>
<li>kernels (non-linear decision boundary) - to classify complex non-linear functions</li>
<li>gaussian kernel
<ul>
<li>fi = exp(-||x-li||^2 / (2*sigma^2))</li>
<li>features used in the &quot;x&quot; vector of: theta&#x27;   - x</li>
<li>li = landmarks (manually chosen)</li>
<li>i = 1,...n</li>
<li>we could use other similarity functions as well</li>
</ul>
</li>
<li>how to get these landmarks?
<ul>
<li>to begin with make each training example as a landmark</li>
<li>but the number of features with this approach = number of training samples!</li>
</ul>
</li>
<li>bias/variance trade-off:
<ul>
<li>C = 1/lambda</li>
<li>large C = lower bias, higher variance</li>
<li>small C = higher bias, lower variance</li>
<li>in gaussian kernel</li>
<li>large sigma = features vary smoothly = higher bias, lower variance</li>
<li>small sigma = features vary sharply = lower bias, higher variance</li>
</ul>
</li>
<li>Using SVM
<ul>
<li>choice of C</li>
<li>choice of kernel (and its parameter values)</li>
<li>no kernel = linear kernel</li>
<li>if using gaussian kernel, do perform feature scaling</li>
</ul>
</li>
<li>not all kernels are valid kernels!
<ul>
<li>they need to satisfy &#x27;mercers theorem&#x27; for them to be valid</li>
<li>this will make sure that the SVM optimizations run correctly to convergence</li>
<li>other kernels are
<ul>
<li>polynomial kernel: (x&#x27;   - l  + c)^d. Performs worse than gaussian kernel</li>
<li>string kernel</li>
<li>chi-square kernel</li>
<li>histogram intersection kernel</li>
</ul>
</li>
</ul>
</li>
<li>multi-class classification
<ul>
<li>one vs all method</li>
<li>some SVMs have multi-class classification built-in</li>
</ul>
</li>
<li>logistic regression vs SVMs
<ul>
<li>n = number of features, m = number of training samples</li>
<li>if n is large compared to m, use logistic regression or linear kernel SVMs</li>
<li>if n is small and m is intermediate, use gaussian kernel SVMs</li>
<li>if n is small and m is large, create more features and then use logistic regression or linear kernel SVMs</li>
</ul>
</li>
<li>neural nets will work well for all these cases, but for some of these problems, these nets can be slower to train</li>
<li>SVM optimization is a convex optimization problem</li>
</ul>
<h3>Week8</h3>
<ul>
<li>unsupervised learning
<ul>
<li>work with unlabelled data</li>
<li>ask it to find some structure in the data</li>
</ul>
</li>
<li>k-means algo
<ul>
<li>most popular algo</li>
<li>randomly initialize &#x27;k&#x27; cluster centroids</li>
<li>cluster assignment - depending upon the distance, datapoints are assigned to these centroids</li>
<li>centroids evaluation - move centroids to the average of these newly assigned clusters</li>
<li>repeat until convergence/max-iterations</li>
</ul>
</li>
<li>optimization objective
<ul>
<li>J = 1/m   - sum(||xi - uci||^2)</li>
<li>m = dataset size</li>
<li>uci = cluster centroid to which xi is assigned</li>
</ul>
</li>
<li>cluster centroid initialization
<ul>
<li>random works ok, but not good</li>
<li>randomly pick K training examples and set centroids to these
<ul>
<li>this can avoid getting stuck at local optimum</li>
</ul>
</li>
</ul>
</li>
<li>one better approach to avoid local optima
<ul>
<li>run K-means with random initializations and repeat this multiple times</li>
<li>[50,1000] times is a good number</li>
<li>pick the output of that initialization with results in the lowest cost function</li>
<li>this can work for K=[2,10], for higher values of K, you might not need this</li>
</ul>
</li>
<li>how to choose K?
<ul>
<li>by far the best way to do is choose it manually!</li>
<li>one other method is &#x27;elbow method&#x27;
<ul>
<li>basically pick that value of K which results in an &#x27;elbow&#x27; in the plot of cost function vs K</li>
<li>but sometimes, if there are no elbows, this becomes ambiguous!</li>
</ul>
</li>
<li>evaluate K-means using on another metric based on its application</li>
</ul>
</li>
<li>dimensionality reduction
<ul>
<li>in case we have highly correlated features, we dont need all of them</li>
<li>used for data compression too</li>
<li>it is also used to visualize data (specifically for input data in many ML applications)</li>
</ul>
</li>
<li>Principal Component Analysis - PCA
<ul>
<li>tries to find a direction (vectors) on which to project the data which reduces the projection error</li>
<li>PCA is not linear regression!
<ul>
<li>we try to minimize squared error in linear regression</li>
<li>we try to minimize projection error in PCA</li>
</ul>
</li>
<li>Step1: data preprocessing or feature-scaling or mean normalization
<ul>
<li>perform x[i] = (x[i] - u[i]), where u[i] is mean over all x[i]&#x27;s</li>
<li>if different features are on different scales, scale them to be on similar ranges</li>
</ul>
</li>
<li>Step2: calculate covariance matrix</li>
<li>Step3: compute eigen vectors of this matrix (using &#x27;svd&#x27;)</li>
<li>Step4: if you take the first &#x27;k&#x27; columns of the output U matrix from svd, you&#x27;ve got k vectors on which to project the data</li>
<li>Step5: to reduce dim of input data, perform: z = Ured&#x27;   - X</li>
</ul>
</li>
<li>choosing &#x27;k&#x27; for PCA
<ul>
<li>typically choose &#x27;k&#x27; to be the smallest value such that
<ul>
<li>sum(|| x[i] - xapprox[i] ||^2) /  sum(|| x[i] ||^2)  &lt;= 0.01</li>
<li>ie, 99% of the data variance is retained</li>
<li>&#x27;S&#x27; diagonal matrix given as output by &#x27;svd&#x27; can be used for this</li>
<li>1 - sum_to_k(S[i][i]) / sum_to_n(S[i][i]). This is the same as above!</li>
</ul>
</li>
</ul>
</li>
<li>reconstructing the original data: Xapprox = Ured   - z</li>
<li>applying PCA
<ul>
<li>used to speedup supervised learning problem. But always make sure that you&#x27;ve tried the learning problem without PCA too!</li>
<li>but the Ureduce should be calculated using only the training set</li>
<li>then apply the mapping on all of training/cv/test sets</li>
<li>PCA should not be used to address overfitting. Use regularization instead!</li>
</ul>
</li>
</ul>
<h3>Week9</h3>
<ul>
<li>anamoly detection
<ul>
<li>somewhat like unsupervised learning</li>
<li>perform density estimation and build a model &#x27;p&#x27; based on the input feature vectors</li>
<li>now for the test case, if p(x) &lt; eps, then flag it as an anamoly</li>
<li>eg: fraud detection, manufacturing</li>
</ul>
</li>
<li>gaussian distribution (normal distribution)
<ul>
<li>p(x) = exp(-(x-u)/2<em>sigma</em>sigma)/sqrt(2<em>pi</em>sigma*sigma)</li>
<li>parameter estimation
<ul>
<li>u = mean(x)</li>
<li>sigma^2 = variance(x)</li>
</ul>
</li>
</ul>
</li>
<li>density estimation
<ul>
<li>p(x) = prod(p(xi))   for each element xi in the feature vector x</li>
<li>each p(xi) is a gaussian distribution</li>
<li>this assumes that each element xi are independent of each other</li>
<li>then use the above gaussian parameter estimation equation on all the feature elements</li>
<li>now to detect anamoly, apply the above density equation using a &#x27;eps&#x27; value to flag the output as anamoly or not</li>
</ul>
</li>
<li>it is always better to have a way to evaluate the learning algorithm
<ul>
<li>becomes easy to fine-tune hyper-parameters</li>
</ul>
</li>
<li>evaluation
<ul>
<li>lets assume now that these examples are labelled as anamolous and non-anamolous</li>
<li>split this into training/cross-validation/test sets, as usual</li>
<li>typically there are no anamolous examples kept in the training set!</li>
<li>then perform density estimation on the training set</li>
<li>predict its performance on cv and test sets
<ul>
<li>can use f1-score, precision/recall, ...</li>
<li>because the data set is very skewed</li>
</ul>
</li>
<li>use cv set to estimate a good value for &#x27;eps&#x27;</li>
</ul>
</li>
<li>choosing features
<ul>
<li>try plotting the histogram of data to confirm whether it could fit a bell-shaped curve or not</li>
<li>if it doesn&#x27;t fit gaussian, try using other distributions</li>
<li>try to see if &#x27;log&#x27; can convert this into gaussian, or any other transformations</li>
<li>use cv set extensively to choose features</li>
</ul>
</li>
<li>multi-variate gaussian
<ul>
<li>in case we have features related to each other, then the previous gaussian approach might miss some anamolies</li>
<li>u = mean vector of all features, cov = covariance matrix</li>
<li>p(x) = exp(-(x-u)&#x27;   - cov^-1   - (x-u) / 2) / ((2   - pi)^(n/2)   - sqrt(det(cov)))</li>
<li>u = mean(x)</li>
<li>cov = mean((x-u)*(x-u)&#x27;)</li>
</ul>
</li>
<li>recommender systems:
<ul>
<li>nu = number of users</li>
<li>nm = number of items to be rated</li>
<li>y(i,j) = rating by user j to item i</li>
<li>predict ratings for all items and recommend items to the users</li>
</ul>
</li>
<li>content based recommendations (CBR)
<ul>
<li>assume certain features for the items</li>
<li>use linear regression on each user to predict his rating</li>
<li>can also apply regularization while learning these params</li>
</ul>
</li>
<li>collaborative filtering (CF)
<ul>
<li>its hard to get features for all the items!</li>
<li>this approach can self-learn these features!</li>
<li>but now lets say that each user has given us how much they like each of these features</li>
<li>so using these preferences for each user as params, we can learn the features for each items!</li>
<li>for each item, repeat this process</li>
<li>one can also apply regularization here (not on the params, but now on the features!)</li>
<li>initially guess the theta values, then using CF, estimate x&#x27;s.</li>
<li>then, using CBR, get better values for theta.</li>
</ul>
</li>
<li>CF algo
<ul>
<li>we don&#x27;t need to go back and forth between theta and x</li>
<li>we could just put both optimizations in a single equation and optimize for both simultaneously</li>
<li>however, there&#x27;s no intercept term used here</li>
</ul>
</li>
<li>vectorization
<ul>
<li>low rank matrix factorization</li>
<li>predict user ratings using: X*Theta&#x27;</li>
</ul>
</li>
<li>using these learned features/params, we can also find related items (just measure feature vector distance between the 2 items)</li>
<li>mean normalization
<ul>
<li>what if a user has not rated any items?!</li>
<li>this leads to params/features to converge to zero</li>
<li>in this case, calculate the mean rating for each row (item)</li>
<li>subtract this mean from every element in the Y matrix</li>
<li>then while predicting the rating, add back the mean</li>
<li>so for this user, we&#x27;ll predict his rating to be mean for each item!</li>
<li>same thing applies to items which might not have any ratings (but better to not recommend it since it has no ratings!)</li>
</ul>
</li>
</ul>
<h3>Week10</h3>
<ul>
<li>its not who has the best algo that wins, it&#x27;s who has the most data</li>
<li>with large datasets, we can&#x27;t update the params using the gradient descent, because &#x27;m&#x27; is too large! computationally inhibitive!</li>
<li>SGD: Stochastic Gradient Descent
<ul>
<li>GD (or BGD = Batch Gradient Descent) becomes very expensive for large datasets</li>
<li>SGD works as follows:
<ul>
<li>randomly shuffle the dataset</li>
<li>perform the params update stage, one sample at a time! (as opposed to BGD)</li>
</ul>
</li>
<li>but it performs somewhat like a random walk in the &#x27;J&#x27; space</li>
</ul>
</li>
<li>Mini BGD
<ul>
<li>sometimes can be even faster than SGD</li>
<li>it basically uses &#x27;b&#x27; examples in each iteration to update params</li>
<li>b = batch size</li>
<li>in-between BGD and SGD</li>
<li>MBGD helps in vectorizing the training wrt SGD, thus can be faster (more parallel stuff to do!)</li>
</ul>
</li>
<li>checking for SGD convergence:
<ul>
<li>for every P iterations, calculate the average &#x27;cost&#x27; of all the previous P examples</li>
<li>plot the same</li>
<li>but the plot can be a bit noisy compared to GD</li>
<li>increasing P can give smoother curve, but after longer duration</li>
<li>can also decrease alpha over epochs to make theta converge</li>
</ul>
</li>
<li>online learning
<ul>
<li>learning on a stream of data</li>
<li>one way is to apply SGD on the current data to learn the params</li>
<li>estimate predicted CTR (Click Through Rate)</li>
</ul>
</li>
<li>map-reduce and data parallelism
<ul>
<li>can be used to split training session on machines</li>
</ul>
</li>
<li>ML pipeline:
<ul>
<li>image -&gt; object detection -&gt; object segmentation -&gt; object recognition</li>
<li>to detect, create a rectangle BB (bounding box) and slide it across the image to detect the object and using a classifier</li>
<li>slide speed on the image is decided by the stride across vertical and horizontal directions</li>
<li>can also apply expansion operator in the output image</li>
<li>then use connected components and draw BB</li>
</ul>
</li>
<li>data augmentation
<ul>
<li>creating artificial data</li>
<li>put artificial distortions (or warping)</li>
<li>change contrast, color, rotate the image, crop the image</li>
<li>adding noise (especially audio)</li>
<li>but does NOT help to add meaningless noise to the data!</li>
</ul>
</li>
<li>ceiling analysis
<ul>
<li>deciding what part of pipeline to work on next</li>
<li>first create a measure of performance (accuracy, cost, ...)</li>
<li>in the pipeline, replace each stage and manually pass the &#x27;correct&#x27; inputs to its next stage.</li>
<li>this way measure the performance of the system</li>
<li>this will tell us which part of pipeline is lagging behind, and we can spend more effort there.</li>
</ul>
</li>
</ul>

  </div>
  <a class="u-url" href="/blog/_posts/2018-01-15-machine-learning.html" hidden></a>
</article>
      </div>
    </main>
    <footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>
  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-3">
        <p>Stuff I find cool/useful</p>
      </div>
    </div>
  </div>
</footer>
  </body>
</html>