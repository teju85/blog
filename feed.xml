<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="https://teju85.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://teju85.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-06-15T23:42:10+05:30</updated><id>https://teju85.github.io/blog/feed.xml</id><title type="html">Quagmire</title><subtitle>Stuff I find cool/useful</subtitle><entry><title type="html">A comprehensive survey on Graph Neural Networks</title><link href="https://teju85.github.io/blog/2020/06/14/survey-of-gnns.html" rel="alternate" type="text/html" title="A comprehensive survey on Graph Neural Networks" /><published>2020-06-14T00:00:00+05:30</published><updated>2020-06-14T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/14/survey-of-gnns</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/14/survey-of-gnns.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main survey paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1901.00596.pdf&quot;&gt;here&lt;/a&gt;.
Divides GNNs into the following top-level four categories:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;recurrent GNNs - iteratively exchange info with neighbors until some form of
convergence is achieved. This idea is borrowed and improved by convGNNs.&lt;/li&gt;
  &lt;li&gt;convolutional GNNs - same as recGNNs, but here multiple such operations are
stacked to extract high-level node representations based on neighbors that
are further away.&lt;/li&gt;
  &lt;li&gt;graph autoencoders - unsupervised methods to represent graphs by latent
vectors and then use a decoder phase to reconstruct the graph&lt;/li&gt;
  &lt;li&gt;spatio-temporal GNNs - combine convGNNs and then regular 1D-CNNs to capture
both spatial and temporal info of the nodes, respectively&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;differences-wrt-regular-dl&quot;&gt;Differences wrt regular DL&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;data space is non-Euclidean&lt;/li&gt;
  &lt;li&gt;graphs can be irregular&lt;/li&gt;
  &lt;li&gt;number of neighbors vary, causing difficulty with regular convolutions&lt;/li&gt;
  &lt;li&gt;instance (aka node) is not independent of the other&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;differences-wrt-network-embedding&quot;&gt;Differences wrt network embedding&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;NE involves other non-DL methods like factorization, random-walks&lt;/li&gt;
  &lt;li&gt;GNNs provide and end-to-end solution for some of the graph-related tasks&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;recgnns&quot;&gt;recGNNs&lt;/h3&gt;
&lt;p&gt;Perform message passing between nodes and their neighbors, until some form of
convergence is achieved.
&lt;script type=&quot;math/tex&quot;&gt;h_v^{(t)} = \sum_{u \epsilon N(v)} f(X_v, x_{u,v}^e, x_u, h_u^{(t-1)})&lt;/script&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;h_v&lt;/script&gt; = hidden vector which is initialized to random value at time = 0&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f(.)&lt;/script&gt; = a contraction mapping parametric function to ensure convergence&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; = node feature matrix&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; = edge feature matrix&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;N(v)&lt;/script&gt; = neighborhood of node &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;n = number of nodes&lt;/li&gt;
  &lt;li&gt;m = number of edges&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Gated GNNs - use GRU with fixed number of recurrence steps, instead of a
generic contraction mapping function. Then uses BPTT (backprop through time)
in order to learn parameters.
&lt;script type=&quot;math/tex&quot;&gt;h_v^{(t)} = GRU(h_v^{(t-1)}, \sum_{u \epsilon N(v)} W h_u^{(t-1)}&lt;/script&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^{(0)} = x_v&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;convgnns&quot;&gt;convGNNs&lt;/h3&gt;

&lt;h4 id=&quot;spectral-based&quot;&gt;spectral based&lt;/h4&gt;
&lt;p&gt;Based on graph signal processing and use normalized graph laplacian
&lt;script type=&quot;math/tex&quot;&gt;L = I - D^{-0.5} A D^{-0.5}&lt;/script&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt; = diagonal matrix with &lt;script type=&quot;math/tex&quot;&gt;D_{ii} = \sum_j A_{ij}&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; is real symmetric and positive semidefinite. So, it can be factored into
&lt;script type=&quot;math/tex&quot;&gt;L = U \Lambda U^T&lt;/script&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; = columwise eigenvectors ordered by eigenvalues&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\Lambda&lt;/script&gt; = diagonal matrix of eigenvalues&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Graph fourier transform on input &lt;script type=&quot;math/tex&quot;&gt;x \epsilon R^n&lt;/script&gt; is defined as &lt;script type=&quot;math/tex&quot;&gt;y = U^T x&lt;/script&gt;
similarly vice-versa for graph inverse fourier transform.&lt;/p&gt;

&lt;p&gt;Assuming a filter &lt;script type=&quot;math/tex&quot;&gt;g \epsilon R^n&lt;/script&gt;, convolution operation will become
&lt;script type=&quot;math/tex&quot;&gt;x*g = U (U^T x \odot U^T g) = U g_{\theta} U^T x&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;g_{\theta} = U^T g&lt;/script&gt;
All spectral methods follow this, except for their choice of &lt;script type=&quot;math/tex&quot;&gt;g_{\theta}&lt;/script&gt;.
Some methods are:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Spectral CNNs&lt;/li&gt;
  &lt;li&gt;Chebyshev spectral CNNs (ChebNet)&lt;/li&gt;
  &lt;li&gt;CayleyNet&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/2020/06/09/graph-convolutional-networks.html&quot;&gt;GCN&lt;/a&gt;
these are however a mix of spectral and spatial based by approximating
ChebNet at first-order and simplifying learnable parameters.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;spatial-based&quot;&gt;spatial based&lt;/h4&gt;
&lt;p&gt;All these methods aggregate neighbor information in some form and propagate this
to the current node. Multiple such layers are stacked upon each other to
increase the neighborhood definition.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Neural Network for Graphs: Somewhat resembles GCN.
&lt;script type=&quot;math/tex&quot;&gt;H^{(k)} = f(X W^{(k)} + \sum_{i=1}^{k - 1} A H^{(k-1)} \Theta^{(k)})&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Diffusion CNNs: &lt;script type=&quot;math/tex&quot;&gt;H^{(k)} = f(W^{(k)} \odot P^k X)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Diffusion Graph Convolution: &lt;script type=&quot;math/tex&quot;&gt;H = \sum_{k=0}^K f(p^k X W^{(k)})&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Message Passing NN&lt;/li&gt;
  &lt;li&gt;GraphSage: samples the neighbors in order to avoid needing full-batch&lt;/li&gt;
  &lt;li&gt;fast-GCN: samples a fixed number of nodes instead of neighbors&lt;/li&gt;
  &lt;li&gt;Graph Attention Network
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^{(k)} = \sigma(\sum_{u \epsilon N(v) \cup v} \alpha_{vu}^{(k)} W^{(k)} h_u^{(k-1)})&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^{(0)} = x_v&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_{vu}^{(k)} = softmax(leakyReLU(a^T [W^{(k)}h_v^{(k-1)} || W^{(k)}h_u^{(k-1)}]))&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;spectral-vs-spatial&quot;&gt;spectral vs spatial&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;spectral methods have theoretical framework&lt;/li&gt;
  &lt;li&gt;spatial methods are computationally efficient and scalable&lt;/li&gt;
  &lt;li&gt;spatial methods allow batching of nodes in a graph&lt;/li&gt;
  &lt;li&gt;spectral methods only work with undirected graphs&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;graph-pooling-modules&quot;&gt;graph pooling modules&lt;/h4&gt;
&lt;p&gt;coarsen the graph representation to reduce computationaly complexity for graph
classification and such other tasks next in the pipeline. Popular approach is to
use mean/max/sum based pooling functions:
&lt;script type=&quot;math/tex&quot;&gt;h_G = poolFunction(h_1^{(K)}, h_2^{(K)}, ..., h_n^{(K)})&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;graph-autoencoders&quot;&gt;Graph autoencoders&lt;/h3&gt;

&lt;h4 id=&quot;network-embedding&quot;&gt;network embedding&lt;/h4&gt;
&lt;p&gt;Low dimensional representation of nodes which preserves the topological info.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Graph AutoEncoder: uses GCN in encoder phase and decoder phase tries to
reconstruct the adjacency matrix based on the generated embedding&lt;/li&gt;
  &lt;li&gt;Variational GAE: Variational version of the above, using KL divergence as the
metric&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;graph-generation&quot;&gt;graph generation&lt;/h4&gt;
&lt;p&gt;Beneficial in solving molecular graph generation problem. There are methods
which try to generate graphs globally or sequentially.&lt;/p&gt;

&lt;h3 id=&quot;spatio-temporal-gnns&quot;&gt;spatio-temporal GNNs&lt;/h3&gt;
&lt;p&gt;Capture both spatial and temporal dependencies together. eg: traffic speed
forecasting. Most simple way is to feed the output of convGNNs into recurrent
layer like RNNs/LSTMs.&lt;/p&gt;

&lt;h3 id=&quot;future-directions&quot;&gt;future directions&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;model depth - going infinite depth will pull all nodes into a single point!
Does it make sense to increase depth?&lt;/li&gt;
  &lt;li&gt;scalability trade-off - use of clustering could destroy patterns, while
sampling the neighbors may miss critical info at times. Need to find a good
trade-off between scalability and info-loss&lt;/li&gt;
  &lt;li&gt;heterogeneous graphs support&lt;/li&gt;
  &lt;li&gt;dynamicity - STGNNs addresses some aspects of this.&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main survey paper can be found here. Divides GNNs into the following top-level four categories: recurrent GNNs - iteratively exchange info with neighbors until some form of convergence is achieved. This idea is borrowed and improved by convGNNs. convolutional GNNs - same as recGNNs, but here multiple such operations are stacked to extract high-level node representations based on neighbors that are further away. graph autoencoders - unsupervised methods to represent graphs by latent vectors and then use a decoder phase to reconstruct the graph spatio-temporal GNNs - combine convGNNs and then regular 1D-CNNs to capture both spatial and temporal info of the nodes, respectively</summary></entry><entry><title type="html">cmus installation and usage on cygwin</title><link href="https://teju85.github.io/blog/2020/06/13/cmus-on-cygwin.html" rel="alternate" type="text/html" title="cmus installation and usage on cygwin" /><published>2020-06-13T00:00:00+05:30</published><updated>2020-06-13T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/13/cmus-on-cygwin</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/13/cmus-on-cygwin.html">&lt;h3 id=&quot;cmus&quot;&gt;cmus&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://cmus.github.io/&quot;&gt;cmus&lt;/a&gt; is a lightweight console player for unix-like
operating systems. Given here are the steps to build it on cygwin.&lt;/p&gt;

&lt;h4 id=&quot;steps&quot;&gt;Steps&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lynx -source rawgit.com/transcode-open/apt-cyg/master/apt-cyg &amp;gt; apt-cyg
install apt-cyg /bin
apt-cyg install ncurses ncursesw pkg-config
apt-cyg install libncursesw-devel libncurses-devel
apt-cyg install libopus-devel libwavpack-devel
apt-cyg install libtool flac-devel

cd ~
wget ftp://ftp.mars.org/pub/mpeg/libmad-0.15.1b.tar.gz
tar xf
cd libmad-0.15.1b
wget 'http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.guess;hb=HEAD' -O config.guess
wget 'http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.sub;hb=HEAD' -O config.sub
sed -i '/-fforce-mem/d' configure
./configure
make
make install

cd ~
git clone https://github.com/cmus/cmus.git
cd cmus
./configure CPPFLAGS=-I/usr/local/include LDFLAGS=-L/usr/local/lib
make
make install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;key-controls&quot;&gt;Key controls&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;v: stop playback&lt;/li&gt;
  &lt;li&gt;b: next track&lt;/li&gt;
  &lt;li&gt;z: previous track&lt;/li&gt;
  &lt;li&gt;c: pause playback&lt;/li&gt;
  &lt;li&gt;s: toggle shuffle (read about the m key below if you’re going to use shuffle)&lt;/li&gt;
  &lt;li&gt;m: toggles the “aaa mode.”&lt;/li&gt;
  &lt;li&gt;x: restart track&lt;/li&gt;
  &lt;li&gt;i: jump view to the currently playing track (handy when in shuffle mode)&lt;/li&gt;
  &lt;li&gt;o: toggle sorting&lt;/li&gt;
  &lt;li&gt;/: searching cmus works as in many Unix programs.
    &lt;ul&gt;
      &lt;li&gt;Typing slash, a string, and enter will find the first instance of that
string in your library.&lt;/li&gt;
      &lt;li&gt;Press n to go to the next string, N to go to the previous.&lt;/li&gt;
      &lt;li&gt;cmus’s search isn’t case sensitive and is quite smart; a search for damned
insurrection will return Bulldozer’s “Insurrection of the Living Damned”
(rad tune).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;-: reduce the volume by 10%&lt;/li&gt;
  &lt;li&gt;+: increase the volume by 10%&lt;/li&gt;
  &lt;li&gt;:add path  - to add a playlist&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tools" /><summary type="html">cmus cmus is a lightweight console player for unix-like operating systems. Given here are the steps to build it on cygwin.</summary></entry><entry><title type="html">Pixie</title><link href="https://teju85.github.io/blog/2020/06/12/pixie.html" rel="alternate" type="text/html" title="Pixie" /><published>2020-06-12T00:00:00+05:30</published><updated>2020-06-12T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/12/pixie</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/12/pixie.html">&lt;h3 id=&quot;pixie-a-system-for-recommending-3-billion-items-to200-million-users-in-real-time&quot;&gt;Pixie: A System for Recommending 3+ Billion Items to200+ Million Users in Real-Time&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1711.07601.pdf&quot;&gt;here&lt;/a&gt; and a more
digestable version is presented in a blog format &lt;a href=&quot;https://medium.com/pinterest-engineering/introducing-pixie-an-advanced-graph-based-recommendation-system-e7b4229b664b&quot;&gt;here&lt;/a&gt;
and &lt;a href=&quot;https://medium.com/pinterest-engineering/an-update-on-pixie-pinterests-recommendation-system-6f273f737e1b&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;proposal&quot;&gt;Proposal&lt;/h4&gt;
&lt;p&gt;Provide real-time recommendations to the users via:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Pixie random walk algorithm to generate recommendations whose runtime is
constant wrt the size of the input graph.&lt;/li&gt;
  &lt;li&gt;description of the implementation (in production) based on C++ on top of
&lt;a href=&quot;http://snap.stanford.edu/&quot;&gt;SNAP&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;details&quot;&gt;Details&lt;/h4&gt;
&lt;p&gt;Input to this system is a query set &lt;script type=&quot;math/tex&quot;&gt;Q = {(q, w_q)}&lt;/script&gt;, which is a collection of
pins with associated weights to represent its importance in current query set.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pixie random walk&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;Biased walks&lt;/em&gt;: walks are biased for a query set &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt; based on the user. This
helps provide personalized recommendations.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;multiple query pins with weights&lt;/em&gt;: weights to the input query pins are
assigned based on the time since the user interacted with this pin and the
interaction type.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;sample walk length&lt;/em&gt;: helps provide enough walks for pins with lower degree
but also reduces runtime cost for pins with higher degree.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;multi-hit booster&lt;/em&gt;: weightage given to the candidate pins which have high
visit counts for all the pins in the &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt;. &lt;script type=&quot;math/tex&quot;&gt;V[p] = (\sum_{q \epsilon Q}\sqrt{V_q[p]})^2&lt;/script&gt;
where &lt;script type=&quot;math/tex&quot;&gt;V_q&lt;/script&gt; is visit count for the query &lt;script type=&quot;math/tex&quot;&gt;q \epsilon Q&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;early stopping&lt;/em&gt;: stop the random walk when the top visited candidates have
crossed certain threshold.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Computation of walk length for a given pin is as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s_q = \|E(q)\|.(C - log\|E(q)\|)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Nq = N w_q \frac{s_q}{\sum_{r \epsilon Q} s_r}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;Nq&lt;/script&gt; = walk length for random walk starting from pin q&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\|E(q)\|&lt;/script&gt; = degree of pin q&lt;/li&gt;
  &lt;li&gt;C = max degree of all pins&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Algorithm for a single query is as follows:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PixieRandomWalk(q, E, U, alpha, Nq, nv, np):
  totSteps = nHighVisited = 0
  V = {0}
  do
    currPin = q
    currSteps = SampleWalkLength(alpha)
    for i in range(currSteps):
      currBoard = E(currPin)[PersonalizedNeighbor(E, U)]
      currPin = E(currBoard)[PersonalizedNeighbor(E, U)]
      V[currPin]++
      if V[currPin] == nv:
        nHighVisited++
    totSteps += currSteps
  while totSteps &amp;lt; Nq and nHighVisited &amp;lt; np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;q = query pin&lt;/li&gt;
  &lt;li&gt;E = edges in the graph&lt;/li&gt;
  &lt;li&gt;U = user features&lt;/li&gt;
  &lt;li&gt;alpha = helps determine the number of steps per random walk&lt;/li&gt;
  &lt;li&gt;PersonalizedNeighbor(E, U) = randomized method to return neighbors, but
edges being weighted by user features&lt;/li&gt;
  &lt;li&gt;Nq = total number of steps taken in the random walk&lt;/li&gt;
  &lt;li&gt;nv and np = used for early stopping. the random walk is terminated when there
are np number of pins that have been visited atleast nv number of times&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;graph pruning&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Prunes the graph to fit in RAM and thus do not have to distribute it.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Removes duplicate pins&lt;/li&gt;
  &lt;li&gt;Removes pins assigned to incorrect boards&lt;/li&gt;
  &lt;li&gt;Removes boards with larger entropy: computes LDA on each pin description and
computes entropy for a board by combining LDA vectors from all pins associated
with this board.&lt;/li&gt;
  &lt;li&gt;Prune the degree (or remove) pins with abnormally high degree: only keep the
edges with highest cosine similarity. Threshold is determined by the pruning
factor &lt;script type=&quot;math/tex&quot;&gt;\delta&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><summary type="html">Pixie: A System for Recommending 3+ Billion Items to200+ Million Users in Real-Time Main paper can be found here and a more digestable version is presented in a blog format here and here.</summary></entry><entry><title type="html">PinSage</title><link href="https://teju85.github.io/blog/2020/06/10/pinsage.html" rel="alternate" type="text/html" title="PinSage" /><published>2020-06-10T00:00:00+05:30</published><updated>2020-06-10T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/10/pinsage</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/10/pinsage.html">&lt;h3 id=&quot;pinsage---graph-convolutional-neural-networks-for-web-scalerecommender-systems&quot;&gt;PinSage - Graph Convolutional Neural Networks for Web-ScaleRecommender Systems&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1806.01973.pdf&quot;&gt;here&lt;/a&gt; and a more
digestable version is presented in a blog format &lt;a href=&quot;https://medium.com/pinterest-engineering/pinsage-a-new-graph-convolutional-neural-network-for-web-scale-recommender-systems-88795a107f48&quot;&gt;here&lt;/a&gt;.
A scalable random-walk GCN to learn embeddings on attribute graphs with billions
of nodes. They demonstrate this on Pinterest’s data with billions of nodes and
tens of billions of edges. They also present an efficient way to do inferencing
on the resulting model via MapReduce paradigm.&lt;/p&gt;

&lt;h4 id=&quot;proposal&quot;&gt;Proposal&lt;/h4&gt;
&lt;p&gt;For improving scalability:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;on-the-fly convolutions: sampling the neighborhood to dynamically construct
the computation graph&lt;/li&gt;
  &lt;li&gt;producer-consumer minibatch construction: CPU producing minibatches via
efficiently sampling the neighborhood GPU performs SGD.&lt;/li&gt;
  &lt;li&gt;efficient MapReduce based inference
For improving accuracy:&lt;/li&gt;
  &lt;li&gt;constructing convs via random walks: sampling of neighbors is done via random
walks on the graph. This also helps provide weightage during aggregation.&lt;/li&gt;
  &lt;li&gt;importance pooling - same as above&lt;/li&gt;
  &lt;li&gt;Curriculum training&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;details&quot;&gt;Details&lt;/h4&gt;
&lt;p&gt;Current GCNs expect the availability of full graph Laplacian during training.
This is very infeasible for web-scale graphs with billions of nodes and edges.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Inputs&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;G = Graph in CSR representation&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;x_u&lt;/script&gt; = node features for each &lt;script type=&quot;math/tex&quot;&gt;u \epsilon G&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;d = dimensionality of the features. This is also the dimensionality of the
output of each layer.&lt;/li&gt;
  &lt;li&gt;L = labelled pairs &lt;script type=&quot;math/tex&quot;&gt;(q, i)&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; represents a good recommendation
if the input query is &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Hyper-params&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;m = dimensionality of the output vector of the aggregation step. This is
assumed to be the same value across all layers&lt;/li&gt;
  &lt;li&gt;K = number of layers&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\Delta&lt;/script&gt; = max-margin used in the loss function&lt;/li&gt;
  &lt;li&gt;B = batch size&lt;/li&gt;
  &lt;li&gt;T = max number of neighbors to be sampled for any node&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;Q^k&lt;/script&gt; = neighborhood feature transformation matrix for &lt;script type=&quot;math/tex&quot;&gt;convolve_k&lt;/script&gt; at kth
layer of the network. Dim = m x d&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;q^k&lt;/script&gt; = bias vector for this operation at kth layer. Length = m&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;W^k&lt;/script&gt; = feature transformation matrix after aggregation at kth layer.
Dim = d x (d + m)&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;w^k&lt;/script&gt; = bias vector for this operation at kth layer. Length = d&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;G_1&lt;/script&gt; = 1st feature transformation matrix at final layer. Dim = d x d&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;g&lt;/script&gt; = bias vector for this operation. Length = d&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;G_2&lt;/script&gt; = 2nd feature transformation at final layer. Dim = d x d&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Local convolutions algorithm at kth layer&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;n_u = \gamma(relu(Q^k h_v^k + q^k), \alpha) | v \epsilon N(u)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m_u = concat(h_u^k, n_u)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_u^{k+1} = relu(W^k m_u + w^k)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_u^{k+1} = \frac{h_u^{k+1}}{||h_u^{k+1}||_2}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt; = set of neighbor weights computed based on random-walk. These are
computed as &lt;script type=&quot;math/tex&quot;&gt;L_1&lt;/script&gt; norm of visit counts of each node during random-walk.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\gamma&lt;/script&gt; = aggregation function. Assumed to be weighted-mean&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;N(u)&lt;/script&gt; = sampled neighborhood for node u&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;minibatch preparation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Happens on CPU for the next batch while current batch is running on GPU. Uses
openmp for parallelization.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Model propagation&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Compute the neighbors for each layer starting from the topmost K-th layer&lt;/li&gt;
  &lt;li&gt;Compute the K-layers of convolve operation&lt;/li&gt;
  &lt;li&gt;Finally apply &lt;script type=&quot;math/tex&quot;&gt;G_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;G_2&lt;/script&gt; transformations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Loss function&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Max-margin ranking loss. Dot product of the embeddings of negative samples is
atleast &lt;script type=&quot;math/tex&quot;&gt;\Delta&lt;/script&gt; distance lesser than that of &lt;script type=&quot;math/tex&quot;&gt;(q, i)&lt;/script&gt;. In other words:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;loss(q, i) = max(0, z_q . z_{n_k} - z_q . z_i + \Delta)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;n_k&lt;/script&gt; = negative sample for query &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;training&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Multi-GPU training. Each GPU gets equal amount from the minibatch. Standard
synchronous SGD is used with the following learning rate policy:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;At first epoch, learning rate is linearly increased from a small value to the
peak value.&lt;/li&gt;
  &lt;li&gt;At subsequent epochs, learning rate is exponentially decayed.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;negative sampling&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Each positive training example &lt;script type=&quot;math/tex&quot;&gt;(q, i)&lt;/script&gt; contains multiple “hard” negative
samples too. These hard negative samples are generated via personalized
pagerank scores. To reduce the number of epochs, curriculum training is being
used. At n-th epoch, n - 1 hard negative samples are added for each positive
training sample.&lt;/p&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">PinSage - Graph Convolutional Neural Networks for Web-ScaleRecommender Systems Main paper can be found here and a more digestable version is presented in a blog format here. A scalable random-walk GCN to learn embeddings on attribute graphs with billions of nodes. They demonstrate this on Pinterest’s data with billions of nodes and tens of billions of edges. They also present an efficient way to do inferencing on the resulting model via MapReduce paradigm.</summary></entry><entry><title type="html">Power of GCNs</title><link href="https://teju85.github.io/blog/2020/06/09/power-of-GCNs.html" rel="alternate" type="text/html" title="Power of GCNs" /><published>2020-06-09T00:00:00+05:30</published><updated>2020-06-09T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/09/power-of-GCNs</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/09/power-of-GCNs.html">&lt;h3 id=&quot;power-of-gcns&quot;&gt;Power of GCNs&lt;/h3&gt;
&lt;p&gt;Summary of the content of the blog found &lt;a href=&quot;https://www.inference.vc/how-powerful-are-graph-convolutions-review-of-kipf-welling-2016-2/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Author seems to claim that due to 1st order approximation of Chebyshev polynomials
as the convolution filter, their expressive power might not be good&lt;/li&gt;
  &lt;li&gt;that’s because this approximation, when applied to the special case of regular
graphs (2D images, eg), will lead to severely weak models&lt;/li&gt;
  &lt;li&gt;But the &lt;a href=&quot;https://tkipf.github.io/graph-convolutional-networks&quot;&gt;main authors of the GCN&lt;/a&gt;
paper also note that the Weisfeiler-Lehman algo also doesn’t converge on
regular graphs!&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Power of GCNs Summary of the content of the blog found here.</summary></entry><entry><title type="html">LightGCN</title><link href="https://teju85.github.io/blog/2020/06/09/lightgcn.html" rel="alternate" type="text/html" title="LightGCN" /><published>2020-06-09T00:00:00+05:30</published><updated>2020-06-09T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/09/lightgcn</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/09/lightgcn.html">&lt;h3 id=&quot;lightgcn---simplifying-and-powering-graph-convolutionnetwork-for-recommendation&quot;&gt;LightGCN - Simplifying and Powering Graph ConvolutionNetwork for Recommendation&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/2002.02126.pdf&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;proposal&quot;&gt;Proposal&lt;/h4&gt;
&lt;p&gt;For collaborative filtering, instead of using full GCNs they only keep the
neighborhood aggregation function and discard feature transformation and the
non-linear activation functions, thereby gaining better final accuracy as well
as simplifying the implementation.&lt;/p&gt;

&lt;h4 id=&quot;details&quot;&gt;Details&lt;/h4&gt;
&lt;p&gt;GCN was originally proposed for classification on rich attributes graph. However
in the case of CF, there are only user-item interaction graphs. They emperically
find that the NGCF’s (Neural Graph Collaborative Filtering, inspired from GCN)
feature transformation and non-linear functions cause accuracy degradation. They
also needlessly increase the complexity of the model. Thus, in LightGCN, they
propose to remove these 2 operations and only keep the neighborhood aggregation.
They create an ID embedding for each user and item and use the user-item
interaction graph to propagate the current embeddings.&lt;/p&gt;

&lt;p&gt;The core graph convolution operation that they are proposing is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_u^{k+1} = \sum_{i \epsilon N_u} \frac{1}{\sqrt{N_i N_u}} e_i^k&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_i^{k+1} = \sum_{i \epsilon N_i} \frac{1}{\sqrt{N_i N_u}} e_u^k&lt;/script&gt;

&lt;p&gt;Note that self-connections are ignored here! As this will be handled in the
final layer combination phase. Final representation (aka combination phase) is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_u = \sum_{k=0}^K \alpha_k e_u^k&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_i = \sum_{k=0}^K \alpha_k e_i^k&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\alpha_k&lt;/script&gt; can be hyper-params are model-params. In this paper, however, they
are setting them to be &lt;script type=&quot;math/tex&quot;&gt;\frac{1}{K+1}&lt;/script&gt; for simplicity.&lt;/p&gt;

&lt;p&gt;Final model prediction is: &lt;script type=&quot;math/tex&quot;&gt;y_{ui} = e_u^T * e_i&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Their code can be found:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/kuandeng/LightGCN&quot;&gt;here&lt;/a&gt; for TF&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/gusye1234/pytorch-light-gcn&quot;&gt;here&lt;/a&gt; for pytorch&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">LightGCN - Simplifying and Powering Graph ConvolutionNetwork for Recommendation Main paper can be found here</summary></entry><entry><title type="html">Graph Convolutional Networks</title><link href="https://teju85.github.io/blog/2020/06/09/graph-convolutional-networks.html" rel="alternate" type="text/html" title="Graph Convolutional Networks" /><published>2020-06-09T00:00:00+05:30</published><updated>2020-06-09T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/09/graph-convolutional-networks</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/09/graph-convolutional-networks.html">&lt;h3 id=&quot;graph-convolutional-networks&quot;&gt;Graph Convolutional Networks&lt;/h3&gt;
&lt;p&gt;Summary of the content of the blog found &lt;a href=&quot;https://tkipf.github.io/graph-convolutional-networks&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Inputs:
    &lt;ul&gt;
      &lt;li&gt;N = number of nodes&lt;/li&gt;
      &lt;li&gt;D = dimensionality of input feature vector for each node&lt;/li&gt;
      &lt;li&gt;A = adjacency matrix&lt;/li&gt;
      &lt;li&gt;L = number of layers&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;L_i&lt;/script&gt; = output features at each layer&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f_i&lt;/script&gt; = output activation at each layer&lt;/li&gt;
      &lt;li&gt;X = feature matrix [dim = N x D]&lt;/li&gt;
      &lt;li&gt;F = output feature vector dimension&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Weights
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;W_i&lt;/script&gt; = weight matrix at each layer [dim = &lt;script type=&quot;math/tex&quot;&gt;L_{i-1}&lt;/script&gt; x &lt;script type=&quot;math/tex&quot;&gt;L_i&lt;/script&gt;], with &lt;script type=&quot;math/tex&quot;&gt;L_0&lt;/script&gt; = D&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Outputs:
    &lt;ul&gt;
      &lt;li&gt;Z = transformed feature vector for each node [dim = N x F]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;L layers means that this network does “convolution” with neighbor nodes upto L hops from a given node&lt;/li&gt;
  &lt;li&gt;A’ = A + I, in order introduce self-loops&lt;/li&gt;
  &lt;li&gt;D = diagonal matrix of node degrees (very useful in normalizing the adjacency matrix)&lt;/li&gt;
  &lt;li&gt;each layer’s operation = &lt;script type=&quot;math/tex&quot;&gt;f_i(D^{-0.5} A' D^{-0.5} X_i W_i)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;author’s show forward prop on this network is generalized, differentiable version of Weisfeiler-Lehman algo!&lt;/li&gt;
  &lt;li&gt;code is on &lt;a href=&quot;https://github.com/tkipf/gcn&quot;&gt;github&lt;/a&gt;. Uses TF&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Graph Convolutional Networks Summary of the content of the blog found here.</summary></entry><entry><title type="html">Spartan Discipline</title><link href="https://teju85.github.io/blog/2020/05/28/spartan-discipline.html" rel="alternate" type="text/html" title="Spartan Discipline" /><published>2020-05-28T00:00:00+05:30</published><updated>2020-05-28T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/05/28/spartan-discipline</id><content type="html" xml:base="https://teju85.github.io/blog/2020/05/28/spartan-discipline.html">&lt;h3 id=&quot;spartan-discipline&quot;&gt;Spartan Discipline&lt;/h3&gt;
&lt;p&gt;By Dominic Mann. This book can be found &lt;a href=&quot;https://www.amazon.com/Spartan-Discipline-Unbreakable-Toughness-Relentless/dp/1539143066&quot;&gt;here&lt;/a&gt;.
Mann gives tips, tricks, suggestions and analogies from Spartan’s lifestyle
to illustrate how to develop self-discipline and be productive in our lives.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;full bellies never plough fields&lt;/li&gt;
  &lt;li&gt;choose delayed gratification over the instant one&lt;/li&gt;
  &lt;li&gt;accept minimalism as it allows to inculcate lazer sharp focus, by eliminating
distractions. For someone with no junk in kitchen shelf, eating healthy
becomes easier.&lt;/li&gt;
  &lt;li&gt;willpower is like muscle. More you exercise it, the stronger it becomes&lt;/li&gt;
  &lt;li&gt;your body can stand almost anything. It’s the mind that’s the bottleneck&lt;/li&gt;
  &lt;li&gt;Mind over matter!&lt;/li&gt;
  &lt;li&gt;a healthy mind and body can go a long way in developing self-discipline&lt;/li&gt;
  &lt;li&gt;external events are not under your control, but how you react to them is&lt;/li&gt;
  &lt;li&gt;start with the end in mind (what do you want people to say at your funeral)&lt;/li&gt;
  &lt;li&gt;conquering yourself is the first step to conquering the world.&lt;/li&gt;
  &lt;li&gt;use your emotions as a tool rather than becoming a tool for them.&lt;/li&gt;
  &lt;li&gt;Conquer your emotions, not the other way around!&lt;/li&gt;
  &lt;li&gt;there are 2 kinds of wants
    &lt;ul&gt;
      &lt;li&gt;wants of the body&lt;/li&gt;
      &lt;li&gt;wants of the mind&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;it is the wants of the mind that you truly want&lt;/li&gt;
  &lt;li&gt;go all the way in or don’t even start. Don’t give yourself any exceptions, or
else, those exceptions can become the norm.&lt;/li&gt;
  &lt;li&gt;to make big gains avoid tiny losses&lt;/li&gt;
  &lt;li&gt;it is through hardship, challenges and adversity that we grow in life&lt;/li&gt;
  &lt;li&gt;developing discipline in one key area of life also leads to being disciplined
in all areas of life. It’s called developing a “keystone habit”&lt;/li&gt;
  &lt;li&gt;Spartans used to not ask how enemies, but where they are. If you truly want to
do something, find a way to do it.&lt;/li&gt;
  &lt;li&gt;give your 100% in everything you do.&lt;/li&gt;
  &lt;li&gt;do one thing at a time, but with lazer sharp focus. Intensity beats extensity&lt;/li&gt;
  &lt;li&gt;you just only need enough willpower to get a habit in motion. Once habit takes
over, no willpower is required&lt;/li&gt;
  &lt;li&gt;we eventually get adjusted to new circumstances and get back to our normalcy.
So we’ll be just as happy with a disciplined life as we were if continued to
be lazy and comfortable&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="book-notes" /><category term="self-help" /><summary type="html">Spartan Discipline By Dominic Mann. This book can be found here. Mann gives tips, tricks, suggestions and analogies from Spartan’s lifestyle to illustrate how to develop self-discipline and be productive in our lives.</summary></entry><entry><title type="html">Using google Hangouts video call from android</title><link href="https://teju85.github.io/blog/2020/04/09/using-hangouts-video-call-android.html" rel="alternate" type="text/html" title="Using google Hangouts video call from android" /><published>2020-04-09T00:00:00+05:30</published><updated>2020-04-09T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/04/09/using-hangouts-video-call-android</id><content type="html" xml:base="https://teju85.github.io/blog/2020/04/09/using-hangouts-video-call-android.html">&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;This blog shows step-by-step process on using Google’s Hangouts apps to do video
calls from your android device.&lt;/p&gt;

&lt;h3 id=&quot;step-1-install-googles-hangouts-app-from-playstore&quot;&gt;Step 1. Install Google’s Hangouts app from playstore&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/google-hangouts-tutorial/01-install-google-hangouts.jpg&quot; alt=&quot;Install Google Hangouts app&quot; /&gt;
This is needed for you join the video call later.&lt;/p&gt;

&lt;h3 id=&quot;step-2-install-googles-hangouts-meet-app-from-playstore&quot;&gt;Step 2. Install Google’s Hangouts Meet app from playstore&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/google-hangouts-tutorial/02-install-google-hangouts-meet.jpg&quot; alt=&quot;Install Google Hangouts Meet app&quot; /&gt;
Note that both ‘Hangouts’ as well as ‘Hangouts Meet’ are required to
successfully join the video call!&lt;/p&gt;

&lt;h3 id=&quot;step-3-open-hangouts-meet-app&quot;&gt;Step 3. Open Hangouts Meet app&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/google-hangouts-tutorial/03-open-meet-app.jpg&quot; alt=&quot;Open Hangouts Meet app&quot; /&gt;
If you calendar has already been updated, an event will show up at the bottom.
Tap on the ‘Join’ button.&lt;/p&gt;

&lt;h3 id=&quot;step-4-join-the-video-call&quot;&gt;Step 4. Join the video call&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/google-hangouts-tutorial/04-join-the-video-call.jpg&quot; alt=&quot;Join video call&quot; /&gt;
The previous step will start the ‘Hangouts’ app. In here, tap on the
‘JOIN VIDEO CALL’ button at the bottom of your screen to join your video call.&lt;/p&gt;</content><author><name></name></author><category term="tutorial" /><summary type="html">Introduction This blog shows step-by-step process on using Google’s Hangouts apps to do video calls from your android device.</summary></entry><entry><title type="html">The Relaxation Response</title><link href="https://teju85.github.io/blog/2020/04/06/relaxation-response.html" rel="alternate" type="text/html" title="The Relaxation Response" /><published>2020-04-06T00:00:00+05:30</published><updated>2020-04-06T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/04/06/relaxation-response</id><content type="html" xml:base="https://teju85.github.io/blog/2020/04/06/relaxation-response.html">&lt;h3 id=&quot;the-relaxation-response&quot;&gt;The Relaxation Response&lt;/h3&gt;
&lt;p&gt;By Dr. Herbert Benson. This book can be found
&lt;a href=&quot;https://www.amazon.com/Relaxation-Response-Herbert-Benson/dp/0380006766&quot;&gt;here&lt;/a&gt;.
In this book, Dr. Benson writes about a response that is opposite to
“fight or flight” response, which is called relaxation response (RR). He lists
the benefits of this response and simple steps to elicit this response.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Field of medicine can be construed as a 3-legged sturdy stool
    &lt;ul&gt;
      &lt;li&gt;medications&lt;/li&gt;
      &lt;li&gt;surgery and similar medical procedures&lt;/li&gt;
      &lt;li&gt;self-care&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;belief is potentially central to our health&lt;/li&gt;
  &lt;li&gt;remembered wellness (aka placebo effect) also elicits RR&lt;/li&gt;
  &lt;li&gt;2 step process in the mind/body technique:
    &lt;ul&gt;
      &lt;li&gt;elicit RR to quiet the mind&lt;/li&gt;
      &lt;li&gt;after the mind has become quiet rewire the thoughts and actions in the
desired direction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;have a balanced approach to all 3 of the legs of this stool. When in doubt,
do consult your physician&lt;/li&gt;
  &lt;li&gt;technology instead of easing our lives has only resulted in more stress&lt;/li&gt;
  &lt;li&gt;we are frustrated that we can’t even solve simple problems like being on time,
due to congestion. Thus we become victims of stress.&lt;/li&gt;
  &lt;li&gt;stress not only affects us mentally, but also physically.
    &lt;ul&gt;
      &lt;li&gt;hypertension is currently a worldwide phenomenon as well as an epidemic.
        &lt;ul&gt;
          &lt;li&gt;It is caused by
            &lt;ul&gt;
              &lt;li&gt;bad diet&lt;/li&gt;
              &lt;li&gt;lack of exercise&lt;/li&gt;
              &lt;li&gt;family disposition&lt;/li&gt;
              &lt;li&gt;environmental stress&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;all animals respond to chronic stressful conditions via the
“fight or flight” response (needed for survival)&lt;/li&gt;
      &lt;li&gt;situations that demand we adjust our behavior elicit this response&lt;/li&gt;
      &lt;li&gt;this response involves increased BP, shallow breath, increased heart rate.&lt;/li&gt;
      &lt;li&gt;this response needs to be used, for eg, running away from or fighting with
the enemy. If it is not used, over periods of time, it can lead to
disastrous consequences, which is what is happening nowadays.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the opposite of “fight or flight” response is the RR
    &lt;ul&gt;
      &lt;li&gt;it reverses the adverse effects of “fight or flight” response&lt;/li&gt;
      &lt;li&gt;evoking RR is to be done via these steps
        &lt;ul&gt;
          &lt;li&gt;a quiet environment&lt;/li&gt;
          &lt;li&gt;a mental device (a word, phrase or mantra) that should be repeated. This
repetition helps avoid distracting thoughts&lt;/li&gt;
          &lt;li&gt;a passive attitude (by disregarding other thoughts and returning to the
mental device in case of any distraction). This is one of the key things
to elicit RR!&lt;/li&gt;
          &lt;li&gt;a comfortable position&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;the above process is also known as Transcendental Meditation, a refined yoga
practice developed by Maharishi Mahesh Yogi&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the risk of developing atherosclerosis is directly related to the BP as well
as cholesterol levels&lt;/li&gt;
  &lt;li&gt;HBP directly affects 3 organs: heart, brain and kidneys&lt;/li&gt;
  &lt;li&gt;events which require adjusting of our behavior cause stress in us. A stressful
person is more susceptible to diseases and having more BP&lt;/li&gt;
  &lt;li&gt;we simply cannot deal with the complexities the life throws at us. So, better
to learn effective ways to cope with those&lt;/li&gt;
  &lt;li&gt;it has been shown now that through voluntary mental acts, one can control the
“involuntary” bodily mechanisms like BP, heart-rate, oxygen consumption,
(aka metabolism) etc.&lt;/li&gt;
  &lt;li&gt;alpha waves are the brain waves which indicate the feeling of well-being&lt;/li&gt;
  &lt;li&gt;major physiologic change due to meditation is the decrease in metabolism
    &lt;ul&gt;
      &lt;li&gt;aka hypometabolism&lt;/li&gt;
      &lt;li&gt;only 3 things cause this: meditation, sleep or hibernation&lt;/li&gt;
      &lt;li&gt;hibernation is shows a drop in rectal temperatures, meditation doesn’t&lt;/li&gt;
      &lt;li&gt;sleep and meditation
        &lt;ul&gt;
          &lt;li&gt;in sleep metabolism decreases gradually until 4-5 hrs&lt;/li&gt;
          &lt;li&gt;in meditation it decreases rapidly in the first 2-3 mins&lt;/li&gt;
          &lt;li&gt;meditation increases alpha waves in brain&lt;/li&gt;
          &lt;li&gt;meditation decreases blood lactate content (associated with anxiety)&lt;/li&gt;
          &lt;li&gt;thus meditation and sleep can’t be substituted for one another!&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;altered state of consciousness
    &lt;ul&gt;
      &lt;li&gt;RR is associated with this state&lt;/li&gt;
      &lt;li&gt;it is one of the states in between coma -&amp;gt; sleep -&amp;gt; drowsiness -&amp;gt; alert -&amp;gt; hyper-alert&lt;/li&gt;
      &lt;li&gt;this state needs to be purposefully evoked&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;people going psychoanalysis sessions will find it hard to assume passive
attitude, thus difficult for them to elicit RR&lt;/li&gt;
  &lt;li&gt;excessive daily elicitation of RR can lead to hallucinations due to sensory
deprivation&lt;/li&gt;
  &lt;li&gt;within few weeks of stopping RR, our body typically goes back to its original
state, so better to be regular with this process&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="book-notes" /><category term="self-help" /><summary type="html">The Relaxation Response By Dr. Herbert Benson. This book can be found here. In this book, Dr. Benson writes about a response that is opposite to “fight or flight” response, which is called relaxation response (RR). He lists the benefits of this response and simple steps to elicit this response.</summary></entry></feed>