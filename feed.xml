<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="https://teju85.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://teju85.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-08-16T09:07:39+05:30</updated><id>https://teju85.github.io/blog/feed.xml</id><title type="html">Quagmire</title><subtitle>Stuff I find cool/useful</subtitle><entry><title type="html">Graph Convolutional Networks for text classification</title><link href="https://teju85.github.io/blog/2020/08/16/text-gcn.html" rel="alternate" type="text/html" title="Graph Convolutional Networks for text classification" /><published>2020-08-16T00:00:00+05:30</published><updated>2020-08-16T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/08/16/text-gcn</id><content type="html" xml:base="https://teju85.github.io/blog/2020/08/16/text-gcn.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1809.05679.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;novel GNN based method for text classification&lt;/li&gt;
  &lt;li&gt;graph is constructed using word co-occurence and word-doc associations&lt;/li&gt;
  &lt;li&gt;learn both word and doc (aka corpus) embeddings simultaneously by building and
using the above mentioned heterogenous text graph, where nodes are both words
and docs&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;text graph construction
    &lt;ul&gt;
      &lt;li&gt;based on word co-occurence (in corpus) and doc-word relations&lt;/li&gt;
      &lt;li&gt;number of nodes = vocab size + corpus size&lt;/li&gt;
      &lt;li&gt;input embeddings are just one-hot vectors&lt;/li&gt;
      &lt;li&gt;edge weights
        &lt;ul&gt;
          &lt;li&gt;doc to word = TFIDF&lt;/li&gt;
          &lt;li&gt;word to word = &lt;script type=&quot;math/tex&quot;&gt;PMI(i, j)&lt;/script&gt; only if &lt;script type=&quot;math/tex&quot;&gt;PMI(i, j)&lt;/script&gt; is positive and words
i and j occur in the sliding window together&lt;/li&gt;
          &lt;li&gt;self-loops are added&lt;/li&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;PMI(i, j) = log\frac{P_{ij}}{P_i P_j}&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;P_{ij} = \frac{nW(i, j)}{nW}&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;P(i) = \frac{nW(i)}{nW}&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;nW&lt;/script&gt; = total number of sliding windows&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;model and training
    &lt;ul&gt;
      &lt;li&gt;usage of spectral GCNs as in Kipf and Welling&lt;/li&gt;
      &lt;li&gt;2 layer GCNs&lt;/li&gt;
      &lt;li&gt;output layer is psased through softmax classifier&lt;/li&gt;
      &lt;li&gt;loss function is cross entropy error over all labelled docs
        &lt;ul&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;L = - \Sigma_d \Sigma_f Y_{df} ln(Z_{df})&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; = all labelled docs&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; = all output features&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; = label vector for a doc&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; = softmax output vector&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;2 layers help information exchange between docs too!&lt;/li&gt;
      &lt;li&gt;more layers didn’t help improving accuracy&lt;/li&gt;
      &lt;li&gt;sliding window size = 20 words&lt;/li&gt;
      &lt;li&gt;first layer output embedding size = 200&lt;/li&gt;
      &lt;li&gt;learning rate = 0.02&lt;/li&gt;
      &lt;li&gt;Adam optimizer with 200 epochs&lt;/li&gt;
      &lt;li&gt;early stopping after 10 epochs with no decrease in validation loss&lt;/li&gt;
      &lt;li&gt;dropout rate = 0.5&lt;/li&gt;
      &lt;li&gt;10% of training as validation set&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main paper can be found here.</summary></entry><entry><title type="html">Graph Attention Networks</title><link href="https://teju85.github.io/blog/2020/08/09/gat.html" rel="alternate" type="text/html" title="Graph Attention Networks" /><published>2020-08-09T00:00:00+05:30</published><updated>2020-08-09T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/08/09/gat</id><content type="html" xml:base="https://teju85.github.io/blog/2020/08/09/gat.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/abs/1710.10903&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;extension of attentional layers into GNNs&lt;/li&gt;
  &lt;li&gt;also the usage of multi-head attention into GNNs&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;compute attention coefficients as follows:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;e_{ij} = a(Wh_i, Wh_j)&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt; = weight matrix&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt; = embeddings of each nodes in the graph&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; = attention function to convert the input vectors into a scalar&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;normalize these across the neighborhood using softmax as follows:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_{ij} = \frac{exp(e_{ij})}{\Sigma_k exp(e_{ik})}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; varies over the neighborhood&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; varies across neighborhood&lt;/li&gt;
      &lt;li&gt;they use only 1-hop neighbors for this&lt;/li&gt;
      &lt;li&gt;but they don’t seem to suggest anything about sub-sampling of neighborhood!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;then finally apply weighted summation over the neighborhood based on the
computed attention values as follows:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;h'_i = \sigma(\Sigma_j \alpha_{ij} W h_j)&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; = non-linearity&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; varies across the neighborhood&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;they also propose to using multi-head attention as follows:
    &lt;ul&gt;
      &lt;li&gt;compute individual attentions for each head as above, independently&lt;/li&gt;
      &lt;li&gt;but at the end , take a concatentaion of resulting embeddings from
each of the heads&lt;/li&gt;
      &lt;li&gt;and in the final layer, instead of concatenating, perform a summation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;a full equation involving attention computation for a single head is:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_{ij} = \frac{exp(lr(a . h'_{ij}))}{\Sigma_k exp(lr(a . h'_{ik}))}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; varies over the neighborhood&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; varies over the neighborhood&lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;h'_{ij} = concat(Wh_i, Wh_j)&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;lr&lt;/script&gt; = LeakyReLu. (with a negative slope of 0.2)&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; = learnable vector used for dot product with the concatenated vector&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main paper can be found here.</summary></entry><entry><title type="html">PairNorm: tackling oversmoothing in GNNs</title><link href="https://teju85.github.io/blog/2020/08/06/pairnorm.html" rel="alternate" type="text/html" title="PairNorm: tackling oversmoothing in GNNs" /><published>2020-08-06T00:00:00+05:30</published><updated>2020-08-06T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/08/06/pairnorm</id><content type="html" xml:base="https://teju85.github.io/blog/2020/08/06/pairnorm.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/abs/1909.12223&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a new pairnorm layer which normalizes the intermediate embeddings to avoid
oversmoothing (OS)&lt;/li&gt;
  &lt;li&gt;allows deeper layers possible for GNNs&lt;/li&gt;
  &lt;li&gt;requires no extra learnable parameters (except for one hyper-param)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;deeper GNNs show gradual loss in accuracy due to
    &lt;ul&gt;
      &lt;li&gt;vanishing gradients&lt;/li&gt;
      &lt;li&gt;overfitting due to increased learnable params&lt;/li&gt;
      &lt;li&gt;OS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;OS?
    &lt;ul&gt;
      &lt;li&gt;phenomenon where node embeddings become very similar to each other&lt;/li&gt;
      &lt;li&gt;it is a form of laplacian smoothing&lt;/li&gt;
      &lt;li&gt;for shallow nets things are fine as the clusters of nodes will correctly get
similar embeddings&lt;/li&gt;
      &lt;li&gt;however, for deeper nets, there’ll be inter-cluster mixing (aka node-wise
smoothing)&lt;/li&gt;
      &lt;li&gt;also, repeatedly applying convlutions (or laplacian smoothing) washes out
all the signals in the features (feature-wise smoothing)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;in order to study the effects of OS, the authors do the following experiment
    &lt;ul&gt;
      &lt;li&gt;take a SGC but strip it out of all transformation layers&lt;/li&gt;
      &lt;li&gt;thus there’ll be no effect of overfitting or vanishing gradients&lt;/li&gt;
      &lt;li&gt;they plot the following 2 metrics in order to show the OS behavior&lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;rowdiff(H^{(k)}) = \frac{1}{n^2} \Sigma_{i,j} \Sigma_p (H_{ip}^{(k)} - H_{jp}^{(k)})^2&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;coldiff(H^{(k)}) = \frac{1}{d^2} \Sigma_{i,j} \Sigma_p (\frac{H_{pi}}{\Sigma_q abs(H_{qi})} - \frac{H_{pj}}{\Sigma_q abs(H_{qj})})^2&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; = number of samples&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; = feature dimension&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;H^{(k)}&lt;/script&gt; = computed embedding at ‘k’th hop&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;authors then show the similarity of GNNs with Graph Regularized Least Squares
(GRLS) method&lt;/li&gt;
  &lt;li&gt;then extend GRLS loss function by adding a penalty term against inter-cluster
mixing, in order to minimize the effect of oversmoothing&lt;/li&gt;
  &lt;li&gt;they propose pairnorm to maintain the Total Pairwise Squared Distance (TPSD)
metric&lt;/li&gt;
  &lt;li&gt;pairnorm
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;x_{ik}^c = x_{ik} - \frac{\Sigma_i \Sigma_k x{ik}}{n}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;x'_{ik} = \frac{s x_{ik}^c}{\sqrt{\frac{1}{n} \Sigma_j \Sigma_p (x_{jp}^c)^2}}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt; = hyper-param controlling TPSD&lt;/li&gt;
      &lt;li&gt;works well for SGC&lt;/li&gt;
      &lt;li&gt;similar to batch-norm layer but without the final scaling and bias&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;pairnorm-SI (scale individual)
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;x'_{ik} = \frac{s x_{ik}^c}{\Sigma_p (x_{ip}^c)^2}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;works well for SGC, GAT and GCN&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main paper can be found here.</summary></entry><entry><title type="html">Learning representations of irregular particle-detector geometry with distance-weighted graph networks</title><link href="https://teju85.github.io/blog/2020/07/26/gravnet-garnet.html" rel="alternate" type="text/html" title="Learning representations of irregular particle-detector geometry with distance-weighted graph networks" /><published>2020-07-26T00:00:00+05:30</published><updated>2020-07-26T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/07/26/gravnet-garnet</id><content type="html" xml:base="https://teju85.github.io/blog/2020/07/26/gravnet-garnet.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1902.07987.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Usage of GNN’s for irregular-geometry detectors for particle reconstruction&lt;/li&gt;
  &lt;li&gt;propose 2 new distance-weighted GNN layers: GRAVNET, GARNET&lt;/li&gt;
  &lt;li&gt;open-source their work based on TF &lt;a href=&quot;https://github.com/jkiesele/caloGraphNN&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;proposed computations assume no structure-dependent info from the input data
and thus this could be generalizable for other tasks such as tracking, jet
identification, etc&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gravnet-and-garnet-layers&quot;&gt;gravnet and garnet layers&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;input: &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; of dimension &lt;script type=&quot;math/tex&quot;&gt;B . V . F_{in}&lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;B&lt;/script&gt; = number of elements in the batch&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt; = number of detector hits per element&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{in}&lt;/script&gt; = input feature dimension per hit&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;perform linear transformation with bias
    &lt;ul&gt;
      &lt;li&gt;dimension of a vector in &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; is &lt;script type=&quot;math/tex&quot;&gt;S + F_{lr}&lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; = learned spatial representation of input vector&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{lr}&lt;/script&gt; = learned attributes for the nodes in the resulting graph&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;graph construction: (done for each element)
    &lt;ul&gt;
      &lt;li&gt;gravnet - a kNN graph is constructed for each element in the batch, based on
the pairwise euclidean distances between all hits in that element.&lt;/li&gt;
      &lt;li&gt;garnet - each of the &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; values is considered as a distance from that hit
to an aggregator&lt;/li&gt;
      &lt;li&gt;the distance between jth vertex and kth vertex in such a graph is called as
&lt;script type=&quot;math/tex&quot;&gt;d_{jk}&lt;/script&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;gravent and garnet layer computations
    &lt;ul&gt;
      &lt;li&gt;scale the features based on a potential function &lt;script type=&quot;math/tex&quot;&gt;V_p&lt;/script&gt;
        &lt;ul&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{jk}^i = f_j^i V_p(d_{jk})&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;gravnet: &lt;script type=&quot;math/tex&quot;&gt;V_p(x) = e^{-x^2}&lt;/script&gt;&lt;/li&gt;
          &lt;li&gt;garnet: &lt;script type=&quot;math/tex&quot;&gt;V_p(x) = e^{-abs(x)}&lt;/script&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;aggregation of scaled features
        &lt;ul&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;f_k^i = agg_j(f_{jk}^i)&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;tried both max and mean&lt;/li&gt;
          &lt;li&gt;aggregation function which was most effective for their use-case was mean&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;transformation: (output dimension = &lt;script type=&quot;math/tex&quot;&gt;F_{out}&lt;/script&gt;
        &lt;ul&gt;
          &lt;li&gt;in case of garnet, each of these &lt;script type=&quot;math/tex&quot;&gt;f_k^i&lt;/script&gt; aggregator features will again
be weighted using similar equation in order to project them back to the
original vertices.&lt;/li&gt;
          &lt;li&gt;concatenate the input &lt;script type=&quot;math/tex&quot;&gt;F_{in}&lt;/script&gt; features with this &lt;script type=&quot;math/tex&quot;&gt;f_k^i&lt;/script&gt; feature&lt;/li&gt;
          &lt;li&gt;perform linear transformation with bias, followed by tanh activation&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;a custom loss function is defined based on the domain knowledge&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;models&quot;&gt;models&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;both a local and global exchange of message across sensors is proposed&lt;/li&gt;
  &lt;li&gt;gravnet model
    &lt;ul&gt;
      &lt;li&gt;has 4 blocks
        &lt;ul&gt;
          &lt;li&gt;concat mean of vertex features and vertex features&lt;/li&gt;
          &lt;li&gt;3 dense layers with tanh activation (dim = 64)&lt;/li&gt;
          &lt;li&gt;one gravnet layer&lt;/li&gt;
          &lt;li&gt;final dense layer with dim = 128 and relu activation&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;gravnet layer
        &lt;ul&gt;
          &lt;li&gt;‘k’ value for kNN-graph is set to 40&lt;/li&gt;
          &lt;li&gt;S = 4&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{lr}&lt;/script&gt; = 22&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{out}&lt;/script&gt; = 48&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;output of each block before the final dense layer is concatenated and then
passed to the final dense layer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;garnet model
    &lt;ul&gt;
      &lt;li&gt;has 4 blocks
        &lt;ul&gt;
          &lt;li&gt;concat mean of vertex features and vertex features&lt;/li&gt;
          &lt;li&gt;one dense layer with tanh activation (dim = 32)&lt;/li&gt;
          &lt;li&gt;11 garnet layers!&lt;/li&gt;
          &lt;li&gt;final dense layer with dim = 48 and relu activation&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;garnet layer
        &lt;ul&gt;
          &lt;li&gt;S = 4&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{lr}&lt;/script&gt; = 20&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{out}&lt;/script&gt; = 32&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;output of each block before the final dense layer is concatenated and then
passed to the final dense layer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;batch norm is applied to the input and output of all blocks&lt;/li&gt;
  &lt;li&gt;for all these models, at the end, the following 2 layers are applied
    &lt;ul&gt;
      &lt;li&gt;a dense layer with dim = 3 and relu activation&lt;/li&gt;
      &lt;li&gt;another dense layer with dim = 2 and softmax activation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;trained using Adam optimizer&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main paper can be found here.</summary></entry><entry><title type="html">All about NVSHMEM</title><link href="https://teju85.github.io/blog/2020/07/17/nvhsmem.html" rel="alternate" type="text/html" title="All about NVSHMEM" /><published>2020-07-17T00:00:00+05:30</published><updated>2020-07-17T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/07/17/nvhsmem</id><content type="html" xml:base="https://teju85.github.io/blog/2020/07/17/nvhsmem.html">&lt;h1 id=&quot;nvshmem&quot;&gt;NVSHMEM&lt;/h1&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;
&lt;p&gt;API document can be found &lt;a href=&quot;https://docs.nvidia.com/hpc-sdk/nvshmem/api/docs/index.html&quot;&gt;here&lt;/a&gt;
and developer guide can be found &lt;a href=&quot;https://docs.nvidia.com/hpc-sdk/nvshmem/developer-guide/index.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;nvshmem is an extension of openshmem API for the GPU clusters. nvshmem provides
a PGAS (Partitioned Global Address Space) for the buffers on GPU cluster.
Enables fine-grained computation/communication overlap and also performing
synchronization, all from the CUDA kernels itself. Thus, this feature is very
helpful in achieving strong scaling on our apps. However, it also provides
CPU-side APIs to initiate communication, for flexibility.&lt;/p&gt;

&lt;h2 id=&quot;programming-model&quot;&gt;Programming model&lt;/h2&gt;
&lt;p&gt;Types of data objects&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Symmetric data objects - objects can be shared across remote PE’s. These are
allocated from a &lt;strong&gt;symmetric heap&lt;/strong&gt; using &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_malloc()&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Private data objects - objects that private to the PE which owns them&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;openshmem provides strong ordering guarantees. However, for perf reasons,
nvshmem doesn’t provide this guarantee and thus it is expected of the devs to
use &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_fence()&lt;/code&gt; when such an ordering is required! But, non-blocking calls
are not ordered with this call and for those, we need to use &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_quiet()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Execution model is typically SPMD (Single Program Multiple Data), but this is
not required by nvshmem. Work is done by PEs, which are typically OS processes.
These PEs are further allowed to create threads, if there’s a support for it.
nvshmem phase begins with the call to either &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_init()&lt;/code&gt; or
&lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_init_thread()&lt;/code&gt; and concludes with the call to &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_finalize()&lt;/code&gt;
done by all PEs or &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_global_exit()&lt;/code&gt; by any PE. We cannot reinitialize the
nvshmem after finalization! (similar to MPI) Each PE has an integer ID, similar
to the concept of MPI ranks.&lt;/p&gt;

&lt;p&gt;Since nvshmem provides one-sided communication API’s, even if the target PE is
not involved in any nvshmem calls, other PE’s can continue to communicate with
this PE and make progress. This is unlike MPI communication model.&lt;/p&gt;

&lt;p&gt;There’s also threadgroup communication with multiple threads can collectively be
part of a single communication operation.&lt;/p&gt;

&lt;p&gt;nvshmem expects all buffer arguments to nvhsmem communication routines to be
symmetric objects.&lt;/p&gt;

&lt;p&gt;symmetric address returned by nvhsmem allocation routine is also a valid local
addresses. However, trying to use a mix of symmetric address and local address
to nvshmem routines can lead to undefined behavior.&lt;/p&gt;

&lt;h2 id=&quot;communication-model&quot;&gt;Communication model&lt;/h2&gt;
&lt;p&gt;Provides &lt;strong&gt;get&lt;/strong&gt; and &lt;strong&gt;put&lt;/strong&gt; methods for working with symmetric objects. Has all
the bulk, scalar and interleaved transfer schemes available. Also supports
atomic memory operations (AMO). There are methods can be initiated from CUDA
kernels or from the host too. All the CPU-side calls are stream-ordered.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_ptr()&lt;/code&gt; provides raw address pointer to be used for issuing explicit
loads/stores to local or remote PEs, as long as they are accessible to each
other.&lt;/p&gt;

&lt;p&gt;All nvshmem symmmetric memory is pinned GPU memory.&lt;/p&gt;

&lt;p&gt;nvshmem assumes a one-to-one mapping between PE and GPU.&lt;/p&gt;

&lt;p&gt;The usual data coalescing policies/guidelines as seen in CUDA programming model
also apply here for efficiency.&lt;/p&gt;

&lt;p&gt;cuda kernels needing sync/collective APIs must be launched using the collective
launch APIs only.&lt;/p&gt;

&lt;h2 id=&quot;memory-model&quot;&gt;memory model&lt;/h2&gt;
&lt;p&gt;List of operations supported:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Remote Memory Access (RMA) - PUT/GET&lt;/li&gt;
  &lt;li&gt;Atomic Memory Operations (AMO)&lt;/li&gt;
  &lt;li&gt;single ops&lt;/li&gt;
  &lt;li&gt;direct loads/stores (via the pointer returned by &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_ptr()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;collective ops&lt;/li&gt;
  &lt;li&gt;wait and test functions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since GPUs expose only a weak memory model, nvshmem does introduce a few
exceptions to the openshmem memory model&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;no guarantees to the order of writes to a symmetric memory, as seen by PEs&lt;/li&gt;
  &lt;li&gt;to enforce ordering to target PE use &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_fence()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;to enforce ordering to all other PE’s use &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_quiet()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;to enforce ordering for nonblocking calls use &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_quiet()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Result of the get or AMO operations will appear in the program order, however.&lt;/p&gt;</content><author><name></name></author><category term="cuda" /><summary type="html">NVSHMEM</summary></entry><entry><title type="html">How to stop worrying and start living</title><link href="https://teju85.github.io/blog/2020/07/05/how-to-stop-worrying.html" rel="alternate" type="text/html" title="How to stop worrying and start living" /><published>2020-07-05T00:00:00+05:30</published><updated>2020-07-05T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/07/05/how-to-stop-worrying</id><content type="html" xml:base="https://teju85.github.io/blog/2020/07/05/how-to-stop-worrying.html">&lt;p&gt;By Dale Carnegie. This book can be found &lt;a href=&quot;https://www.amazon.in/How-Stop-Worrying-Start-Living/dp/0671733354&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Carnegie walks us through a list of time-tested rules/ideas/guidelines to help
us stop our greatest enemy, worry. When you have gone through this list, you’ll
realize that this is nothing novel and everyone before us have been trying to
tell us the same thing! However, the uniqueness in his book is that he shows us
the examples from real people who have been able to put some of these techniques
in order to conquer their worries.&lt;/p&gt;

&lt;h3 id=&quot;intro&quot;&gt;intro&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;leadership gravitates towards those who can stand up and speak what they are
thinking&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;live-in-day-tight-compartments&quot;&gt;live in “day-tight compartments”&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Thomas Carlyle: our main business is not to see what lies dimly at a distance,
but to do what lies clearly at hand&lt;/li&gt;
  &lt;li&gt;today’s bread is the only kind of bread you can possibly eat. By all means
prepare for tomorrow, but don’t have anxiety about it&lt;/li&gt;
  &lt;li&gt;anyone can do their job or handle their responsibilities for one day&lt;/li&gt;
  &lt;li&gt;everyday is a new life to a wise man&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;a-magic-formula-for-solving-worry-situations&quot;&gt;a magic formula for solving worry situations&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;3-step solution to come out of worry and anxiety: (Carrier formula)
    &lt;ul&gt;
      &lt;li&gt;Step1: imagine the worst that could happen&lt;/li&gt;
      &lt;li&gt;Step2: reconcile with the worst case&lt;/li&gt;
      &lt;li&gt;Step3: calmly start working towards solutions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;what-worry-may-do-to-you&quot;&gt;what worry may do to you&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;people who don’t know how to fight worry, die young&lt;/li&gt;
  &lt;li&gt;you don’t get stomach ulcers from you eat, but from what’s eating you&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-to-analyse-and-solve-worry-problems&quot;&gt;how to analyse and solve worry problems&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;six honest men: what, when, why, how, where and who - Rudyard Kipling&lt;/li&gt;
  &lt;li&gt;basic steps in problem analysis
    &lt;ul&gt;
      &lt;li&gt;get the facts&lt;/li&gt;
      &lt;li&gt;analyze the facts&lt;/li&gt;
      &lt;li&gt;come to a decision and then act on it&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;confusion is the chief cause of worry&lt;/li&gt;
  &lt;li&gt;if one gathers all the facts in an objective way, the problem usually solves
itself!&lt;/li&gt;
  &lt;li&gt;it is hard to collect facts when our emotions are running high due to worry.
So, do this:
    &lt;ul&gt;
      &lt;li&gt;think that you are collecting these facts for another person&lt;/li&gt;
      &lt;li&gt;now pretend that you are a lawyer trying to bring you down and collect all
facts against you&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;a problem well stated is problem half solved&lt;/li&gt;
  &lt;li&gt;but once the decision has been made, don’t self-doubt&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-to-eliminate-50-of-your-business-worries&quot;&gt;how to eliminate 50% of your business worries&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;answer these questions:
    &lt;ul&gt;
      &lt;li&gt;what is the problem?&lt;/li&gt;
      &lt;li&gt;what is its cause?&lt;/li&gt;
      &lt;li&gt;what are all the possible solutions?&lt;/li&gt;
      &lt;li&gt;what solution do you recommend?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-to-crowd-worry-out-of-your-mind&quot;&gt;how to crowd worry out of your mind&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;keeping yourself busy can drive out anxiety&lt;/li&gt;
  &lt;li&gt;remember: idle mind is devil’s workshop!&lt;/li&gt;
  &lt;li&gt;worried person must lose himself in action, lest be wither in despair&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dont-let-the-beetles-get-you-down&quot;&gt;don’t let the beetles get you down&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;we often face the most difficult hardships with extreme courage, but always
let us down due to silly trifles!&lt;/li&gt;
  &lt;li&gt;only few of us are greatly wronged. It is the small hurt to our ego which lead
to fights and murders&lt;/li&gt;
  &lt;li&gt;a giant tree withstands centuries of avalanche and storms, only to be brought
down due to incessant attacks by tiny insects and beetles!&lt;/li&gt;
  &lt;li&gt;don’t dwell on trifles. Life is too short to be little.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;a-law-that-will-outlaw-many-of-your-worries&quot;&gt;a law that will outlaw many of your worries&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;most of our worries are due to imagination&lt;/li&gt;
  &lt;li&gt;when you find yourself worrying about some possibility ask yourself, what’s
the chance of it happening&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;co-operate-with-the-inevitable&quot;&gt;co-operate with the inevitable&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;it is so. It can’t be otherwise&lt;/li&gt;
  &lt;li&gt;when unpleasant things happen to us, we can either accept them and adjust
ourselves or live a life of rebellion&lt;/li&gt;
  &lt;li&gt;acceptance of what has happened is the first step towards overcoming the
consequences of a misfortune&lt;/li&gt;
  &lt;li&gt;circumstances alone do not make us happy or unhappy, but our reactions.&lt;/li&gt;
  &lt;li&gt;it’s only miserable of we cannot endure our circumstances&lt;/li&gt;
  &lt;li&gt;this doesn’t mean we should shy away from adversities! It means when we have a
chance a fighting back we must.&lt;/li&gt;
  &lt;li&gt;when I can’t handle events, I let them handle themselves - Ford&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;put-a-stop-loss-order-on-your-worries&quot;&gt;put a “stop-loss” order on your worries&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;just like we put a stop-loss order on the purchased shares to minimize loss,
we should do the same on our worries, impatience, etc.&lt;/li&gt;
  &lt;li&gt;things happen, but we shouldn’t be paying them back at the cost of our peace
of mind.&lt;/li&gt;
  &lt;li&gt;most of our miseries are due to the false estimates we have on things&lt;/li&gt;
  &lt;li&gt;when you find yourself worrying too much, ask yourself:
    &lt;ul&gt;
      &lt;li&gt;what is it worth to me&lt;/li&gt;
      &lt;li&gt;at what price should I put a stop-loss order on it&lt;/li&gt;
      &lt;li&gt;have I already paid enough&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dont-try-to-saw-sawdust&quot;&gt;don’t try to saw sawdust&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;there’s only one way to benefit from our past, ie to calmly analyze it for any
mistakes, benefit from it and forget it!&lt;/li&gt;
  &lt;li&gt;don’t cry over spilt milk!
    &lt;ul&gt;
      &lt;li&gt;all the fuss and cry in the world will not bring back that milk&lt;/li&gt;
      &lt;li&gt;we can only try to avoid trying to get it spilt the next time&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;let the past bury it’s dead&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;eight-words-that-can-transform-your-life&quot;&gt;eight words that can transform your life&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;our mental attitude is the X factor that determines our fate&lt;/li&gt;
  &lt;li&gt;thus out biggest problem is choosing the right thoughts!&lt;/li&gt;
  &lt;li&gt;our life is what our thoughts make it&lt;/li&gt;
  &lt;li&gt;we need to b concerned about our problems, not worried&lt;/li&gt;
  &lt;li&gt;Our mental thoughts can also affect our physical powers&lt;/li&gt;
  &lt;li&gt;nothing can bring you peace but yourself&lt;/li&gt;
  &lt;li&gt;think and act cheerfully and you will fell cheerful&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;high-cost-of-getting-even&quot;&gt;high cost of getting even&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;we don’t have to be saintly and love our enemies. But atleast, for our own
health’s sake, let us forgive them and forget them&lt;/li&gt;
  &lt;li&gt;a man is a fool who can’t be angry, but a man is wise who won’t be angry&lt;/li&gt;
  &lt;li&gt;no one or thing can humiliate or disturb us, unless we let them&lt;/li&gt;
  &lt;li&gt;one way to not hate our attackers is to have mission much bigger than
ourselves and be completely involved towards it&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;if-you-do-this-youll-never-worry-about-ingratitude&quot;&gt;if you do this, you’ll never worry about ingratitude&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;an angry man is always full of poison&lt;/li&gt;
  &lt;li&gt;it is natural for man to forget to be grateful&lt;/li&gt;
  &lt;li&gt;the biggest mistake we make is to expect gratitude in return to our supposed
good deeds&lt;/li&gt;
  &lt;li&gt;both gratitude and love can’t be demanded&lt;/li&gt;
  &lt;li&gt;ingratitude is our nature. So, gratitude as a quality needs to be cultivated
from an early age&lt;/li&gt;
  &lt;li&gt;our children will become what we make them to be&lt;/li&gt;
  &lt;li&gt;if we want our children to be grateful, then we should be grateful&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;would-you-take-a-million-dollars-for-what-you-have&quot;&gt;Would You Take A Million Dollars For What You Have?&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;~90% of things in our lives are right. So, if you want to be worry-free, then
concentrate on these&lt;/li&gt;
  &lt;li&gt;think and thank: think of all things you are grateful if and thank God for them&lt;/li&gt;
  &lt;li&gt;we seldom think of what we have but what we lack&lt;/li&gt;
  &lt;li&gt;Count your blessings not your troubles&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;find-yourself-and-be-yourself-remember-there-is-no-one-else-on-earth-like-you&quot;&gt;Find Yourself And Be Yourself: Remember There Is No One Else on Earth Like You&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;we bring a lot of misery upon ourselves by trying to fit in someone else’s shoes&lt;/li&gt;
  &lt;li&gt;you won’t get far by playing ape&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;if-you-have-a-lemon-make-lemonade&quot;&gt;if you have a lemon, make lemonade&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;one of humanity’s greatest powers is to turn a minus into a plus&lt;/li&gt;
  &lt;li&gt;a superior man not only bears up under necessity, but loves it&lt;/li&gt;
  &lt;li&gt;anybody can capitalise on their gains. The real challenge is in turning our
loses into profit.&lt;/li&gt;
  &lt;li&gt;our infirmities help us unexpectedly&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-to-cure-melancholy-in-14-days&quot;&gt;how to cure melancholy in 14 days&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;the cure is simple: everyday try to think how to make someone happy&lt;/li&gt;
  &lt;li&gt;doing so helps to take off the focus on ourselves&lt;/li&gt;
  &lt;li&gt;when you’re good to others, you are best to yourself&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-my-mother-and-father-conquered-worry&quot;&gt;how my mother and father conquered worry&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Man is made not to understand life, but to live it&lt;/li&gt;
  &lt;li&gt;sovereign cure for worry is religious faith&lt;/li&gt;
  &lt;li&gt;faith is one of the forces by which man lives. thus an absence of it leads to
a total collapse&lt;/li&gt;
  &lt;li&gt;Prayer:
    &lt;ul&gt;
      &lt;li&gt;helps by putting our problems into concrete words&lt;/li&gt;
      &lt;li&gt;helps by giving us a feeling that we are not alone&lt;/li&gt;
      &lt;li&gt;it is the first action towards fixing our problems&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;remember-that-no-one-ever-kicks-a-dead-dog&quot;&gt;remember that no one ever kicks a dead dog&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;When you’re getting kicking and criticized, it basic means that you’re
accomplishing something important&lt;/li&gt;
  &lt;li&gt;vulgar people take huge delight in the faults and follies of great people&lt;/li&gt;
  &lt;li&gt;unjust criticism is actually a disguised compliment&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;do-this-and-the-criticism-cant-hurt-you&quot;&gt;do this and the criticism can’t hurt you&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;We take the little jibes taken at us, far too seriously!&lt;/li&gt;
  &lt;li&gt;in the long run, it’s pointless to keep scores&lt;/li&gt;
  &lt;li&gt;if you put your head above the crowd you’ll be criticized. So, just learn to
ignore unjust criticism&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;fool-things-i-have-done&quot;&gt;fool things I have done&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;we ourselves are to be blamed for our misfortunes, no one else&lt;/li&gt;
  &lt;li&gt;setting up a regular and continued self-analysis process is very helpful in
helping us grow&lt;/li&gt;
  &lt;li&gt;every man is a fool for atleast 5 minutes in a day. Wisdom lies in not
exceeding that limit!&lt;/li&gt;
  &lt;li&gt;opinions of our enemies come closer to the truth than those of ourselves.&lt;/li&gt;
  &lt;li&gt;if the criticism is genuine and done with honest intentions, no matter who
gives them, we need to take them seriously&lt;/li&gt;
  &lt;li&gt;We are not perfect. So let’s ask for unbiased and constructive criticism&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-to-add-one-hour-a-day-to-our-waking-life&quot;&gt;how to add one hour a day to our waking life&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Fatigue lowers our physical as well as mental resistance.&lt;/li&gt;
  &lt;li&gt;rest often and always before you get tired&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;what-makes-you-tired-and-what-you-can-do-about-it&quot;&gt;what makes you tired and what you can do about it&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;mental work alone can’t make us tired. Our brains are tireless!&lt;/li&gt;
  &lt;li&gt;Most of our fatigues are derived from our mental and emotional attitudes&lt;/li&gt;
  &lt;li&gt;worry, tenseness and emotional upsets are the main reasons behind fatigue of a
sedentary worker&lt;/li&gt;
  &lt;li&gt;eyes consume about a quarter of nervous energies in our body. So, start by
relaxing eyes.&lt;/li&gt;
  &lt;li&gt;don’t make an effort to relax, as relaxation is the absence of any effort or
tension&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-the-housewife-can-avoid-fatigue-and-keep-looking-young&quot;&gt;how the housewife can avoid fatigue and keep looking young&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;talking about your worries with someone else can help reduce anxiety&lt;/li&gt;
  &lt;li&gt;keeping a note of inspiring quotes and referring to them often can give you
the much needed lift&lt;/li&gt;
  &lt;li&gt;quiet your nerves with slow, steady and deep breathing&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;four-good-working-habits-that-will-prevent-fatigue-and-worry&quot;&gt;four good working habits that will prevent fatigue and worry&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Keep only the things that are needed for your immediate task on your desk&lt;/li&gt;
  &lt;li&gt;do things in the order of their importance&lt;/li&gt;
  &lt;li&gt;when you face a problem solve it then and there if you have all the facts to
make the decision. Don’t keep putting off making decisions&lt;/li&gt;
  &lt;li&gt;learn to organize, deputise, delegate and supervise&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-to-banish-the-boredom-that-produces-fatigue-worry-and-resentment&quot;&gt;how to banish the boredom that produces fatigue, worry and resentment&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;one of the chief causes of fatigue is boredom&lt;/li&gt;
  &lt;li&gt;boredom causes exhaustion far earlier than the physical activity itself&lt;/li&gt;
  &lt;li&gt;where you find your interests, you’ll also find your energy too&lt;/li&gt;
  &lt;li&gt;our life is what our thoughts make it&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-to-keep-from-worrying-about-insomnia&quot;&gt;how to keep from worrying about insomnia&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;worrying about insomnia will be much worse than insomnia itself&lt;/li&gt;
  &lt;li&gt;every person needs a different amount of sleep. So, it’s not worth fretting
about this&lt;/li&gt;
  &lt;li&gt;feeling of security is the first pre-requisite for a sound sleep&lt;/li&gt;
  &lt;li&gt;Relaxing your body is also helpful to fall asleep&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;major-decision-of-your-life&quot;&gt;major decision of your life&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;for youngsters, there are 2 major decisions that’ll define the rest of their
lives:
    &lt;ul&gt;
      &lt;li&gt;what’ll be your vocation&lt;/li&gt;
      &lt;li&gt;who’ll be the father/mother of your children&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;a man can succeed at almost anything in which he has unlimited enthusiasm&lt;/li&gt;
  &lt;li&gt;it’s a real pity if all that a person gets out of his work is pay and nothing
else&lt;/li&gt;
  &lt;li&gt;get guidance from your parents, vocational guide, teachers, etc. But at the
end, you decide your career based on what you think is interesting for you&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;70-of-all-our-worries&quot;&gt;70% of all our worries…&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Are about money&lt;/li&gt;
  &lt;li&gt;below are the rules to help you budget your money wisely&lt;/li&gt;
  &lt;li&gt;keep a ledger of your expenses to know where your money is going&lt;/li&gt;
  &lt;li&gt;get a tailor-made budget that really fits your needs&lt;/li&gt;
  &lt;li&gt;learn to spend money wisely&lt;/li&gt;
  &lt;li&gt;don’t increase your headaches with your income&lt;/li&gt;
  &lt;li&gt;try to build credit for when the case you have to borrow&lt;/li&gt;
  &lt;li&gt;protect yourself against illness, fire and other exigencies&lt;/li&gt;
  &lt;li&gt;don’t have your life-insurance proceeds paid to your survivors in lumpsum.
Instead, arrange for a monthly income of sorts&lt;/li&gt;
  &lt;li&gt;teach your children a responsible attitude towards money&lt;/li&gt;
  &lt;li&gt;if necessary, find another source of income&lt;/li&gt;
  &lt;li&gt;don’t ever think of gambling as a way for earning money&lt;/li&gt;
  &lt;li&gt;if we can’t change our financial situation, let’s atleast be good to ourselves
and don’t fret over things that can’t be changed&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="book-notes" /><category term="self-help" /><summary type="html">By Dale Carnegie. This book can be found here.</summary></entry><entry><title type="html">Shapley Values</title><link href="https://teju85.github.io/blog/2020/06/30/shapley-values.html" rel="alternate" type="text/html" title="Shapley Values" /><published>2020-06-30T00:00:00+05:30</published><updated>2020-06-30T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/30/shapley-values</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/30/shapley-values.html">&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;p&gt;The reference chapter can be found in &lt;a href=&quot;https://christophm.github.io/interpretable-ml-book/shapley.html&quot;&gt;this&lt;/a&gt;
book.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Shapley Values (SV) explain prediction via considering each feature as a
player and prediction as the payout and deals with how to fairly distribute
the payout among the players&lt;/li&gt;
  &lt;li&gt;has solid base in coalitional game theory&lt;/li&gt;
  &lt;li&gt;gain (payout) here is the difference between actual prediction and average&lt;/li&gt;
  &lt;li&gt;SV for an instance is the average marginal  contribution of a feature value
across all possible coalitions (weighted average, to be precise)&lt;/li&gt;
  &lt;li&gt;marginal contribution = difference between prediction with and without this
feature value&lt;/li&gt;
  &lt;li&gt;computing SV for linear models is very straightforward&lt;/li&gt;
  &lt;li&gt;SV satisfy the following properties
    &lt;ul&gt;
      &lt;li&gt;Efficiency - feature contributions add upto difference between predicted and
mean prediction&lt;/li&gt;
      &lt;li&gt;Symmetry - SV of 2 feature values should be the same if they contribute
equally for all coalitions&lt;/li&gt;
      &lt;li&gt;Dummy - if a feature value does not contribute to the output, then its value
should be 0&lt;/li&gt;
      &lt;li&gt;Additivity - for ensemble models, final SV can be computed by adding up the
individual SV from each of the underlying models&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;computating-sv&quot;&gt;Computating SV&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\phi_j = \sum_{S \subset {x} - {x_j}} \frac{len(S)! (p - len(S) - 1)!}{p!} (val(S \bigcup {x_j}) - val(S))&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;val(S) = \int_{x \notin S} f(x_1, ..., x_p) - E[f(X)]&lt;/script&gt;

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\phi_j&lt;/script&gt; - SV for j-th feature value&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; - number of features&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; - the model&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;approximating-sv-via-monte-carlo-sampling&quot;&gt;Approximating SV via Monte-Carlo sampling&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\phi'_j = \frac{1}{M} \sum_{m=1}^M f(x_{+j}^m) - f(x_{-j}^m)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;M&lt;/script&gt; - number of samples&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f(x_{+j}^m)&lt;/script&gt; - prediction where the feature values are first randomly
permuted and then the first j feature values are kept from the input sample
while the rest are randomly picked from another sample in the dataset.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f(x_{-j}^m)&lt;/script&gt; - same as above but with j-th feature value also chosen at
random from another sample&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;disadvantages&quot;&gt;Disadvantages&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;suffers from inclusion of unrealistic feature values&lt;/li&gt;
  &lt;li&gt;computationally super expensive&lt;/li&gt;
  &lt;li&gt;explanation involves all the features, which can be difficult for humans to
further interpret, as opposed to explainer models like LIME.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="book-notes" /><category term="interpretable-machine-learning" /><category term="machine-learning" /><summary type="html">Summary The reference chapter can be found in this book.</summary></entry><entry><title type="html">Tree-LSTM’s</title><link href="https://teju85.github.io/blog/2020/06/25/tree-lstms.html" rel="alternate" type="text/html" title="Tree-LSTM's" /><published>2020-06-25T00:00:00+05:30</published><updated>2020-06-25T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/25/tree-lstms</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/25/tree-lstms.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1503.00075.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Generalization of LSTMs to tree structured network topologies, with arbitrary
branching factor&lt;/li&gt;
  &lt;li&gt;demonstrate better results than “linear” LSTMs on SemEval and SSTB datasets&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tree-lstms&quot;&gt;Tree LSTMs&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;“linear” LSTMs compute their current hidden state based on previous hidden
state and current input&lt;/li&gt;
  &lt;li&gt;tree LSTMs compute their current hidden state from current input and hidden
states of children. There will be one forget gate for each child and only the
leaf nodes get to take in the input vectors&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;child-tree-lstms&quot;&gt;Child tree LSTMs&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;useful for unordered children&lt;/li&gt;
  &lt;li&gt;eg: dependency trees&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;C(j)&lt;/script&gt; = children of j-th node&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; = sigmoid function&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;x_j&lt;/script&gt; inputs to the j-th node&lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;k \epsilon C(j)&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_j' = \sum_k h_k&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;i_j = \sigma(W^{(i)}x_j + U^{(i)}h_j' + b^{(i)})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{jk} = \sigma(W^{(f)}x_j + U^{(f)}h_k + b^{(f)})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;o_j = \sigma(W^{(o)}x_j + U^{(o)}h_j' + b^{(o)})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;u_j = tanh(W^{(u)}x_j + U^{(u)}h_j' + b^{(u)})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;c_j = i_j \odot u_j + \sum_k f_{jk} c_k&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_j = o_j \odot tanh(c_j)&lt;/script&gt;

&lt;h4 id=&quot;n-ary-tree-lstms&quot;&gt;N-ary tree LSTMs&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;useful when branching factor is atmost N&lt;/li&gt;
  &lt;li&gt;has finer grained control over forget gates from each child node&lt;/li&gt;
  &lt;li&gt;child nodes are expected to be ordered&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;i_j = \sigma(W^{(i)}x_j + \sum_{l=1}^N U_l^{(i)}h_{jl} + b^{(i)})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{jk} = \sigma(W^{(f)}x_j + \sum_{l=1}^N U_{kl}^{(f)}h_{jl} + b^{(i)})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;o_j = \sigma(W^{(o)}x_j + \sum_{l=1}^N U_l^{(o)}h_{jl} + b^{(o)})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;u_j = tanh(W^{(u)}x_j + \sum_{l=1}^N U_l^{(u)}h_{jl} + b^{(u)})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;c_j = i_j \odot u_j + \sum_{l=1}^N f_{jl} \odot c_{jl}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_j = o_j \odot tanh(c_j)&lt;/script&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main paper can be found here.</summary></entry><entry><title type="html">GraphSAGE</title><link href="https://teju85.github.io/blog/2020/06/24/graphsage.html" rel="alternate" type="text/html" title="GraphSAGE" /><published>2020-06-24T00:00:00+05:30</published><updated>2020-06-24T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/24/graphsage</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/24/graphsage.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1706.02216.pdf&quot;&gt;here&lt;/a&gt;.
SaGe = Sample and Aggregation functions&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Learns parametric functions in order to generate low dimensional embeddings of
the nodes in the graph&lt;/li&gt;
  &lt;li&gt;These functions can also be used to generate embeddings of unseen nodes too&lt;/li&gt;
  &lt;li&gt;It can also optionally use node features as starting points for embeddings&lt;/li&gt;
  &lt;li&gt;Configurable number of layers representing the number of hops for each node&lt;/li&gt;
  &lt;li&gt;Custom loss function (based on negative-sampling) for unsupervised learning&lt;/li&gt;
  &lt;li&gt;Also supports supervised learning&lt;/li&gt;
  &lt;li&gt;Scales to large graphs through neighborhood sampling and minibatch techniques&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;forward-propagation-algo&quot;&gt;forward propagation algo&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^0 = x_v&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;for k = 1 to K
    &lt;ul&gt;
      &lt;li&gt;for v in minibatch
        &lt;ul&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_{N(v)}^k = aggregator_k(h_u^{k-1}, u \epsilon N(v))&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^k = \sigma(W^k concat(h_v^{k-1}, h_{N(v)}^k))&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^k = \frac{h_v^k}{L2norm(h_v^k)}&lt;/script&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;z_v = h_v^K&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;h^k&lt;/script&gt; = hidden vectors at each layer for all vertices&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt; = nodes&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;N(v)&lt;/script&gt; = sampled neighborhood for each node&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; = number of layers (hyperparameter)&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; = a non-linear activation function&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;W^k&lt;/script&gt; = learnable weights for each layer&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; = output embedding&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In paper the authors show the similarity of this algo with the popular
&lt;a href=&quot;https://www.davidbieber.com/post/2019-05-10-weisfeiler-lehman-isomorphism-test/&quot;&gt;Weisfeiler-Lehman&lt;/a&gt;
graph isomorphism test.&lt;/p&gt;

&lt;h3 id=&quot;neighborhood-sampling&quot;&gt;neighborhood sampling&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;performs uniform sampling&lt;/li&gt;
  &lt;li&gt;different samples are drawn for each layer based on different sampling rates
&lt;script type=&quot;math/tex&quot;&gt;S_i&lt;/script&gt;, for each layer&lt;/li&gt;
  &lt;li&gt;authors recommend to keep &lt;script type=&quot;math/tex&quot;&gt;\Pi_i S_i \le 500&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;sampling technique is pretty much the same as seen in
&lt;a href=&quot;/blog/2020/06/10/pinsage.html&quot;&gt;PinSage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;They recommend &lt;script type=&quot;math/tex&quot;&gt;K = 2, S_1 = 25, S_2 = 10&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;learning&quot;&gt;learning&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;via SGD + using Adam optimizer&lt;/li&gt;
  &lt;li&gt;loss function for unsupervised mode is based on negative sampling and its
equation is as follows: &lt;script type=&quot;math/tex&quot;&gt;J(z_u) = -log(sigmoid(z_u^T z_v)) - Q E[log(sigmoid(z_u^T z_{v_n}))]&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt; = number of negative samples&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;v_n&lt;/script&gt; = negative sample&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; = node that is a neighbor of &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;aggregators&quot;&gt;aggregators&lt;/h3&gt;
&lt;p&gt;These must be permutation invariant. They test the following aggregators&lt;/p&gt;

&lt;h4 id=&quot;mean-aggregator&quot;&gt;mean aggregator&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^k = \sigma(W^k Mean(h_u^{k-1} with u \epsilon N(v), h_v^{k-1}))&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;note that this uses &lt;script type=&quot;math/tex&quot;&gt;h_v^{k-1}&lt;/script&gt; in the aggregation itself!&lt;/li&gt;
  &lt;li&gt;thus this can be thought of as “skip connection” between layers&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;lstm-aggregator&quot;&gt;LSTM aggregator&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;LSTM’s are not permutation invariant&lt;/li&gt;
  &lt;li&gt;So they make it to be invariant by randomly permuting the inputs&lt;/li&gt;
  &lt;li&gt;this seems to show the best accuracy in their experimentation&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;pooling-aggregator&quot;&gt;pooling aggregator&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_{N(v)}^k = max_{u \epsilon N(v)}(\sigma(W_{pool}^k h_u^k + b^k))&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;aggregator can be either max or mean, both seem to provide similar accuracy&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main paper can be found here. SaGe = Sample and Aggregation functions</summary></entry><entry><title type="html">Learning Graph Neural Networks with Deep Graph Library</title><link href="https://teju85.github.io/blog/2020/06/18/dgl-webconf-2020.html" rel="alternate" type="text/html" title="Learning Graph Neural Networks with Deep Graph Library" /><published>2020-06-18T00:00:00+05:30</published><updated>2020-06-18T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/18/dgl-webconf-2020</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/18/dgl-webconf-2020.html">&lt;p&gt;Recording of the talk can be found &lt;a href=&quot;https://www.youtube.com/watch?v=bD6S3xUXNds&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;overview-of-graph-neural-networks&quot;&gt;Overview of Graph Neural Networks&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Tasks in graph learning
    &lt;ul&gt;
      &lt;li&gt;node classification (fraud detection)&lt;/li&gt;
      &lt;li&gt;link prediction (eg: recsys)&lt;/li&gt;
      &lt;li&gt;graph classification (eg: drug discovery)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;graph learning has 2 steps:
    &lt;ul&gt;
      &lt;li&gt;generate low-dim embedding of node&lt;/li&gt;
      &lt;li&gt;use standard classifiers from there onwards&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;GNNs can learn node, edge, graph embeddings in an end-to-end fashion and are
based on message-passing between neighbors
    &lt;ul&gt;
      &lt;li&gt;aggregation operation needs to be permutation invariant&lt;/li&gt;
      &lt;li&gt;thereby these nets integrate node/edge/graph features as well as topology in
a non-linear fashion&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;for graph classification, there’ll be a final “readout” layer to compute the
overall graph embedding based on embeddings of each node&lt;/li&gt;
  &lt;li&gt;training of large graphs is done via mini-batch training
    &lt;ul&gt;
      &lt;li&gt;with pruning of neighborhood via sampling to reduce computational complexity&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;deep-graph-library---an-update&quot;&gt;Deep Graph Library - an update&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/dgl/01-dgl-stack.png&quot; alt=&quot;DGL stack&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;already having active customers using DGL via AWS Sagemaker&lt;/li&gt;
  &lt;li&gt;started out with multiple backends&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;flexible-message-propagation&quot;&gt;flexible message propagation&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/dgl/02-flexible-message-handling.png&quot; alt=&quot;Flexible message handling&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;full propagation&lt;/li&gt;
  &lt;li&gt;propagation by graph traversal: sampling on ego-network&lt;/li&gt;
  &lt;li&gt;propagation by random walk&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;dgl-programming-interface&quot;&gt;DGL programming interface&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/dgl/03-dgl-api.png&quot; alt=&quot;DGL API&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt; is the core abstraction
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph.ndata[&quot;h&quot;]&lt;/code&gt; - the node representation matrix&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;simple and flexible message passing APIs
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;active set&lt;/em&gt; - set of nodes/edges to trigger computation on&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;three user defined functions
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\phi^v&lt;/script&gt; - transformation function on vertices&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\bigoplus&lt;/script&gt; - reduction or aggregation function&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\phi^e&lt;/script&gt; - transformation function on edges&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;update_all&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;shortcut for &lt;code class=&quot;highlighter-rouge&quot;&gt;send(G.edges()); recv(G.nodes());&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;in other words, do a full propagation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;now heterogeneous graph is supported&lt;/li&gt;
  &lt;li&gt;new sampling API is introduced in v0.43 release&lt;/li&gt;
  &lt;li&gt;next plan is to look at distributed training&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;using-gnns-for-basic-graph-tasks&quot;&gt;Using GNNs for basic graph tasks&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;using Zachary’s karate class network to demo APIs of DGL&lt;/li&gt;
  &lt;li&gt;DGL expects node id’s to be consecutive integers starting from 0&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.graph&lt;/code&gt; is the main graph structure which provides IO and query methods&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.graph.ndata&lt;/code&gt; member is a dict that holds node features as tensor&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.graph.edata&lt;/code&gt; member is a dict that holds edge features as tensor&lt;/li&gt;
  &lt;li&gt;definition of models (and their training) in dgl is similar to pytorch&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How to customize graph-conv using message passing APIs&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.graph.ndata&lt;/code&gt; (and &lt;code class=&quot;highlighter-rouge&quot;&gt;edata&lt;/code&gt;) can be locally updated using
&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.graph.local_scope()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Message passing APIs in DGL are a generalization as found in
&lt;em&gt;Message Passing Neural Network&lt;/em&gt;s. The relevant equations are as follows:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;m_{uv}^{(l)} = Message^{(l)}(h_u^{(l-1)}, h_v^{(l-1)}, e_{uv}^{(l)})&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;m_v^{(l)} = Aggregation_{u \epsilon N(v)}(m_{uv}^{(l)})&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^{(l)} = Update^{(l)}(h_v^{(l-1)}, m_v^{(l)})&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;scale-gnn-to-giant-graphs-using-dgl&quot;&gt;Scale GNN to giant graphs using DGL&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;for large batches it is recommended to use mini-batch training procedure&lt;/li&gt;
  &lt;li&gt;minibatch generation on graphs
    &lt;ul&gt;
      &lt;li&gt;sample the target nodes
        &lt;ul&gt;
          &lt;li&gt;not done inside DGL&lt;/li&gt;
          &lt;li&gt;using &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy.random.choice&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.utils.data.DataLoader&lt;/code&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;randomly sample the neighbors (multi-hop)
        &lt;ul&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.sampling.sample_neighbors&lt;/code&gt; for one layer&lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.in_subgraph&lt;/code&gt; similar to the above, but will copy all edges&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;construct the minibatch
        &lt;ul&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.to_block&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;renames nodes to be consecutive (for memory efficiency as well as perf)&lt;/li&gt;
          &lt;li&gt;constructs a bipartite graph for message passing (COO format)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;to_block()&lt;/code&gt; has an option &lt;code class=&quot;highlighter-rouge&quot;&gt;include_dst_in_src&lt;/code&gt; to help with self-loops during
 aggregation&lt;/li&gt;
  &lt;li&gt;inference
    &lt;ul&gt;
      &lt;li&gt;we need to infer for all nodes in each layer&lt;/li&gt;
      &lt;li&gt;thus, inference is typically costlier than training!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dgl-on-real-world-applications&quot;&gt;DGL on real world applications&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;eg: recommender systems using GCMC&lt;/li&gt;
  &lt;li&gt;introduced traditional collaborative filtering based approaches&lt;/li&gt;
  &lt;li&gt;such a user-item matrix can be converted into bipartite graphs&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;apply_edges()&lt;/code&gt; computes edge features&lt;/li&gt;
  &lt;li&gt;heterogenous graphs:
    &lt;ul&gt;
      &lt;li&gt;graphs with different types of nodes and/or edges. (eg: user-item graphs)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.heterograph&lt;/code&gt; for creating such graphs&lt;/li&gt;
      &lt;li&gt;accessing node features is via: &lt;code class=&quot;highlighter-rouge&quot;&gt;g.nodes[&quot;ntype&quot;].data[&quot;name&quot;]&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;accessing edge features is via: &lt;code class=&quot;highlighter-rouge&quot;&gt;g.edges[&quot;etype&quot;].data[&quot;name&quot;]&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Recording of the talk can be found here.</summary></entry></feed>