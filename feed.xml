<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="https://teju85.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://teju85.github.io/blog/" rel="alternate" type="text/html" /><updated>2021-01-10T19:53:11+05:30</updated><id>https://teju85.github.io/blog/feed.xml</id><title type="html">Quagmire</title><subtitle>Stuff I find cool/useful</subtitle><entry><title type="html">Perfecting Patience</title><link href="https://teju85.github.io/blog/2021/01/10/perfecting-patience.html" rel="alternate" type="text/html" title="Perfecting Patience" /><published>2021-01-10T00:00:00+05:30</published><updated>2021-01-10T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2021/01/10/perfecting-patience</id><content type="html" xml:base="https://teju85.github.io/blog/2021/01/10/perfecting-patience.html">&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;In this book Dalai Lama discusses the Buddhist practices for perfecting patience
and tolerance, to help overcome anger and hatred. But I found that all the
techniques that he shows here can be practiced by Buddhists and non-Buddhists
alike. This book can be found
&lt;a href=&quot;https://www.penguinrandomhouse.com/books/576117/perfecting-patience-by-the-dalai-lama-translated-by-thupten-jinpa/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;h4 id=&quot;the-challenge-of-patience&quot;&gt;the challenge of patience&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;a moment of anger can destroy the lifetime of merit - Shantideva
    &lt;ul&gt;
      &lt;li&gt;at first this sounds far fetched and extreme, but if you take into account
the ripple effects of anger, this is certainly true&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;patience cannot be practiced in isolation but in our day to day interaction
with other people&lt;/li&gt;
  &lt;li&gt;patience can only be developed once we have some control over our anger&lt;/li&gt;
  &lt;li&gt;three characteristics of patience are tolerance:
    &lt;ul&gt;
      &lt;li&gt;based on conscious acceptance of pain and hardship, which helps in
understanding others pain and suffering and be compassionate towards them&lt;/li&gt;
      &lt;li&gt;resulting from reflecting on the nature of reality. The more we are attached
to something the more likely we get angry if we perceive a threat to it. We
need to realise that the actions of others are never done in isolation but
are related to the complex interdependencies in this world.&lt;/li&gt;
      &lt;li&gt;towards injuries from others. In reality, you cannot separate the person
from the circumstance that caused him to injure you and only hate him or get
angry at him. Shantideva goes a step further and asks us to consider these
enemies as very precious, since they are the ones who can help us practice
patience!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;there’s no evil like hatred. There’s no fortitude like patience&lt;/li&gt;
  &lt;li&gt;often the fuel for the anger is some form of discomfort. Finding this
connection is the first step towards controlling anger&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;day-one&quot;&gt;day one&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;compassion is a state of mind which is non-violent, non-aggressive and
non-harming.&lt;/li&gt;
  &lt;li&gt;one aspect of compassion is to respect others’ rights and their views.&lt;/li&gt;
  &lt;li&gt;hatred is pure evil as it involves having ill-will against others. Whereas
anger can be beneficial some times especially when it is fuelled by compassion&lt;/li&gt;
  &lt;li&gt;state of mind is crucial to enjoying our physical health, wealth and
friendship we have.&lt;/li&gt;
  &lt;li&gt;The only thing that protects us from the destructive effects of anger and
hatred is tolerance and patience&lt;/li&gt;
  &lt;li&gt;to practice tolerance and patience is to seek the causal factors/conditions
responsible for the origin of anger and hatred, then eliminate those instead
of directly trying to go against these strong emotions&lt;/li&gt;
  &lt;li&gt;our natural tendency is to dislike suffering and like pleasure. So, any
discomfort/suffering physical or mental will eventually invoke nager and
hatred&lt;/li&gt;
  &lt;li&gt;there are only few causes for happiness, but many for suffering. So it is
better for us to increase our tolerance for suffering&lt;/li&gt;
  &lt;li&gt;eg: by being able to tolerate smaller harms, we can prepare ourselves to
tolerate greater ones in future&lt;/li&gt;
  &lt;li&gt;hatred, anger and attachment are rooted in ignorance&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;day-two&quot;&gt;day two&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;unwholesome actions are the ones done through undisciplined state of mind, and
vice-versa&lt;/li&gt;
  &lt;li&gt;practice of patience and tolerance; love and compassion; complement and
reinforce each other&lt;/li&gt;
  &lt;li&gt;true hero is the one who gains victory over hatred and anger&lt;/li&gt;
  &lt;li&gt;by meditating on suffering, one can develop empathy towards the others, which
will in turn help us to be more patient and tolerant&lt;/li&gt;
  &lt;li&gt;We hold grudge on animate objects and never on inanimate objects like
illnesses, when the latter can equally do us harm. Just like the latter, the
former could also have caused the ill-will or hatred that are out of their
control&lt;/li&gt;
  &lt;li&gt;imagine someone close to you losing temper and thereby turning into an “ugly”
being. Then meditate on the effects of such an outrage and realise the
importance of patience and tolerance&lt;/li&gt;
  &lt;li&gt;many of the harmful acts are not done with malicious intent but out of pure
ignorance or carelessness&lt;/li&gt;
  &lt;li&gt;being angry at disturbed people who harm others is like getting angry at fire
for burning&lt;/li&gt;
  &lt;li&gt;being angry at people who harm when under circumstances out of their control
is like blaming the sky for the overcast of clouds&lt;/li&gt;
  &lt;li&gt;why should we only hate the person who hits us with a stick and not instead
hate the stick and the circumstances that are also responsible for his act?&lt;/li&gt;
  &lt;li&gt;we too might have similarly caused pain to others so it is just right that we
too receive the same from others, right?&lt;/li&gt;
  &lt;li&gt;one’s pain is one’s own creation&lt;/li&gt;
  &lt;li&gt;many of us take petty things too seriously and things which have grave impact
on us very lightly!&lt;/li&gt;
  &lt;li&gt;if someone is insulting us, it doesn’t cause bodily harm. So, why should our
minds be bothered with such acts?&lt;/li&gt;
  &lt;li&gt;imagine someone who gets on your nerves says something that irritates you.
Further imagine your natural response to it and then observe the sequence of
events that can unfold due to it. Now, meditate on what would have happened of
you were to practice tolerance instead.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;day-three&quot;&gt;day three&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;if the person who’s at the recieving end of the harm also gets angry
(ignorantly) with the perpetrator, then both these people are in the same
category&lt;/li&gt;
  &lt;li&gt;just like how we remove all the fire-spreading materials from a burning house
to reduce its spread, we should also do similar thing in order to stop the
spread of hatred. Eg: attachment is the root of hatred&lt;/li&gt;
  &lt;li&gt;if one observes carefully, one can see that the reason all conflicts and
fights arise even inside a family is because of strong attachment&lt;/li&gt;
  &lt;li&gt;if we fall ill, worrying and feeling sorry for ourselves will only add
additional mental burden&lt;/li&gt;
  &lt;li&gt;we also cannot blame everything on karma and take a passive attitude towards
life!&lt;/li&gt;
  &lt;li&gt;visualize a person suffering badly. Now relate yourself to that person and try
to share their suffering. Now make a resolution that you’ll help all such
sentient beings&lt;/li&gt;
  &lt;li&gt;when we hear our enemies being praised by others, we shouldn’t be angry or
jealous about it. Instead we should feel happy that this enemy has atleast
made someone else happy&lt;/li&gt;
  &lt;li&gt;if we expect others to be happy when we are praised, then it’s logical to
reciprocate the same when others are being praised too&lt;/li&gt;
  &lt;li&gt;worrying when our fame/recognition decline is just like children who cry when
their sandcastle topples down&lt;/li&gt;
  &lt;li&gt;our ultimate goal is the freedom from suffering. We shouldn’t be distracted
from it due to material gain and honor&lt;/li&gt;
  &lt;li&gt;there are opportunities for practising generosity but very few for patience.
So we need to be grateful when there are enemies who inflict harm onto us&lt;/li&gt;
  &lt;li&gt;in your meditation practice the act of give-and-take. Visualize a very
afflicted individual and give him all your successes whereas take all his
sufferings&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;day-four&quot;&gt;day four&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;interaction with sentient beings are very much needed for us to practice
tolerance and patience.&lt;/li&gt;
  &lt;li&gt;thus one can argue that we should value sentient beings more than the Buddha’s
for their contribution towards our perfection of these virtuous values&lt;/li&gt;
  &lt;li&gt;in your meditation, practice thoughtlessness. By default our mind is always
focused on external objects, because of sensory experience. Try to focus
inward. Since there’s no object to focus on, there’s always the chance of
falling asleep! Start by concentrating on your breath and then do meditation.&lt;/li&gt;
  &lt;li&gt;a childish compassion is one where we are compassionate towards the sufferings
of sentient beings but when we come across successful people we become envious
of them&lt;/li&gt;
  &lt;li&gt;people with worldly success are plagued by mental/emotional pains whereas the
poor are plagued by physical pains&lt;/li&gt;
  &lt;li&gt;this is because we are all under the power and influence of ignorance!&lt;/li&gt;
  &lt;li&gt;meditate on the concept of “self”. Self is an aggregation of all our
experiences. There’s always a difference between what we perceive and what the
reality is. The conclusion here is that things are not independent or inherent
as we think of them as. But instead, things are dependent on other factors.
This is what is meant by meditating on emptiness.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="self-help" /><summary type="html">Introduction In this book Dalai Lama discusses the Buddhist practices for perfecting patience and tolerance, to help overcome anger and hatred. But I found that all the techniques that he shows here can be practiced by Buddhists and non-Buddhists alike. This book can be found here.</summary></entry><entry><title type="html">Pranic Energization Technique</title><link href="https://teju85.github.io/blog/2020/12/29/pet.html" rel="alternate" type="text/html" title="Pranic Energization Technique" /><published>2020-12-29T00:00:00+05:30</published><updated>2020-12-29T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/12/29/pet</id><content type="html" xml:base="https://teju85.github.io/blog/2020/12/29/pet.html">&lt;h3 id=&quot;pranic-energization-technique&quot;&gt;Pranic Energization Technique&lt;/h3&gt;
&lt;p&gt;PET (short for “Pranic Energization Technique”) is a book written by
Dr. H. R. Nagendra to show how to use our Prana Shakthi to energize the whole
body and reversing the long-term effects of negative thoughts. This book can be
found &lt;a href=&quot;https://www.amazon.com/Pranic-Energisation-Technique-PET-Nagendra/dp/8187313102&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;h4 id=&quot;intro&quot;&gt;Intro&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;PET - short for Pranic Energization Technique.&lt;/li&gt;
  &lt;li&gt;It is the usage of Prana Shakthi to energize our entire body&lt;/li&gt;
  &lt;li&gt;It is an advanced form of yoga&lt;/li&gt;
  &lt;li&gt;Prana (life) manifests itself in 5 functional forms in our body:
    &lt;ul&gt;
      &lt;li&gt;Prana - which controls upper body and respiration&lt;/li&gt;
      &lt;li&gt;Apana - which controls lower body and excretion&lt;/li&gt;
      &lt;li&gt;Samana - controls abdominal region and digestion&lt;/li&gt;
      &lt;li&gt;Udana - controls upwards movements like belching, vomiting, etc&lt;/li&gt;
      &lt;li&gt;Vyana - one which controls touch and is all through the body&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;breath-awareness&quot;&gt;Breath awareness&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;first step towards realizing Prana Shakthi in PET.&lt;/li&gt;
  &lt;li&gt;respiration involves 3 phases
    &lt;ul&gt;
      &lt;li&gt;inspiration aka Puraka&lt;/li&gt;
      &lt;li&gt;hold aka Kumbhaka&lt;/li&gt;
      &lt;li&gt;expiration aka Rechaka&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;start by noticing the breath (to recognize any imbalances or irregularities)
    &lt;ul&gt;
      &lt;li&gt;sit in any comfortable position or Shavasana&lt;/li&gt;
      &lt;li&gt;start watching the breath at the top of the nose&lt;/li&gt;
      &lt;li&gt;recognize any imbalances in breath (eg: breath flow between 2 nostrils), but
don’t control them&lt;/li&gt;
      &lt;li&gt;observe breath becoming continuous, regular and smooth&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;just the act of observing these imbalances helps in reducing them&lt;/li&gt;
  &lt;li&gt;it is believed that left nostril breathing promotes right-lobe of brain and
vice-versa. In yoga:
    &lt;ul&gt;
      &lt;li&gt;left nostril breathing implies Chandra Nadi Prana flow, which is soothing in
nature&lt;/li&gt;
      &lt;li&gt;right nostril breathing implies Surya Nadi Prana flow, which is energizing
in nature&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Nadi Shuddhi Pranayama
    &lt;ul&gt;
      &lt;li&gt;a balancing technique for breathing&lt;/li&gt;
      &lt;li&gt;take up Sthiti posture&lt;/li&gt;
      &lt;li&gt;adopt Nasika Mudra in right hand&lt;/li&gt;
      &lt;li&gt;inhale through left nostril while closing right nostril with the thumb&lt;/li&gt;
      &lt;li&gt;enjoy the Kevala Kumbhaka&lt;/li&gt;
      &lt;li&gt;open the right nostril and exhale while closing the left nostril via the
ring and index fingers&lt;/li&gt;
      &lt;li&gt;enjoy the Kevala Kumbhaka&lt;/li&gt;
      &lt;li&gt;repeat vice-versa on the other side&lt;/li&gt;
      &lt;li&gt;repeat the whole thing for 9 rounds&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Kapalabhathi
    &lt;ul&gt;
      &lt;li&gt;for folks with nasal blockage or observing drowsiness during Nadi Shuddhi
Pranayama can instead practice this&lt;/li&gt;
      &lt;li&gt;cleanses respiratory tract and stimulates brain cells&lt;/li&gt;
      &lt;li&gt;sit in Vajrasana or Padmasana&lt;/li&gt;
      &lt;li&gt;adopt Nasika Mudra in right hand&lt;/li&gt;
      &lt;li&gt;close right nostril with the thumb and breathe in fully through the left
nostril while bulging the abdominal muscles (aka diaphragmatic breathing)&lt;/li&gt;
      &lt;li&gt;close the left nostril with little and ring fingers. Open the right nostril&lt;/li&gt;
      &lt;li&gt;exhale with a burst as fast as possible by sucking in abdominal muscles&lt;/li&gt;
      &lt;li&gt;repeat vice-versa on the other side&lt;/li&gt;
      &lt;li&gt;repeat the whole for 60 rounds (at a speed of 60 rounds per minute)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cautions with Kapalabhati practive
    &lt;ul&gt;
      &lt;li&gt;always do this under empty stomach only&lt;/li&gt;
      &lt;li&gt;don’t contort facial muscles&lt;/li&gt;
      &lt;li&gt;don’t twist nostrils&lt;/li&gt;
      &lt;li&gt;don’t practice if: having high BP, IHD, slip disk, under menstruation, under
pregnancy, spondylosis, etc&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;awareness-and-relaxation&quot;&gt;Awareness and relaxation&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;improving awareness and sensitivity
    &lt;ul&gt;
      &lt;li&gt;start with pointed awareness (aka attention)&lt;/li&gt;
      &lt;li&gt;carefully trace the movement of breath from nose tip all the way to the lungs
and back. Feel the coolness of air while inspiration and warmness during the
expiration.&lt;/li&gt;
      &lt;li&gt;reach a stage of maintaining continuous line of awareness through the path of
breathing&lt;/li&gt;
      &lt;li&gt;gradually expand this linear awareness to the inner surfaces of the entire
respiratory tract&lt;/li&gt;
      &lt;li&gt;notice that the breathing stops during end of inhalation and start of
exhalation and vice-versa (aka Kevala Kumbhaka). This induces deep rest and
relaxation&lt;/li&gt;
      &lt;li&gt;we can now start feeling our heart beat, pulses in blood vessels. This is the
state of 3D awareness, over the entire body&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bhramari Pranayama
    &lt;ul&gt;
      &lt;li&gt;while exhaling produce a humming sound, like a bee&lt;/li&gt;
      &lt;li&gt;elongate the duration of humming/breathing without disturbing the flow&lt;/li&gt;
      &lt;li&gt;enjoy the Kevala Kumbhaka and the sound vibrations throughout the body&lt;/li&gt;
      &lt;li&gt;repeat for 9 times&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Resonance in Bhramari is the key thing. We should adjust our frequency of the
produced sound so as to feel the resonance throughout the body.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;sensitization-recognition-and-vyana&quot;&gt;Sensitization, Recognition and Vyana&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Mudras - yogic practice to evoke Prana and further sensitize and recognizing
nerve impulses.&lt;/li&gt;
  &lt;li&gt;Kriya Mudras - for cleansing&lt;/li&gt;
  &lt;li&gt;Asana Mudras - practised with breath locks to clam the mind&lt;/li&gt;
  &lt;li&gt;Pranayama Mudras - associated during pranayama in order to sensitize vyana.&lt;/li&gt;
  &lt;li&gt;Sakthi Calini Mudras - to invoke dormant powers within us&lt;/li&gt;
  &lt;li&gt;Dhyana Mudras - for meditation&lt;/li&gt;
  &lt;li&gt;Jnana Mudras - for Rsis&lt;/li&gt;
  &lt;li&gt;Recognition of nerve impulses - in PET Adi, Cin, Cinmaya and
Namaskara mudras are used for this purpose
    &lt;ul&gt;
      &lt;li&gt;sit in a comfortable position and relax the whole body&lt;/li&gt;
      &lt;li&gt;place hands on thighs and adopt Cin mudra&lt;/li&gt;
      &lt;li&gt;observe pulse and heart beat sync&lt;/li&gt;
      &lt;li&gt;open the fingers in Cin mudra and touch again, now recognize the nerve
impulses going from fingers to the brain&lt;/li&gt;
      &lt;li&gt;now adopt Cinmaya mudra&lt;/li&gt;
      &lt;li&gt;press and release the other fingers and feel the impulses (repeat 9 rounds)&lt;/li&gt;
      &lt;li&gt;adopt Adi mudra and repeat this press and releas process&lt;/li&gt;
      &lt;li&gt;similarly adopt Namaskara mudra and repeat&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Recognition of Vyana: nerve impulses is always unidirectional, to the brain
and they travel at a fixed speed. Vyana has none of these limitations.
    &lt;ul&gt;
      &lt;li&gt;move the palms in and out, bring the palms as close as ~2cms gap between.
Feel that region between the palms getting sensitized. We are experiencing
Vyana in this space. Now rotate both palms clock and anti-clock wise in
order to churn Vyana.&lt;/li&gt;
      &lt;li&gt;it is this perception of Vyana that will be utilized to energize our systems
and also to improve our immune system.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;rotation-and-energization&quot;&gt;Rotation and Energization&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Yoga provides a holistic solution to improving our immune system, which is
known to get degraded due to stresses in our daily lives.
    &lt;ul&gt;
      &lt;li&gt;first level is handling at the body level by performing various asanas in
order to improve flexibility and release stress&lt;/li&gt;
      &lt;li&gt;second level is by slowing and balancing of breath through pranayama&lt;/li&gt;
      &lt;li&gt;third level is by handling at emotional and mental levels through yoga nidra
and cyclic meditation&lt;/li&gt;
      &lt;li&gt;fourth level is by using the wisdom from Upanishads to correct our notions
about happiness, life, misery and death.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;rotating and energization of vyana
    &lt;ul&gt;
      &lt;li&gt;place the palms on the knees&lt;/li&gt;
      &lt;li&gt;start moving prana from right heel to right calf, right thigh, right buttock
right back and similarly start moving prana from right hand to arm to shoulder
to joints to neck to back of the head, top of head and then coming down from
the front right side of the body all the way back to heel and fingers&lt;/li&gt;
      &lt;li&gt;repeat this for the left side&lt;/li&gt;
      &lt;li&gt;now rotate prana simultaneously from both sides&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;growth-and-levels-of-consciousness&quot;&gt;growth and levels of consciousness&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;silence is a state in which the mind, body, prana, emotions and intellect are
completely nullified and are unified with the universe&lt;/li&gt;
  &lt;li&gt;practicing silence
    &lt;ul&gt;
      &lt;li&gt;feel the prana around the body expanding and diffusing into the blue sky&lt;/li&gt;
      &lt;li&gt;experience the bliss associated with it&lt;/li&gt;
      &lt;li&gt;stay for as long as you can&lt;/li&gt;
      &lt;li&gt;if other thoughts come up, focus back on the difussion of prana into the sky&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;harnessing-the-will-and-resolution&quot;&gt;harnessing the will and resolution&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;resolution is a clear and positive thought (eg: I’m ever happy)&lt;/li&gt;
  &lt;li&gt;we are what we think we are. Such is the power of a thought!&lt;/li&gt;
  &lt;li&gt;So, a strong positive resolution is very essential&lt;/li&gt;
  &lt;li&gt;to be happy, at a state of bliss is everyone’s birthright. All the negative
states are unnatural&lt;/li&gt;
  &lt;li&gt;mind is the cause for both bondage and freedom. Our thoughts can transform us&lt;/li&gt;
  &lt;li&gt;for maximal effect, such a positive resolve needs to be made when we are in
the blissful state of silence (as described earlier)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;prananusandhana-and-quality-of-life&quot;&gt;prananusandhana and quality of life&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;PET is best practiced half hour during morning and evening of each day&lt;/li&gt;
  &lt;li&gt;but for best results, we should spread the experience of prana throughout the
day (aka Anusandhana - act of recollection of prana for revitalizing the whole
being)&lt;/li&gt;
  &lt;li&gt;steps are as follows
    &lt;ul&gt;
      &lt;li&gt;build an awareness of breath throughout the day. Make sure that the breath
is balanced between the 2 nostrils&lt;/li&gt;
      &lt;li&gt;expand the awareness of breath throughout the respiratory tract&lt;/li&gt;
      &lt;li&gt;feel the nerve impulses&lt;/li&gt;
      &lt;li&gt;sensitize further to feel vyana, spread it throughout the body&lt;/li&gt;
      &lt;li&gt;apply rotate and control of vyana flows in order to balance it all across&lt;/li&gt;
      &lt;li&gt;enjoy the diffusion of vyana beyond the body&lt;/li&gt;
      &lt;li&gt;retain this blissful awareness of prana throughout the day&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;continuously introspect and track the growth (if we can measure it, we
certainly can improve it!)&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="yoga" /><category term="health" /><summary type="html">Pranic Energization Technique PET (short for “Pranic Energization Technique”) is a book written by Dr. H. R. Nagendra to show how to use our Prana Shakthi to energize the whole body and reversing the long-term effects of negative thoughts. This book can be found here.</summary></entry><entry><title type="html">Accelerating 2-opt and 3-opt local search using GPU in TSP</title><link href="https://teju85.github.io/blog/2020/12/07/2-opt-3-opt-TSP.html" rel="alternate" type="text/html" title="Accelerating 2-opt and 3-opt local search using GPU in TSP" /><published>2020-12-07T00:00:00+05:30</published><updated>2020-12-07T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/12/07/2-opt-3-opt-TSP</id><content type="html" xml:base="https://teju85.github.io/blog/2020/12/07/2-opt-3-opt-TSP.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;http://olab.is.s.u-tokyo.ac.jp/~kamil.rocki/rocki_hpcs2012.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;proposal to parallelize 2-opt and 3-opt swaps on GPUs, over-and-above the
parallelization strategy discussed in &lt;a href=&quot;/blog/2020/12/06/parallel-tsp.html&quot;&gt;this&lt;/a&gt;
paper.&lt;/li&gt;
  &lt;li&gt;they also further note that due to global memory access latencies, it is
faster to recompute the distances by each thread, instead of pre-computing
them.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;make each block work on a particular climber and have each thread inside it
work on multiple possible pairs (or triplets).&lt;/li&gt;
  &lt;li&gt;then finally do a block-wide reduction to compute the best swap.&lt;/li&gt;
  &lt;li&gt;this approach helps them to utilize shared memory for storing the city
co-ordinates, as well as for storing the best path&lt;/li&gt;
  &lt;li&gt;they also note that pre-computing the distance matrix and accessing them while
doing 2-opt/3-opt swaps leads to random accesses and thereby causing perf
degradation.&lt;/li&gt;
  &lt;li&gt;thus, instead they propose to recompute this value from the input coordinates
by all threads during the process of swap&lt;/li&gt;
  &lt;li&gt;the number of cities they can support with this approach is only limited by
the available shared memory capacity on the chip.&lt;/li&gt;
  &lt;li&gt;the authors however do not talk about the number of climbers used in their
code or even the algorithm used by them (I &lt;em&gt;think&lt;/em&gt; it is IHC as used in the
base paper mentioned above).&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="cuda" /><category term="tsp" /><summary type="html">Proposal Main paper can be found here.</summary></entry><entry><title type="html">Parallel GPU version of TSP</title><link href="https://teju85.github.io/blog/2020/12/06/parallel-tsp.html" rel="alternate" type="text/html" title="Parallel GPU version of TSP" /><published>2020-12-06T00:00:00+05:30</published><updated>2020-12-06T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/12/06/parallel-tsp</id><content type="html" xml:base="https://teju85.github.io/blog/2020/12/06/parallel-tsp.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://userweb.cs.txstate.edu/~burtscher/papers/pdpta11b.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An optimized GPU version of TSP solver using Iterative Hill Climbing (IHC)
technique&lt;/li&gt;
  &lt;li&gt;Paper limits itself to 100-cities with 100,000 random restarts.&lt;/li&gt;
  &lt;li&gt;However, the techniques suggested here can be generalized&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;each thread works on one of the climbers.
    &lt;ul&gt;
      &lt;li&gt;continues to perform the 4851 2-opt moves in each IHC step, until convergence&lt;/li&gt;
      &lt;li&gt;FYI, &lt;script type=&quot;math/tex&quot;&gt;4851 = \frac{(100 - 1) * (100 - 2)}{2}&lt;/script&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;after convergence of each climber, a global atomicCAS is performed in order to
update the best solution found so far&lt;/li&gt;
  &lt;li&gt;they only compute the incremental TSP cost instead of computing the full path
cost inside IHC step and only compute the global path cost after convergence&lt;/li&gt;
  &lt;li&gt;all threads continue to fetch their next climber from a global queue until it
is exhausted&lt;/li&gt;
  &lt;li&gt;distance matrix is assumed to be pre-computed (for edge weights)&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="cuda" /><category term="tsp" /><summary type="html">Proposal Main paper can be found here.</summary></entry><entry><title type="html">cmake on cygwin</title><link href="https://teju85.github.io/blog/2020/09/12/cmake-on-cygwin.html" rel="alternate" type="text/html" title="cmake on cygwin" /><published>2020-09-12T00:00:00+05:30</published><updated>2020-09-12T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/09/12/cmake-on-cygwin</id><content type="html" xml:base="https://teju85.github.io/blog/2020/09/12/cmake-on-cygwin.html">&lt;h3 id=&quot;correctly-installing-cmake-on-cygwin&quot;&gt;correctly installing cmake on cygwin&lt;/h3&gt;
&lt;p&gt;I have had this issue when I install cmake on cygwin&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt-cyg &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;cmake
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;cmake &lt;span class=&quot;nt&quot;&gt;--version&lt;/span&gt;
CMake Error: Could not find CMAKE_ROOT &lt;span class=&quot;o&quot;&gt;!!!&lt;/span&gt;
CMake has most likely not been installed correctly.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When I try to find where all cygwin is installed, here’s the output:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;which &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; cmake
/bin/cmake
/usr/bin/cmake
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When I now update my &lt;code class=&quot;highlighter-rouge&quot;&gt;PATH&lt;/code&gt; environment variable to instead prioritize the
&lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/bin&lt;/code&gt; folder, by doing: &lt;code class=&quot;highlighter-rouge&quot;&gt;export PATH=/usr/bin:$PATH&lt;/code&gt; at the end of my
&lt;code class=&quot;highlighter-rouge&quot;&gt;.bashrc&lt;/code&gt; file, I’m now able to get cmake working.&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;which &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; cmake
/usr/bin/cmake
/bin/cmake
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;cmake &lt;span class=&quot;nt&quot;&gt;--version&lt;/span&gt;
cmake version 3.6.2

CMake suite maintained and supported by Kitware &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;kitware.com/cmake&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;My guess is that when &lt;code class=&quot;highlighter-rouge&quot;&gt;cmake&lt;/code&gt; gets resolved to &lt;code class=&quot;highlighter-rouge&quot;&gt;/bin&lt;/code&gt; folder, it somehow gets
confused while finding cmake modules, leading to the above error.&lt;/p&gt;</content><author><name></name></author><category term="tools" /><summary type="html">correctly installing cmake on cygwin I have had this issue when I install cmake on cygwin $ apt-cyg install cmake $ cmake --version CMake Error: Could not find CMAKE_ROOT !!! CMake has most likely not been installed correctly.</summary></entry><entry><title type="html">Graph Convolutional Networks for text classification</title><link href="https://teju85.github.io/blog/2020/08/16/text-gcn.html" rel="alternate" type="text/html" title="Graph Convolutional Networks for text classification" /><published>2020-08-16T00:00:00+05:30</published><updated>2020-08-16T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/08/16/text-gcn</id><content type="html" xml:base="https://teju85.github.io/blog/2020/08/16/text-gcn.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1809.05679.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;novel GNN based method for text classification&lt;/li&gt;
  &lt;li&gt;graph is constructed using word co-occurence and word-doc associations&lt;/li&gt;
  &lt;li&gt;learn both word and doc (aka corpus) embeddings simultaneously by building and
using the above mentioned heterogenous text graph, where nodes are both words
and docs&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;text graph construction
    &lt;ul&gt;
      &lt;li&gt;based on word co-occurence (in corpus) and doc-word relations&lt;/li&gt;
      &lt;li&gt;number of nodes = vocab size + corpus size&lt;/li&gt;
      &lt;li&gt;input embeddings are just one-hot vectors&lt;/li&gt;
      &lt;li&gt;edge weights
        &lt;ul&gt;
          &lt;li&gt;doc to word = TFIDF&lt;/li&gt;
          &lt;li&gt;word to word = &lt;script type=&quot;math/tex&quot;&gt;PMI(i, j)&lt;/script&gt; only if &lt;script type=&quot;math/tex&quot;&gt;PMI(i, j)&lt;/script&gt; is positive and words
i and j occur in the sliding window together&lt;/li&gt;
          &lt;li&gt;self-loops are added&lt;/li&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;PMI(i, j) = log\frac{P_{ij}}{P_i P_j}&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;P_{ij} = \frac{nW(i, j)}{nW}&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;P(i) = \frac{nW(i)}{nW}&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;nW&lt;/script&gt; = total number of sliding windows&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;model and training
    &lt;ul&gt;
      &lt;li&gt;usage of spectral GCNs as in Kipf and Welling&lt;/li&gt;
      &lt;li&gt;2 layer GCNs&lt;/li&gt;
      &lt;li&gt;output layer is psased through softmax classifier&lt;/li&gt;
      &lt;li&gt;loss function is cross entropy error over all labelled docs
        &lt;ul&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;L = - \Sigma_d \Sigma_f Y_{df} ln(Z_{df})&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; = all labelled docs&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; = all output features&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; = label vector for a doc&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; = softmax output vector&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;2 layers help information exchange between docs too!&lt;/li&gt;
      &lt;li&gt;more layers didn’t help improving accuracy&lt;/li&gt;
      &lt;li&gt;sliding window size = 20 words&lt;/li&gt;
      &lt;li&gt;first layer output embedding size = 200&lt;/li&gt;
      &lt;li&gt;learning rate = 0.02&lt;/li&gt;
      &lt;li&gt;Adam optimizer with 200 epochs&lt;/li&gt;
      &lt;li&gt;early stopping after 10 epochs with no decrease in validation loss&lt;/li&gt;
      &lt;li&gt;dropout rate = 0.5&lt;/li&gt;
      &lt;li&gt;10% of training as validation set&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main paper can be found here.</summary></entry><entry><title type="html">Graph Attention Networks</title><link href="https://teju85.github.io/blog/2020/08/09/gat.html" rel="alternate" type="text/html" title="Graph Attention Networks" /><published>2020-08-09T00:00:00+05:30</published><updated>2020-08-09T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/08/09/gat</id><content type="html" xml:base="https://teju85.github.io/blog/2020/08/09/gat.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/abs/1710.10903&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;extension of attentional layers into GNNs&lt;/li&gt;
  &lt;li&gt;also the usage of multi-head attention into GNNs&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;compute attention coefficients as follows:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;e_{ij} = a(Wh_i, Wh_j)&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt; = weight matrix&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;h&lt;/script&gt; = embeddings of each nodes in the graph&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; = attention function to convert the input vectors into a scalar&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;normalize these across the neighborhood using softmax as follows:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_{ij} = \frac{exp(e_{ij})}{\Sigma_k exp(e_{ik})}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; varies over the neighborhood&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; varies across neighborhood&lt;/li&gt;
      &lt;li&gt;they use only 1-hop neighbors for this&lt;/li&gt;
      &lt;li&gt;but they don’t seem to suggest anything about sub-sampling of neighborhood!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;then finally apply weighted summation over the neighborhood based on the
computed attention values as follows:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;h'_i = \sigma(\Sigma_j \alpha_{ij} W h_j)&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; = non-linearity&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; varies across the neighborhood&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;they also propose to using multi-head attention as follows:
    &lt;ul&gt;
      &lt;li&gt;compute individual attentions for each head as above, independently&lt;/li&gt;
      &lt;li&gt;but at the end , take a concatentaion of resulting embeddings from
each of the heads&lt;/li&gt;
      &lt;li&gt;and in the final layer, instead of concatenating, perform a summation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;a full equation involving attention computation for a single head is:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_{ij} = \frac{exp(lr(a . h'_{ij}))}{\Sigma_k exp(lr(a . h'_{ik}))}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; varies over the neighborhood&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; varies over the neighborhood&lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;h'_{ij} = concat(Wh_i, Wh_j)&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;lr&lt;/script&gt; = LeakyReLu. (with a negative slope of 0.2)&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; = learnable vector used for dot product with the concatenated vector&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main paper can be found here.</summary></entry><entry><title type="html">PairNorm: tackling oversmoothing in GNNs</title><link href="https://teju85.github.io/blog/2020/08/06/pairnorm.html" rel="alternate" type="text/html" title="PairNorm: tackling oversmoothing in GNNs" /><published>2020-08-06T00:00:00+05:30</published><updated>2020-08-06T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/08/06/pairnorm</id><content type="html" xml:base="https://teju85.github.io/blog/2020/08/06/pairnorm.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/abs/1909.12223&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a new pairnorm layer which normalizes the intermediate embeddings to avoid
oversmoothing (OS)&lt;/li&gt;
  &lt;li&gt;allows deeper layers possible for GNNs&lt;/li&gt;
  &lt;li&gt;requires no extra learnable parameters (except for one hyper-param)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;deeper GNNs show gradual loss in accuracy due to
    &lt;ul&gt;
      &lt;li&gt;vanishing gradients&lt;/li&gt;
      &lt;li&gt;overfitting due to increased learnable params&lt;/li&gt;
      &lt;li&gt;OS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;OS?
    &lt;ul&gt;
      &lt;li&gt;phenomenon where node embeddings become very similar to each other&lt;/li&gt;
      &lt;li&gt;it is a form of laplacian smoothing&lt;/li&gt;
      &lt;li&gt;for shallow nets things are fine as the clusters of nodes will correctly get
similar embeddings&lt;/li&gt;
      &lt;li&gt;however, for deeper nets, there’ll be inter-cluster mixing (aka node-wise
smoothing)&lt;/li&gt;
      &lt;li&gt;also, repeatedly applying convlutions (or laplacian smoothing) washes out
all the signals in the features (feature-wise smoothing)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;in order to study the effects of OS, the authors do the following experiment
    &lt;ul&gt;
      &lt;li&gt;take a SGC but strip it out of all transformation layers&lt;/li&gt;
      &lt;li&gt;thus there’ll be no effect of overfitting or vanishing gradients&lt;/li&gt;
      &lt;li&gt;they plot the following 2 metrics in order to show the OS behavior&lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;rowdiff(H^{(k)}) = \frac{1}{n^2} \Sigma_{i,j} \Sigma_p (H_{ip}^{(k)} - H_{jp}^{(k)})^2&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;coldiff(H^{(k)}) = \frac{1}{d^2} \Sigma_{i,j} \Sigma_p (\frac{H_{pi}}{\Sigma_q abs(H_{qi})} - \frac{H_{pj}}{\Sigma_q abs(H_{qj})})^2&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; = number of samples&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; = feature dimension&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;H^{(k)}&lt;/script&gt; = computed embedding at ‘k’th hop&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;authors then show the similarity of GNNs with Graph Regularized Least Squares
(GRLS) method&lt;/li&gt;
  &lt;li&gt;then extend GRLS loss function by adding a penalty term against inter-cluster
mixing, in order to minimize the effect of oversmoothing&lt;/li&gt;
  &lt;li&gt;they propose pairnorm to maintain the Total Pairwise Squared Distance (TPSD)
metric&lt;/li&gt;
  &lt;li&gt;pairnorm
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;x_{ik}^c = x_{ik} - \frac{\Sigma_i \Sigma_k x{ik}}{n}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;x'_{ik} = \frac{s x_{ik}^c}{\sqrt{\frac{1}{n} \Sigma_j \Sigma_p (x_{jp}^c)^2}}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt; = hyper-param controlling TPSD&lt;/li&gt;
      &lt;li&gt;works well for SGC&lt;/li&gt;
      &lt;li&gt;similar to batch-norm layer but without the final scaling and bias&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;pairnorm-SI (scale individual)
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;x'_{ik} = \frac{s x_{ik}^c}{\Sigma_p (x_{ip}^c)^2}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;works well for SGC, GAT and GCN&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main paper can be found here.</summary></entry><entry><title type="html">Learning representations of irregular particle-detector geometry with distance-weighted graph networks</title><link href="https://teju85.github.io/blog/2020/07/26/gravnet-garnet.html" rel="alternate" type="text/html" title="Learning representations of irregular particle-detector geometry with distance-weighted graph networks" /><published>2020-07-26T00:00:00+05:30</published><updated>2020-07-26T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/07/26/gravnet-garnet</id><content type="html" xml:base="https://teju85.github.io/blog/2020/07/26/gravnet-garnet.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1902.07987.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Usage of GNN’s for irregular-geometry detectors for particle reconstruction&lt;/li&gt;
  &lt;li&gt;propose 2 new distance-weighted GNN layers: GRAVNET, GARNET&lt;/li&gt;
  &lt;li&gt;open-source their work based on TF &lt;a href=&quot;https://github.com/jkiesele/caloGraphNN&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;proposed computations assume no structure-dependent info from the input data
and thus this could be generalizable for other tasks such as tracking, jet
identification, etc&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gravnet-and-garnet-layers&quot;&gt;gravnet and garnet layers&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;input: &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; of dimension &lt;script type=&quot;math/tex&quot;&gt;B . V . F_{in}&lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;B&lt;/script&gt; = number of elements in the batch&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt; = number of detector hits per element&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{in}&lt;/script&gt; = input feature dimension per hit&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;perform linear transformation with bias
    &lt;ul&gt;
      &lt;li&gt;dimension of a vector in &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; is &lt;script type=&quot;math/tex&quot;&gt;S + F_{lr}&lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; = learned spatial representation of input vector&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{lr}&lt;/script&gt; = learned attributes for the nodes in the resulting graph&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;graph construction: (done for each element)
    &lt;ul&gt;
      &lt;li&gt;gravnet - a kNN graph is constructed for each element in the batch, based on
the pairwise euclidean distances between all hits in that element.&lt;/li&gt;
      &lt;li&gt;garnet - each of the &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; values is considered as a distance from that hit
to an aggregator&lt;/li&gt;
      &lt;li&gt;the distance between jth vertex and kth vertex in such a graph is called as
&lt;script type=&quot;math/tex&quot;&gt;d_{jk}&lt;/script&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;gravent and garnet layer computations
    &lt;ul&gt;
      &lt;li&gt;scale the features based on a potential function &lt;script type=&quot;math/tex&quot;&gt;V_p&lt;/script&gt;
        &lt;ul&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{jk}^i = f_j^i V_p(d_{jk})&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;gravnet: &lt;script type=&quot;math/tex&quot;&gt;V_p(x) = e^{-x^2}&lt;/script&gt;&lt;/li&gt;
          &lt;li&gt;garnet: &lt;script type=&quot;math/tex&quot;&gt;V_p(x) = e^{-abs(x)}&lt;/script&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;aggregation of scaled features
        &lt;ul&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;f_k^i = agg_j(f_{jk}^i)&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;tried both max and mean&lt;/li&gt;
          &lt;li&gt;aggregation function which was most effective for their use-case was mean&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;transformation: (output dimension = &lt;script type=&quot;math/tex&quot;&gt;F_{out}&lt;/script&gt;
        &lt;ul&gt;
          &lt;li&gt;in case of garnet, each of these &lt;script type=&quot;math/tex&quot;&gt;f_k^i&lt;/script&gt; aggregator features will again
be weighted using similar equation in order to project them back to the
original vertices.&lt;/li&gt;
          &lt;li&gt;concatenate the input &lt;script type=&quot;math/tex&quot;&gt;F_{in}&lt;/script&gt; features with this &lt;script type=&quot;math/tex&quot;&gt;f_k^i&lt;/script&gt; feature&lt;/li&gt;
          &lt;li&gt;perform linear transformation with bias, followed by tanh activation&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;a custom loss function is defined based on the domain knowledge&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;models&quot;&gt;models&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;both a local and global exchange of message across sensors is proposed&lt;/li&gt;
  &lt;li&gt;gravnet model
    &lt;ul&gt;
      &lt;li&gt;has 4 blocks
        &lt;ul&gt;
          &lt;li&gt;concat mean of vertex features and vertex features&lt;/li&gt;
          &lt;li&gt;3 dense layers with tanh activation (dim = 64)&lt;/li&gt;
          &lt;li&gt;one gravnet layer&lt;/li&gt;
          &lt;li&gt;final dense layer with dim = 128 and relu activation&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;gravnet layer
        &lt;ul&gt;
          &lt;li&gt;‘k’ value for kNN-graph is set to 40&lt;/li&gt;
          &lt;li&gt;S = 4&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{lr}&lt;/script&gt; = 22&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{out}&lt;/script&gt; = 48&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;output of each block before the final dense layer is concatenated and then
passed to the final dense layer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;garnet model
    &lt;ul&gt;
      &lt;li&gt;has 4 blocks
        &lt;ul&gt;
          &lt;li&gt;concat mean of vertex features and vertex features&lt;/li&gt;
          &lt;li&gt;one dense layer with tanh activation (dim = 32)&lt;/li&gt;
          &lt;li&gt;11 garnet layers!&lt;/li&gt;
          &lt;li&gt;final dense layer with dim = 48 and relu activation&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;garnet layer
        &lt;ul&gt;
          &lt;li&gt;S = 4&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{lr}&lt;/script&gt; = 20&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;F_{out}&lt;/script&gt; = 32&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;output of each block before the final dense layer is concatenated and then
passed to the final dense layer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;batch norm is applied to the input and output of all blocks&lt;/li&gt;
  &lt;li&gt;for all these models, at the end, the following 2 layers are applied
    &lt;ul&gt;
      &lt;li&gt;a dense layer with dim = 3 and relu activation&lt;/li&gt;
      &lt;li&gt;another dense layer with dim = 2 and softmax activation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;trained using Adam optimizer&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main paper can be found here.</summary></entry><entry><title type="html">All about NVSHMEM</title><link href="https://teju85.github.io/blog/2020/07/17/nvhsmem.html" rel="alternate" type="text/html" title="All about NVSHMEM" /><published>2020-07-17T00:00:00+05:30</published><updated>2020-07-17T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/07/17/nvhsmem</id><content type="html" xml:base="https://teju85.github.io/blog/2020/07/17/nvhsmem.html">&lt;h1 id=&quot;nvshmem&quot;&gt;NVSHMEM&lt;/h1&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;
&lt;p&gt;API document can be found &lt;a href=&quot;https://docs.nvidia.com/hpc-sdk/nvshmem/api/docs/index.html&quot;&gt;here&lt;/a&gt;
and developer guide can be found &lt;a href=&quot;https://docs.nvidia.com/hpc-sdk/nvshmem/developer-guide/index.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;nvshmem is an extension of openshmem API for the GPU clusters. nvshmem provides
a PGAS (Partitioned Global Address Space) for the buffers on GPU cluster.
Enables fine-grained computation/communication overlap and also performing
synchronization, all from the CUDA kernels itself. Thus, this feature is very
helpful in achieving strong scaling on our apps. However, it also provides
CPU-side APIs to initiate communication, for flexibility.&lt;/p&gt;

&lt;h2 id=&quot;programming-model&quot;&gt;Programming model&lt;/h2&gt;
&lt;p&gt;Types of data objects&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Symmetric data objects - objects can be shared across remote PE’s. These are
allocated from a &lt;strong&gt;symmetric heap&lt;/strong&gt; using &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_malloc()&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Private data objects - objects that private to the PE which owns them&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;openshmem provides strong ordering guarantees. However, for perf reasons,
nvshmem doesn’t provide this guarantee and thus it is expected of the devs to
use &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_fence()&lt;/code&gt; when such an ordering is required! But, non-blocking calls
are not ordered with this call and for those, we need to use &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_quiet()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Execution model is typically SPMD (Single Program Multiple Data), but this is
not required by nvshmem. Work is done by PEs, which are typically OS processes.
These PEs are further allowed to create threads, if there’s a support for it.
nvshmem phase begins with the call to either &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_init()&lt;/code&gt; or
&lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_init_thread()&lt;/code&gt; and concludes with the call to &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_finalize()&lt;/code&gt;
done by all PEs or &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_global_exit()&lt;/code&gt; by any PE. We cannot reinitialize the
nvshmem after finalization! (similar to MPI) Each PE has an integer ID, similar
to the concept of MPI ranks.&lt;/p&gt;

&lt;p&gt;Since nvshmem provides one-sided communication API’s, even if the target PE is
not involved in any nvshmem calls, other PE’s can continue to communicate with
this PE and make progress. This is unlike MPI communication model.&lt;/p&gt;

&lt;p&gt;There’s also threadgroup communication with multiple threads can collectively be
part of a single communication operation.&lt;/p&gt;

&lt;p&gt;nvshmem expects all buffer arguments to nvhsmem communication routines to be
symmetric objects.&lt;/p&gt;

&lt;p&gt;symmetric address returned by nvhsmem allocation routine is also a valid local
addresses. However, trying to use a mix of symmetric address and local address
to nvshmem routines can lead to undefined behavior.&lt;/p&gt;

&lt;h2 id=&quot;communication-model&quot;&gt;Communication model&lt;/h2&gt;
&lt;p&gt;Provides &lt;strong&gt;get&lt;/strong&gt; and &lt;strong&gt;put&lt;/strong&gt; methods for working with symmetric objects. Has all
the bulk, scalar and interleaved transfer schemes available. Also supports
atomic memory operations (AMO). There are methods can be initiated from CUDA
kernels or from the host too. All the CPU-side calls are stream-ordered.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_ptr()&lt;/code&gt; provides raw address pointer to be used for issuing explicit
loads/stores to local or remote PEs, as long as they are accessible to each
other.&lt;/p&gt;

&lt;p&gt;All nvshmem symmmetric memory is pinned GPU memory.&lt;/p&gt;

&lt;p&gt;nvshmem assumes a one-to-one mapping between PE and GPU.&lt;/p&gt;

&lt;p&gt;The usual data coalescing policies/guidelines as seen in CUDA programming model
also apply here for efficiency.&lt;/p&gt;

&lt;p&gt;cuda kernels needing sync/collective APIs must be launched using the collective
launch APIs only.&lt;/p&gt;

&lt;h2 id=&quot;memory-model&quot;&gt;memory model&lt;/h2&gt;
&lt;p&gt;List of operations supported:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Remote Memory Access (RMA) - PUT/GET&lt;/li&gt;
  &lt;li&gt;Atomic Memory Operations (AMO)&lt;/li&gt;
  &lt;li&gt;single ops&lt;/li&gt;
  &lt;li&gt;direct loads/stores (via the pointer returned by &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_ptr()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;collective ops&lt;/li&gt;
  &lt;li&gt;wait and test functions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since GPUs expose only a weak memory model, nvshmem does introduce a few
exceptions to the openshmem memory model&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;no guarantees to the order of writes to a symmetric memory, as seen by PEs&lt;/li&gt;
  &lt;li&gt;to enforce ordering to target PE use &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_fence()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;to enforce ordering to all other PE’s use &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_quiet()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;to enforce ordering for nonblocking calls use &lt;code class=&quot;highlighter-rouge&quot;&gt;nvshmem_quiet()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Result of the get or AMO operations will appear in the program order, however.&lt;/p&gt;</content><author><name></name></author><category term="cuda" /><summary type="html">NVSHMEM</summary></entry></feed>