<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="https://teju85.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://teju85.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-06-22T13:15:54+05:30</updated><id>https://teju85.github.io/blog/feed.xml</id><title type="html">Quagmire</title><subtitle>Stuff I find cool/useful</subtitle><entry><title type="html">Learning Graph Neural Networks with Deep Graph Library</title><link href="https://teju85.github.io/blog/2020/06/18/dgl-webconf-2020.html" rel="alternate" type="text/html" title="Learning Graph Neural Networks with Deep Graph Library" /><published>2020-06-18T00:00:00+05:30</published><updated>2020-06-18T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/18/dgl-webconf-2020</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/18/dgl-webconf-2020.html">&lt;p&gt;Recording of the talk can be found &lt;a href=&quot;https://www.youtube.com/watch?v=bD6S3xUXNds&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;overview-of-graph-neural-networks&quot;&gt;Overview of Graph Neural Networks&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Tasks in graph learning
    &lt;ul&gt;
      &lt;li&gt;node classification (fraud detection)&lt;/li&gt;
      &lt;li&gt;link prediction (eg: recsys)&lt;/li&gt;
      &lt;li&gt;graph classification (eg: drug discovery)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;graph learning has 2 steps:
    &lt;ul&gt;
      &lt;li&gt;generate low-dim embedding of node&lt;/li&gt;
      &lt;li&gt;use standard classifiers from there onwards&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;GNNs can learn node, edge, graph embeddings in an end-to-end fashion and are
based on message-passing between neighbors
    &lt;ul&gt;
      &lt;li&gt;aggregation operation needs to be permutation invariant&lt;/li&gt;
      &lt;li&gt;thereby these nets integrate node/edge/graph features as well as topology in
a non-linear fashion&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;for graph classification, there’ll be a final “readout” layer to compute the
overall graph embedding based on embeddings of each node&lt;/li&gt;
  &lt;li&gt;training of large graphs is done via mini-batch training
    &lt;ul&gt;
      &lt;li&gt;with pruning of neighborhood via sampling to reduce computational complexity&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;deep-graph-library---an-update&quot;&gt;Deep Graph Library - an update&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/dgl/01-dgl-stack.png&quot; alt=&quot;DGL stack&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;already having active customers using DGL via AWS Sagemaker&lt;/li&gt;
  &lt;li&gt;started out with multiple backends&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;flexible-message-propagation&quot;&gt;flexible message propagation&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/dgl/02-flexible-message-handling.png&quot; alt=&quot;Flexible message handling&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;full propagation&lt;/li&gt;
  &lt;li&gt;propagation by graph traversal: sampling on ego-network&lt;/li&gt;
  &lt;li&gt;propagation by random walk&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;dgl-programming-interface&quot;&gt;DGL programming interface&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/blog/assets/dgl/03-dgl-api.png&quot; alt=&quot;DGL API&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt; is the core abstraction
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph.ndata[&quot;h&quot;]&lt;/code&gt; - the node representation matrix&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;simple and flexible message passing APIs
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;active set&lt;/em&gt; - set of nodes/edges to trigger computation on&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;three user defined functions
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\phi^v&lt;/script&gt; - transformation function on vertices&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\bigoplus&lt;/script&gt; - reduction or aggregation function&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\phi^e&lt;/script&gt; - transformation function on edges&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;update_all&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;shortcut for &lt;code class=&quot;highlighter-rouge&quot;&gt;send(G.edges()); recv(G.nodes());&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;in other words, do a full propagation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;now heterogeneous graph is supported&lt;/li&gt;
  &lt;li&gt;new sampling API is introduced in v0.43 release&lt;/li&gt;
  &lt;li&gt;next plan is to look at distributed training&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;using-gnns-for-basic-graph-tasks&quot;&gt;Using GNNs for basic graph tasks&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;using Zachary’s karate class network to demo APIs of DGL&lt;/li&gt;
  &lt;li&gt;DGL expects node id’s to be consecutive integers starting from 0&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.graph&lt;/code&gt; is the main graph structure which provides IO and query methods&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.graph.ndata&lt;/code&gt; member is a dict that holds node features as tensor&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.graph.edata&lt;/code&gt; member is a dict that holds edge features as tensor&lt;/li&gt;
  &lt;li&gt;definition of models (and their training) in dgl is very similar to that of pytorch&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How to customize graph-conv using message passing APIs&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.graph.ndata&lt;/code&gt; (and &lt;code class=&quot;highlighter-rouge&quot;&gt;edata&lt;/code&gt;) can be locally updated using &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.graph.local_scope()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Message passing APIs in DGL are a generalization as found in
&lt;em&gt;Message Passing Neural Network&lt;/em&gt;s. The relevant equations are as follows:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;m_{uv}^{(l)} = Message^{(l)}(h_u^{(l-1)}, h_v^{(l-1)}, e_{uv}^{(l)})&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;m_v^{(l)} = Aggregation_{u \epsilon N(v)}(m_{uv}^{(l)})&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^{(l)} = Update^{(l)}(h_v^{(l-1)}, m_v^{(l)})&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;scale-gnn-to-giant-graphs-using-dgl&quot;&gt;Scale GNN to giant graphs using DGL&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;for large batches it is recommended to use mini-batch training procedure&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Currently stopped at 2:46:17&lt;/p&gt;</content><author><name></name></author><category term="tech-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Recording of the talk can be found here.</summary></entry><entry><title type="html">Open Graph Benchmark: Datasets for Machine Learning on Graphs</title><link href="https://teju85.github.io/blog/2020/06/17/open-graph-benchmark.html" rel="alternate" type="text/html" title="Open Graph Benchmark: Datasets for Machine Learning on Graphs" /><published>2020-06-17T00:00:00+05:30</published><updated>2020-06-17T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/17/open-graph-benchmark</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/17/open-graph-benchmark.html">&lt;h3 id=&quot;proposal&quot;&gt;proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;&quot;&gt;here&lt;/a&gt; and the code for it is found &lt;a href=&quot;https://ogb.stanford.edu&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Provides diverse datasets from different domains&lt;/li&gt;
  &lt;li&gt;Various sizes to test scalability&lt;/li&gt;
  &lt;li&gt;Fully automated data loader, train-test split and evaluation methods for every dataset&lt;/li&gt;
  &lt;li&gt;Different categories of tasks - node, link, graph property prediction&lt;/li&gt;
  &lt;li&gt;Finally public leaderboard for inviting community contributions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ogb-package&quot;&gt;ogb package&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;provides utilities to download the datset and train/test split them.&lt;/li&gt;
  &lt;li&gt;such utilities are provided for multiple datasets&lt;/li&gt;
  &lt;li&gt;also provides utility methods to evaluate the resulting graph model too&lt;/li&gt;
  &lt;li&gt;it is compatible with pytorch-geometric and DGL&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">proposal Main paper can be found here and the code for it is found here.</summary></entry><entry><title type="html">DeepWalk: Online Learning of Social Representations</title><link href="https://teju85.github.io/blog/2020/06/16/deepwalk.html" rel="alternate" type="text/html" title="DeepWalk: Online Learning of Social Representations" /><published>2020-06-16T00:00:00+05:30</published><updated>2020-06-16T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/16/deepwalk</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/16/deepwalk.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1403.6652.pdf&quot;&gt;here&lt;/a&gt; and a quick
summary of the techniques of this paper can be found in &lt;a href=&quot;https://medium.com/analytics-vidhya/an-intuitive-explanation-of-deepwalk-84177f7f2b72&quot;&gt;this blog&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Learns representations of the nodes in a graph, inspired from word2vec.&lt;/li&gt;
  &lt;li&gt;Treats the list of nodes from a random walk as sentences&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Authors note a striking similarity of power-law distribution of nodes in the
random walk and words in natural languages&lt;/li&gt;
  &lt;li&gt;Such random walks are also helpful from implementation PoV, as they are easy
to parallelize&lt;/li&gt;
  &lt;li&gt;They are also helpful when the graph changes and we need to iteratively update
the learnings, instead of costly global recomputation&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h4&gt;
&lt;p&gt;Inputs:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;G(V, E)&lt;/script&gt; graph
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; number of nodes&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; number of edges&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; window size&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; output embedding size&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\gamma&lt;/script&gt; walks per node&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; walk length&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\Phi \epsilon R^{n x d}&lt;/script&gt; the embeddings for each node&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DeepWalk algo:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Randomly initialize &lt;script type=&quot;math/tex&quot;&gt;\Phi&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;for i from 0 to &lt;script type=&quot;math/tex&quot;&gt;\gamma&lt;/script&gt;
    &lt;ol&gt;
      &lt;li&gt;for each &lt;script type=&quot;math/tex&quot;&gt;v_i&lt;/script&gt; in shuffle(V)
        &lt;ul&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;W_{v_i}&lt;/script&gt; = randomwalk(G, &lt;script type=&quot;math/tex&quot;&gt;v_i&lt;/script&gt;, t)&lt;/li&gt;
          &lt;li&gt;skipgram(&lt;script type=&quot;math/tex&quot;&gt;\Phi&lt;/script&gt;, $$W_{v_i}, w)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;skipgram algo:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;for each &lt;script type=&quot;math/tex&quot;&gt;v_j \epsilon W_{v_i}&lt;/script&gt;
    &lt;ol&gt;
      &lt;li&gt;for each &lt;script type=&quot;math/tex&quot;&gt;u_k \epsilon W_{v_i}[j - w : j + w]&lt;/script&gt;
        &lt;ul&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\Phi) = -log(Pr(u_k || \Phi(v_j)))&lt;/script&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;\Phi = \Phi - \alpha \frac{\partial J}{\partial \Phi}&lt;/script&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;Pr(.)&lt;/script&gt; above uses hierarchical softmax to be computationally more efficient.&lt;/p&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main paper can be found here and a quick summary of the techniques of this paper can be found in this blog.</summary></entry><entry><title type="html">A comprehensive survey on Graph Neural Networks</title><link href="https://teju85.github.io/blog/2020/06/14/survey-of-gnns.html" rel="alternate" type="text/html" title="A comprehensive survey on Graph Neural Networks" /><published>2020-06-14T00:00:00+05:30</published><updated>2020-06-14T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/14/survey-of-gnns</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/14/survey-of-gnns.html">&lt;h3 id=&quot;proposal&quot;&gt;Proposal&lt;/h3&gt;
&lt;p&gt;Main survey paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1901.00596.pdf&quot;&gt;here&lt;/a&gt;.
Divides GNNs into the following top-level four categories:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;recurrent GNNs - iteratively exchange info with neighbors until some form of
convergence is achieved. This idea is borrowed and improved by convGNNs.&lt;/li&gt;
  &lt;li&gt;convolutional GNNs - same as recGNNs, but here multiple such operations are
stacked to extract high-level node representations based on neighbors that
are further away.&lt;/li&gt;
  &lt;li&gt;graph autoencoders - unsupervised methods to represent graphs by latent
vectors and then use a decoder phase to reconstruct the graph&lt;/li&gt;
  &lt;li&gt;spatio-temporal GNNs - combine convGNNs and then regular 1D-CNNs to capture
both spatial and temporal info of the nodes, respectively&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;differences-wrt-regular-dl&quot;&gt;Differences wrt regular DL&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;data space is non-Euclidean&lt;/li&gt;
  &lt;li&gt;graphs can be irregular&lt;/li&gt;
  &lt;li&gt;number of neighbors vary, causing difficulty with regular convolutions&lt;/li&gt;
  &lt;li&gt;instance (aka node) is not independent of the other&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;differences-wrt-network-embedding&quot;&gt;Differences wrt network embedding&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;NE involves other non-DL methods like factorization, random-walks&lt;/li&gt;
  &lt;li&gt;GNNs provide and end-to-end solution for some of the graph-related tasks&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;recgnns&quot;&gt;recGNNs&lt;/h3&gt;
&lt;p&gt;Perform message passing between nodes and their neighbors, until some form of
convergence is achieved.
&lt;script type=&quot;math/tex&quot;&gt;h_v^{(t)} = \sum_{u \epsilon N(v)} f(X_v, x_{u,v}^e, x_u, h_u^{(t-1)})&lt;/script&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;h_v&lt;/script&gt; = hidden vector which is initialized to random value at time = 0&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f(.)&lt;/script&gt; = a contraction mapping parametric function to ensure convergence&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; = node feature matrix&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; = edge feature matrix&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;N(v)&lt;/script&gt; = neighborhood of node &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;n = number of nodes&lt;/li&gt;
  &lt;li&gt;m = number of edges&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Gated GNNs - use GRU with fixed number of recurrence steps, instead of a
generic contraction mapping function. Then uses BPTT (backprop through time)
in order to learn parameters.
&lt;script type=&quot;math/tex&quot;&gt;h_v^{(t)} = GRU(h_v^{(t-1)}, \sum_{u \epsilon N(v)} W h_u^{(t-1)}&lt;/script&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^{(0)} = x_v&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;convgnns&quot;&gt;convGNNs&lt;/h3&gt;

&lt;h4 id=&quot;spectral-based&quot;&gt;spectral based&lt;/h4&gt;
&lt;p&gt;Based on graph signal processing and use normalized graph laplacian
&lt;script type=&quot;math/tex&quot;&gt;L = I - D^{-0.5} A D^{-0.5}&lt;/script&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt; = diagonal matrix with &lt;script type=&quot;math/tex&quot;&gt;D_{ii} = \sum_j A_{ij}&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; is real symmetric and positive semidefinite. So, it can be factored into
&lt;script type=&quot;math/tex&quot;&gt;L = U \Lambda U^T&lt;/script&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; = columwise eigenvectors ordered by eigenvalues&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\Lambda&lt;/script&gt; = diagonal matrix of eigenvalues&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Graph fourier transform on input &lt;script type=&quot;math/tex&quot;&gt;x \epsilon R^n&lt;/script&gt; is defined as &lt;script type=&quot;math/tex&quot;&gt;y = U^T x&lt;/script&gt;
similarly vice-versa for graph inverse fourier transform.&lt;/p&gt;

&lt;p&gt;Assuming a filter &lt;script type=&quot;math/tex&quot;&gt;g \epsilon R^n&lt;/script&gt;, convolution operation will become
&lt;script type=&quot;math/tex&quot;&gt;x*g = U (U^T x \odot U^T g) = U g_{\theta} U^T x&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;g_{\theta} = U^T g&lt;/script&gt;
All spectral methods follow this, except for their choice of &lt;script type=&quot;math/tex&quot;&gt;g_{\theta}&lt;/script&gt;.
Some methods are:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Spectral CNNs&lt;/li&gt;
  &lt;li&gt;Chebyshev spectral CNNs (ChebNet)&lt;/li&gt;
  &lt;li&gt;CayleyNet&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/2020/06/09/graph-convolutional-networks.html&quot;&gt;GCN&lt;/a&gt;
these are however a mix of spectral and spatial based by approximating
ChebNet at first-order and simplifying learnable parameters.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;spatial-based&quot;&gt;spatial based&lt;/h4&gt;
&lt;p&gt;All these methods aggregate neighbor information in some form and propagate this
to the current node. Multiple such layers are stacked upon each other to
increase the neighborhood definition.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Neural Network for Graphs: Somewhat resembles GCN.
&lt;script type=&quot;math/tex&quot;&gt;H^{(k)} = f(X W^{(k)} + \sum_{i=1}^{k - 1} A H^{(k-1)} \Theta^{(k)})&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Diffusion CNNs: &lt;script type=&quot;math/tex&quot;&gt;H^{(k)} = f(W^{(k)} \odot P^k X)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Diffusion Graph Convolution: &lt;script type=&quot;math/tex&quot;&gt;H = \sum_{k=0}^K f(p^k X W^{(k)})&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Message Passing NN&lt;/li&gt;
  &lt;li&gt;GraphSage: samples the neighbors in order to avoid needing full-batch&lt;/li&gt;
  &lt;li&gt;fast-GCN: samples a fixed number of nodes instead of neighbors&lt;/li&gt;
  &lt;li&gt;Graph Attention Network
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^{(k)} = \sigma(\sum_{u \epsilon N(v) \cup v} \alpha_{vu}^{(k)} W^{(k)} h_u^{(k-1)})&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_v^{(0)} = x_v&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_{vu}^{(k)} = softmax(leakyReLU(a^T [W^{(k)}h_v^{(k-1)} || W^{(k)}h_u^{(k-1)}]))&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;spectral-vs-spatial&quot;&gt;spectral vs spatial&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;spectral methods have theoretical framework&lt;/li&gt;
  &lt;li&gt;spatial methods are computationally efficient and scalable&lt;/li&gt;
  &lt;li&gt;spatial methods allow batching of nodes in a graph&lt;/li&gt;
  &lt;li&gt;spectral methods only work with undirected graphs&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;graph-pooling-modules&quot;&gt;graph pooling modules&lt;/h4&gt;
&lt;p&gt;coarsen the graph representation to reduce computationaly complexity for graph
classification and such other tasks next in the pipeline. Popular approach is to
use mean/max/sum based pooling functions:
&lt;script type=&quot;math/tex&quot;&gt;h_G = poolFunction(h_1^{(K)}, h_2^{(K)}, ..., h_n^{(K)})&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;graph-autoencoders&quot;&gt;Graph autoencoders&lt;/h3&gt;

&lt;h4 id=&quot;network-embedding&quot;&gt;network embedding&lt;/h4&gt;
&lt;p&gt;Low dimensional representation of nodes which preserves the topological info.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Graph AutoEncoder: uses GCN in encoder phase and decoder phase tries to
reconstruct the adjacency matrix based on the generated embedding&lt;/li&gt;
  &lt;li&gt;Variational GAE: Variational version of the above, using KL divergence as the
metric&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;graph-generation&quot;&gt;graph generation&lt;/h4&gt;
&lt;p&gt;Beneficial in solving molecular graph generation problem. There are methods
which try to generate graphs globally or sequentially.&lt;/p&gt;

&lt;h3 id=&quot;spatio-temporal-gnns&quot;&gt;spatio-temporal GNNs&lt;/h3&gt;
&lt;p&gt;Capture both spatial and temporal dependencies together. eg: traffic speed
forecasting. Most simple way is to feed the output of convGNNs into recurrent
layer like RNNs/LSTMs.&lt;/p&gt;

&lt;h3 id=&quot;future-directions&quot;&gt;future directions&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;model depth - going infinite depth will pull all nodes into a single point!
Does it make sense to increase depth?&lt;/li&gt;
  &lt;li&gt;scalability trade-off - use of clustering could destroy patterns, while
sampling the neighbors may miss critical info at times. Need to find a good
trade-off between scalability and info-loss&lt;/li&gt;
  &lt;li&gt;heterogeneous graphs support&lt;/li&gt;
  &lt;li&gt;dynamicity - STGNNs addresses some aspects of this.&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Proposal Main survey paper can be found here. Divides GNNs into the following top-level four categories: recurrent GNNs - iteratively exchange info with neighbors until some form of convergence is achieved. This idea is borrowed and improved by convGNNs. convolutional GNNs - same as recGNNs, but here multiple such operations are stacked to extract high-level node representations based on neighbors that are further away. graph autoencoders - unsupervised methods to represent graphs by latent vectors and then use a decoder phase to reconstruct the graph spatio-temporal GNNs - combine convGNNs and then regular 1D-CNNs to capture both spatial and temporal info of the nodes, respectively</summary></entry><entry><title type="html">cmus installation and usage on cygwin</title><link href="https://teju85.github.io/blog/2020/06/13/cmus-on-cygwin.html" rel="alternate" type="text/html" title="cmus installation and usage on cygwin" /><published>2020-06-13T00:00:00+05:30</published><updated>2020-06-13T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/13/cmus-on-cygwin</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/13/cmus-on-cygwin.html">&lt;h3 id=&quot;cmus&quot;&gt;cmus&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://cmus.github.io/&quot;&gt;cmus&lt;/a&gt; is a lightweight console player for unix-like
operating systems. Given here are the steps to build it on cygwin.&lt;/p&gt;

&lt;h4 id=&quot;steps&quot;&gt;Steps&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lynx -source rawgit.com/transcode-open/apt-cyg/master/apt-cyg &amp;gt; apt-cyg
install apt-cyg /bin
apt-cyg install ncurses ncursesw pkg-config
apt-cyg install libncursesw-devel libncurses-devel
apt-cyg install libopus-devel libwavpack-devel
apt-cyg install libtool flac-devel

cd ~
wget ftp://ftp.mars.org/pub/mpeg/libmad-0.15.1b.tar.gz
tar xf
cd libmad-0.15.1b
wget 'http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.guess;hb=HEAD' -O config.guess
wget 'http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.sub;hb=HEAD' -O config.sub
sed -i '/-fforce-mem/d' configure
./configure
make
make install

cd ~
git clone https://github.com/cmus/cmus.git
cd cmus
./configure CPPFLAGS=-I/usr/local/include LDFLAGS=-L/usr/local/lib
make
make install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;key-controls&quot;&gt;Key controls&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;v: stop playback&lt;/li&gt;
  &lt;li&gt;b: next track&lt;/li&gt;
  &lt;li&gt;z: previous track&lt;/li&gt;
  &lt;li&gt;c: pause playback&lt;/li&gt;
  &lt;li&gt;s: toggle shuffle (read about the m key below if you’re going to use shuffle)&lt;/li&gt;
  &lt;li&gt;m: toggles the “aaa mode.”&lt;/li&gt;
  &lt;li&gt;x: restart track&lt;/li&gt;
  &lt;li&gt;i: jump view to the currently playing track (handy when in shuffle mode)&lt;/li&gt;
  &lt;li&gt;o: toggle sorting&lt;/li&gt;
  &lt;li&gt;/: searching cmus works as in many Unix programs.
    &lt;ul&gt;
      &lt;li&gt;Typing slash, a string, and enter will find the first instance of that
string in your library.&lt;/li&gt;
      &lt;li&gt;Press n to go to the next string, N to go to the previous.&lt;/li&gt;
      &lt;li&gt;cmus’s search isn’t case sensitive and is quite smart; a search for damned
insurrection will return Bulldozer’s “Insurrection of the Living Damned”
(rad tune).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;-: reduce the volume by 10%&lt;/li&gt;
  &lt;li&gt;+: increase the volume by 10%&lt;/li&gt;
  &lt;li&gt;:add path  - to add a playlist&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tools" /><summary type="html">cmus cmus is a lightweight console player for unix-like operating systems. Given here are the steps to build it on cygwin.</summary></entry><entry><title type="html">Pixie</title><link href="https://teju85.github.io/blog/2020/06/12/pixie.html" rel="alternate" type="text/html" title="Pixie" /><published>2020-06-12T00:00:00+05:30</published><updated>2020-06-12T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/12/pixie</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/12/pixie.html">&lt;h3 id=&quot;pixie-a-system-for-recommending-3-billion-items-to200-million-users-in-real-time&quot;&gt;Pixie: A System for Recommending 3+ Billion Items to200+ Million Users in Real-Time&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1711.07601.pdf&quot;&gt;here&lt;/a&gt; and a more
digestable version is presented in a blog format &lt;a href=&quot;https://medium.com/pinterest-engineering/introducing-pixie-an-advanced-graph-based-recommendation-system-e7b4229b664b&quot;&gt;here&lt;/a&gt;
and &lt;a href=&quot;https://medium.com/pinterest-engineering/an-update-on-pixie-pinterests-recommendation-system-6f273f737e1b&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;proposal&quot;&gt;Proposal&lt;/h4&gt;
&lt;p&gt;Provide real-time recommendations to the users via:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Pixie random walk algorithm to generate recommendations whose runtime is
constant wrt the size of the input graph.&lt;/li&gt;
  &lt;li&gt;description of the implementation (in production) based on C++ on top of
&lt;a href=&quot;http://snap.stanford.edu/&quot;&gt;SNAP&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;details&quot;&gt;Details&lt;/h4&gt;
&lt;p&gt;Input to this system is a query set &lt;script type=&quot;math/tex&quot;&gt;Q = {(q, w_q)}&lt;/script&gt;, which is a collection of
pins with associated weights to represent its importance in current query set.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pixie random walk&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;Biased walks&lt;/em&gt;: walks are biased for a query set &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt; based on the user. This
helps provide personalized recommendations.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;multiple query pins with weights&lt;/em&gt;: weights to the input query pins are
assigned based on the time since the user interacted with this pin and the
interaction type.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;sample walk length&lt;/em&gt;: helps provide enough walks for pins with lower degree
but also reduces runtime cost for pins with higher degree.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;multi-hit booster&lt;/em&gt;: weightage given to the candidate pins which have high
visit counts for all the pins in the &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt;. &lt;script type=&quot;math/tex&quot;&gt;V[p] = (\sum_{q \epsilon Q}\sqrt{V_q[p]})^2&lt;/script&gt;
where &lt;script type=&quot;math/tex&quot;&gt;V_q&lt;/script&gt; is visit count for the query &lt;script type=&quot;math/tex&quot;&gt;q \epsilon Q&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;early stopping&lt;/em&gt;: stop the random walk when the top visited candidates have
crossed certain threshold.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Computation of walk length for a given pin is as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s_q = \|E(q)\|.(C - log\|E(q)\|)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Nq = N w_q \frac{s_q}{\sum_{r \epsilon Q} s_r}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;Nq&lt;/script&gt; = walk length for random walk starting from pin q&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\|E(q)\|&lt;/script&gt; = degree of pin q&lt;/li&gt;
  &lt;li&gt;C = max degree of all pins&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Algorithm for a single query is as follows:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PixieRandomWalk(q, E, U, alpha, Nq, nv, np):
  totSteps = nHighVisited = 0
  V = {0}
  do
    currPin = q
    currSteps = SampleWalkLength(alpha)
    for i in range(currSteps):
      currBoard = E(currPin)[PersonalizedNeighbor(E, U)]
      currPin = E(currBoard)[PersonalizedNeighbor(E, U)]
      V[currPin]++
      if V[currPin] == nv:
        nHighVisited++
    totSteps += currSteps
  while totSteps &amp;lt; Nq and nHighVisited &amp;lt; np
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;q = query pin&lt;/li&gt;
  &lt;li&gt;E = edges in the graph&lt;/li&gt;
  &lt;li&gt;U = user features&lt;/li&gt;
  &lt;li&gt;alpha = helps determine the number of steps per random walk&lt;/li&gt;
  &lt;li&gt;PersonalizedNeighbor(E, U) = randomized method to return neighbors, but
edges being weighted by user features&lt;/li&gt;
  &lt;li&gt;Nq = total number of steps taken in the random walk&lt;/li&gt;
  &lt;li&gt;nv and np = used for early stopping. the random walk is terminated when there
are np number of pins that have been visited atleast nv number of times&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;graph pruning&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Prunes the graph to fit in RAM and thus do not have to distribute it.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Removes duplicate pins&lt;/li&gt;
  &lt;li&gt;Removes pins assigned to incorrect boards&lt;/li&gt;
  &lt;li&gt;Removes boards with larger entropy: computes LDA on each pin description and
computes entropy for a board by combining LDA vectors from all pins associated
with this board.&lt;/li&gt;
  &lt;li&gt;Prune the degree (or remove) pins with abnormally high degree: only keep the
edges with highest cosine similarity. Threshold is determined by the pruning
factor &lt;script type=&quot;math/tex&quot;&gt;\delta&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><summary type="html">Pixie: A System for Recommending 3+ Billion Items to200+ Million Users in Real-Time Main paper can be found here and a more digestable version is presented in a blog format here and here.</summary></entry><entry><title type="html">PinSage</title><link href="https://teju85.github.io/blog/2020/06/10/pinsage.html" rel="alternate" type="text/html" title="PinSage" /><published>2020-06-10T00:00:00+05:30</published><updated>2020-06-10T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/10/pinsage</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/10/pinsage.html">&lt;h3 id=&quot;pinsage---graph-convolutional-neural-networks-for-web-scalerecommender-systems&quot;&gt;PinSage - Graph Convolutional Neural Networks for Web-ScaleRecommender Systems&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/1806.01973.pdf&quot;&gt;here&lt;/a&gt; and a more
digestable version is presented in a blog format &lt;a href=&quot;https://medium.com/pinterest-engineering/pinsage-a-new-graph-convolutional-neural-network-for-web-scale-recommender-systems-88795a107f48&quot;&gt;here&lt;/a&gt;.
A scalable random-walk GCN to learn embeddings on attribute graphs with billions
of nodes. They demonstrate this on Pinterest’s data with billions of nodes and
tens of billions of edges. They also present an efficient way to do inferencing
on the resulting model via MapReduce paradigm.&lt;/p&gt;

&lt;h4 id=&quot;proposal&quot;&gt;Proposal&lt;/h4&gt;
&lt;p&gt;For improving scalability:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;on-the-fly convolutions: sampling the neighborhood to dynamically construct
the computation graph&lt;/li&gt;
  &lt;li&gt;producer-consumer minibatch construction: CPU producing minibatches via
efficiently sampling the neighborhood GPU performs SGD.&lt;/li&gt;
  &lt;li&gt;efficient MapReduce based inference
For improving accuracy:&lt;/li&gt;
  &lt;li&gt;constructing convs via random walks: sampling of neighbors is done via random
walks on the graph. This also helps provide weightage during aggregation.&lt;/li&gt;
  &lt;li&gt;importance pooling - same as above&lt;/li&gt;
  &lt;li&gt;Curriculum training&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;details&quot;&gt;Details&lt;/h4&gt;
&lt;p&gt;Current GCNs expect the availability of full graph Laplacian during training.
This is very infeasible for web-scale graphs with billions of nodes and edges.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Inputs&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;G = Graph in CSR representation&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;x_u&lt;/script&gt; = node features for each &lt;script type=&quot;math/tex&quot;&gt;u \epsilon G&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;d = dimensionality of the features. This is also the dimensionality of the
output of each layer.&lt;/li&gt;
  &lt;li&gt;L = labelled pairs &lt;script type=&quot;math/tex&quot;&gt;(q, i)&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; represents a good recommendation
if the input query is &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Hyper-params&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;m = dimensionality of the output vector of the aggregation step. This is
assumed to be the same value across all layers&lt;/li&gt;
  &lt;li&gt;K = number of layers&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\Delta&lt;/script&gt; = max-margin used in the loss function&lt;/li&gt;
  &lt;li&gt;B = batch size&lt;/li&gt;
  &lt;li&gt;T = max number of neighbors to be sampled for any node&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;Q^k&lt;/script&gt; = neighborhood feature transformation matrix for &lt;script type=&quot;math/tex&quot;&gt;convolve_k&lt;/script&gt; at kth
layer of the network. Dim = m x d&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;q^k&lt;/script&gt; = bias vector for this operation at kth layer. Length = m&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;W^k&lt;/script&gt; = feature transformation matrix after aggregation at kth layer.
Dim = d x (d + m)&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;w^k&lt;/script&gt; = bias vector for this operation at kth layer. Length = d&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;G_1&lt;/script&gt; = 1st feature transformation matrix at final layer. Dim = d x d&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;g&lt;/script&gt; = bias vector for this operation. Length = d&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;G_2&lt;/script&gt; = 2nd feature transformation at final layer. Dim = d x d&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Local convolutions algorithm at kth layer&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;n_u = \gamma(relu(Q^k h_v^k + q^k), \alpha) | v \epsilon N(u)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m_u = concat(h_u^k, n_u)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_u^{k+1} = relu(W^k m_u + w^k)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_u^{k+1} = \frac{h_u^{k+1}}{||h_u^{k+1}||_2}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt; = set of neighbor weights computed based on random-walk. These are
computed as &lt;script type=&quot;math/tex&quot;&gt;L_1&lt;/script&gt; norm of visit counts of each node during random-walk.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\gamma&lt;/script&gt; = aggregation function. Assumed to be weighted-mean&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;N(u)&lt;/script&gt; = sampled neighborhood for node u&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;minibatch preparation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Happens on CPU for the next batch while current batch is running on GPU. Uses
openmp for parallelization.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Model propagation&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Compute the neighbors for each layer starting from the topmost K-th layer&lt;/li&gt;
  &lt;li&gt;Compute the K-layers of convolve operation&lt;/li&gt;
  &lt;li&gt;Finally apply &lt;script type=&quot;math/tex&quot;&gt;G_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;G_2&lt;/script&gt; transformations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Loss function&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Max-margin ranking loss. Dot product of the embeddings of negative samples is
atleast &lt;script type=&quot;math/tex&quot;&gt;\Delta&lt;/script&gt; distance lesser than that of &lt;script type=&quot;math/tex&quot;&gt;(q, i)&lt;/script&gt;. In other words:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;loss(q, i) = max(0, z_q . z_{n_k} - z_q . z_i + \Delta)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;n_k&lt;/script&gt; = negative sample for query &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;training&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Multi-GPU training. Each GPU gets equal amount from the minibatch. Standard
synchronous SGD is used with the following learning rate policy:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;At first epoch, learning rate is linearly increased from a small value to the
peak value.&lt;/li&gt;
  &lt;li&gt;At subsequent epochs, learning rate is exponentially decayed.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;negative sampling&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Each positive training example &lt;script type=&quot;math/tex&quot;&gt;(q, i)&lt;/script&gt; contains multiple “hard” negative
samples too. These hard negative samples are generated via personalized
pagerank scores. To reduce the number of epochs, curriculum training is being
used. At n-th epoch, n - 1 hard negative samples are added for each positive
training sample.&lt;/p&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">PinSage - Graph Convolutional Neural Networks for Web-ScaleRecommender Systems Main paper can be found here and a more digestable version is presented in a blog format here. A scalable random-walk GCN to learn embeddings on attribute graphs with billions of nodes. They demonstrate this on Pinterest’s data with billions of nodes and tens of billions of edges. They also present an efficient way to do inferencing on the resulting model via MapReduce paradigm.</summary></entry><entry><title type="html">Power of GCNs</title><link href="https://teju85.github.io/blog/2020/06/09/power-of-GCNs.html" rel="alternate" type="text/html" title="Power of GCNs" /><published>2020-06-09T00:00:00+05:30</published><updated>2020-06-09T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/09/power-of-GCNs</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/09/power-of-GCNs.html">&lt;h3 id=&quot;power-of-gcns&quot;&gt;Power of GCNs&lt;/h3&gt;
&lt;p&gt;Summary of the content of the blog found &lt;a href=&quot;https://www.inference.vc/how-powerful-are-graph-convolutions-review-of-kipf-welling-2016-2/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Author seems to claim that due to 1st order approximation of Chebyshev polynomials
as the convolution filter, their expressive power might not be good&lt;/li&gt;
  &lt;li&gt;that’s because this approximation, when applied to the special case of regular
graphs (2D images, eg), will lead to severely weak models&lt;/li&gt;
  &lt;li&gt;But the &lt;a href=&quot;https://tkipf.github.io/graph-convolutional-networks&quot;&gt;main authors of the GCN&lt;/a&gt;
paper also note that the Weisfeiler-Lehman algo also doesn’t converge on
regular graphs!&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Power of GCNs Summary of the content of the blog found here.</summary></entry><entry><title type="html">LightGCN</title><link href="https://teju85.github.io/blog/2020/06/09/lightgcn.html" rel="alternate" type="text/html" title="LightGCN" /><published>2020-06-09T00:00:00+05:30</published><updated>2020-06-09T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/09/lightgcn</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/09/lightgcn.html">&lt;h3 id=&quot;lightgcn---simplifying-and-powering-graph-convolutionnetwork-for-recommendation&quot;&gt;LightGCN - Simplifying and Powering Graph ConvolutionNetwork for Recommendation&lt;/h3&gt;
&lt;p&gt;Main paper can be found &lt;a href=&quot;https://arxiv.org/pdf/2002.02126.pdf&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;proposal&quot;&gt;Proposal&lt;/h4&gt;
&lt;p&gt;For collaborative filtering, instead of using full GCNs they only keep the
neighborhood aggregation function and discard feature transformation and the
non-linear activation functions, thereby gaining better final accuracy as well
as simplifying the implementation.&lt;/p&gt;

&lt;h4 id=&quot;details&quot;&gt;Details&lt;/h4&gt;
&lt;p&gt;GCN was originally proposed for classification on rich attributes graph. However
in the case of CF, there are only user-item interaction graphs. They emperically
find that the NGCF’s (Neural Graph Collaborative Filtering, inspired from GCN)
feature transformation and non-linear functions cause accuracy degradation. They
also needlessly increase the complexity of the model. Thus, in LightGCN, they
propose to remove these 2 operations and only keep the neighborhood aggregation.
They create an ID embedding for each user and item and use the user-item
interaction graph to propagate the current embeddings.&lt;/p&gt;

&lt;p&gt;The core graph convolution operation that they are proposing is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_u^{k+1} = \sum_{i \epsilon N_u} \frac{1}{\sqrt{N_i N_u}} e_i^k&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_i^{k+1} = \sum_{i \epsilon N_i} \frac{1}{\sqrt{N_i N_u}} e_u^k&lt;/script&gt;

&lt;p&gt;Note that self-connections are ignored here! As this will be handled in the
final layer combination phase. Final representation (aka combination phase) is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_u = \sum_{k=0}^K \alpha_k e_u^k&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_i = \sum_{k=0}^K \alpha_k e_i^k&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\alpha_k&lt;/script&gt; can be hyper-params are model-params. In this paper, however, they
are setting them to be &lt;script type=&quot;math/tex&quot;&gt;\frac{1}{K+1}&lt;/script&gt; for simplicity.&lt;/p&gt;

&lt;p&gt;Final model prediction is: &lt;script type=&quot;math/tex&quot;&gt;y_{ui} = e_u^T * e_i&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Their code can be found:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/kuandeng/LightGCN&quot;&gt;here&lt;/a&gt; for TF&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/gusye1234/pytorch-light-gcn&quot;&gt;here&lt;/a&gt; for pytorch&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="tech-notes" /><category term="paper-notes" /><category term="graph" /><category term="gnn" /><summary type="html">LightGCN - Simplifying and Powering Graph ConvolutionNetwork for Recommendation Main paper can be found here</summary></entry><entry><title type="html">Graph Convolutional Networks</title><link href="https://teju85.github.io/blog/2020/06/09/graph-convolutional-networks.html" rel="alternate" type="text/html" title="Graph Convolutional Networks" /><published>2020-06-09T00:00:00+05:30</published><updated>2020-06-09T00:00:00+05:30</updated><id>https://teju85.github.io/blog/2020/06/09/graph-convolutional-networks</id><content type="html" xml:base="https://teju85.github.io/blog/2020/06/09/graph-convolutional-networks.html">&lt;h3 id=&quot;graph-convolutional-networks&quot;&gt;Graph Convolutional Networks&lt;/h3&gt;
&lt;p&gt;Summary of the content of the blog found &lt;a href=&quot;https://tkipf.github.io/graph-convolutional-networks&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Inputs:
    &lt;ul&gt;
      &lt;li&gt;N = number of nodes&lt;/li&gt;
      &lt;li&gt;D = dimensionality of input feature vector for each node&lt;/li&gt;
      &lt;li&gt;A = adjacency matrix&lt;/li&gt;
      &lt;li&gt;L = number of layers&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;L_i&lt;/script&gt; = output features at each layer&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f_i&lt;/script&gt; = output activation at each layer&lt;/li&gt;
      &lt;li&gt;X = feature matrix [dim = N x D]&lt;/li&gt;
      &lt;li&gt;F = output feature vector dimension&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Weights
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;W_i&lt;/script&gt; = weight matrix at each layer [dim = &lt;script type=&quot;math/tex&quot;&gt;L_{i-1}&lt;/script&gt; x &lt;script type=&quot;math/tex&quot;&gt;L_i&lt;/script&gt;], with &lt;script type=&quot;math/tex&quot;&gt;L_0&lt;/script&gt; = D&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Outputs:
    &lt;ul&gt;
      &lt;li&gt;Z = transformed feature vector for each node [dim = N x F]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;L layers means that this network does “convolution” with neighbor nodes upto L hops from a given node&lt;/li&gt;
  &lt;li&gt;A’ = A + I, in order introduce self-loops&lt;/li&gt;
  &lt;li&gt;D = diagonal matrix of node degrees (very useful in normalizing the adjacency matrix)&lt;/li&gt;
  &lt;li&gt;each layer’s operation = &lt;script type=&quot;math/tex&quot;&gt;f_i(D^{-0.5} A' D^{-0.5} X_i W_i)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;author’s show forward prop on this network is generalized, differentiable version of Weisfeiler-Lehman algo!&lt;/li&gt;
  &lt;li&gt;code is on &lt;a href=&quot;https://github.com/tkipf/gcn&quot;&gt;github&lt;/a&gt;. Uses TF&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="tech-notes" /><category term="graph" /><category term="gnn" /><summary type="html">Graph Convolutional Networks Summary of the content of the blog found here.</summary></entry></feed>