I"¿<h3 id="graph-convolutional-networks">Graph Convolutional Networks</h3>
<p>Summary of the content of the blog found <a href="https://tkipf.github.io/graph-convolutional-networks">here</a>.</p>

<h3 id="summary">Summary</h3>
<ul>
  <li>Inputs:
    <ul>
      <li>N = number of nodes</li>
      <li>D = dimensionality of input feature vector for each node</li>
      <li>A = adjacency matrix</li>
      <li>L = number of layers</li>
      <li>\(L_i\) = output features at each layer</li>
      <li>\(f_i\) = output activation at each layer</li>
      <li>X = feature matrix [dim = N x D]</li>
      <li>F = output feature vector dimension</li>
    </ul>
  </li>
  <li>Weights
    <ul>
      <li>\(W_i\) = weight matrix at each layer [dim = \(L_{i-1}\) x \(L_i\)], with \(L_0\) = D</li>
    </ul>
  </li>
  <li>Outputs:
    <ul>
      <li>Z = transformed feature vector for each node [dim = N x F]</li>
    </ul>
  </li>
  <li>L layers means that this network does ‚Äúconvolution‚Äù with neighbor nodes upto L hops from a given node</li>
  <li>A‚Äô = A + I, in order introduce self-loops</li>
  <li>D = diagonal matrix of node degrees (very useful in normalizing the adjacency matrix)</li>
  <li>each layer‚Äôs operation = \(f_i(D^{-0.5} A' D^{-0.5} X_i W_i)\)</li>
  <li>author‚Äôs show forward prop on this network is generalized, differentiable version of Weisfeiler-Lehman algo!</li>
  <li>code is on <a href="https://github.com/tkipf/gcn">github</a>. Uses TF</li>
</ul>
:ET