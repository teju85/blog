<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="/src/assets/main.css">
  
  
</head>
  <body>
    <header class="site-header" role="banner">
  <div class="wrapper">
    
    
    <a class="site-title" rel="author" href="/">Quagmire</a>

    
  </div>
</header>
    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">"BlazingText"</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-12-06" itemprop="datePublished">
        Published: 2018-12-06
      </time>
      <br/>
      <time class="dt-published" datetime="2021-07-15" itemprop="datePublished">
        Last Modifed: 2021-07-15
      </time>
    </p>
  </header>

  <ul class="tags">
  
    <li><a href="/tags.html#tech-notes" class="tag">tech-notes</a></li>
  
    <li><a href="/tags.html#paper-notes" class="tag">paper-notes</a></li>
  
    <li><a href="/tags.html#machine-learning" class="tag">machine-learning</a></li>
  
    <li><a href="/tags.html#word2vec" class="tag">word2vec</a></li>
  
  </ul>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Summary of <a href="https://dl.acm.org/citation.cfm?doid=3146347.3146354">this</a> paper on
BlazingText.</p>
<ul>
<li>parallelizing word2vec SGD on GPUs</li>
<li>typical way of parallelizing SGD is through Hogwild approach
<ul>
<li>ignore conflicts that might arise between read/write of weights</li>
<li>since there are not many conflicts, convergence is not usually affected</li>
</ul>
</li>
<li>they too use Intel&#x27;s minibatching technique + shared negative samples here</li>
<li>they implement both the following kernels
<ul>
<li>one CTA per word
<ul>
<li>each thread maps to a vector dimension</li>
<li>peak parallel perf</li>
<li>but reduced accuracy due to increased probability of conflicts</li>
</ul>
</li>
<li>one CTA per sentence
<ul>
<li>each thread maps to a vector dim</li>
<li>medium perf</li>
<li>due to reduced conflicts, gives better accuracy</li>
<li>more sentences worked upon at the same time increases chances of conflicts!</li>
</ul>
</li>
</ul>
</li>
<li>distributed training
<ul>
<li>use data parallelism only</li>
<li>use ncclAllReduce</li>
<li>synchronize at the end of each epoch</li>
<li>they notice reduced accuracy with more GPUs added (specifically &gt; 4)</li>
</ul>
</li>
</ul>

  </div>
  <a class="u-url" href="./_posts/2018-12-06-blazingtext.html" hidden></a>
</article>
      </div>
    </main>
          

<footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-3">
        <p>Stuff I find cool/useful</p>
      </div>
    </div>
  </div>
</footer>
  </body>
</html>